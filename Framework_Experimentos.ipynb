{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOuRKxrDhZE6Rhzvs6QJILr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OscarRojasG/Experimentos-GPTValidator/blob/main/Framework_Experimentos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Framework para experimentos GPTValidator"
      ],
      "metadata": {
        "id": "wAu6OvJu7hBs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El objetivo de este framework consiste en proporcionar un conjunto de funciones previamente implementadas para facilitar la evaluación y comparación de prompts para el proyecto EvaluAI."
      ],
      "metadata": {
        "id": "3ixHfITmnzVF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instrucciones de uso"
      ],
      "metadata": {
        "id": "NtGhcZhln18k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Cargar dataset"
      ],
      "metadata": {
        "id": "pV4tFiFvGSY4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Subir archivo .xlsx con todos los datasets combinados. Debe contener al menos 5 columnas con los siguientes datos:\n",
        "    * **Contexto** (context): Conocimiento previo que necesita el modelo para evaluar la respuesta del estudiante.\n",
        "    * **Pregunta** (question)\n",
        "    * **Respuesta** (answer): Respuesta del estudiante\n",
        "    * **Evaluación manual** (real_eval): Puntaje de referencia dado por uno o más evaluadores humanos.\n",
        "    * **Dataset de origen** (dataset): Dataset del cual provienen los datos para una fila en particular.\n",
        "\n",
        "2. Especificar el nombre de las columnas en un diccionario con la siguiente estructura (ejemplo):\n",
        "\n",
        "    ```\n",
        "    column_data = {\n",
        "            \"context\": \"Contexto\",\n",
        "            \"question\": \"Pregunta\",\n",
        "            \"answer\": \"Respuesta\",\n",
        "            \"real_eval\": \"EvalManual\",\n",
        "            \"dataset\": \"Dataset\"\n",
        "    }\n",
        "    ```\n",
        "\n",
        "3. Cargar dataset con la función `load_dataset(path, sheet_name, column_data)`\n",
        "\n",
        "    - **path** - Ruta del archivo xlsx a utilizar.\n",
        "    - **sheet_name** - Nombre de la hoja donde se encuentran los datos.\n",
        "    - **column_data** - Diccionario explicado en el punto anterior."
      ],
      "metadata": {
        "id": "AKWV5dgcCGKv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Definir miniprompts a evaluar"
      ],
      "metadata": {
        "id": "Q0nCnpHNaR9O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Subir carpeta con la colección de miniprompts. Los miniprompts deben estar definidos en archivos txt y agrupados en carpetas por categoría (ejemplos, analysis, feedback, etc.). **Se pueden crear nuevas carpetas sin restricciones**.\n",
        "\n",
        "2. Seleccionar los miniprompts a utilizar para la generación de los prompts. Estos deben ser definidos en un diccionario donde la clave corresponde al nombre de la carpeta y el valor es el nombre del archivo txt con el miniprompt correspondiente. Se puede utilizar el comodín * como valor para probar con todos los miniprompts de esa carpeta.\n",
        "\n",
        "    ```\n",
        "    prompt_data = {\n",
        "        \"examples\": \"examples_XX.txt\",\n",
        "        \"context\": \"knowledge_XX.txt\",\n",
        "        \"question\": \"...\",\n",
        "        \"answer\": \"...\",\n",
        "        \"instructions\": {\n",
        "            \"analysis\": \"*\",\n",
        "            \"feedback\": \"...\",\n",
        "            \"score\": \"...\",\n",
        "        }\n",
        "    }\n",
        "    ```\n",
        "\n",
        "3. Cargar prompts con la función ``generate_prompts(prompt_data, prompt_folder)``\n",
        "\n",
        "    - **prompt_data** - Diccionario explicado en el punto anterior.\n",
        "    - **prompt_folder** - Ruta de la carpeta donde se encuentra la colección de miniprompts. (Ej: Experiments/Miniprompts)\n",
        "\n",
        "#### Notas adicionales\n",
        "\n",
        "En caso de tener problemas al subir la carpeta a colab, subirla como zip y ejecutar el comando\n",
        "\n",
        "```\n",
        "!unzip nombre_carpeta.zip\n",
        "```\n",
        "\n",
        "Los criterios deben ser definidos en las primeras líneas del miniprompt score con el símbolo $.\n",
        "\n",
        "```\n",
        "$correctness\n",
        "$completeness\n",
        "$clarity\n",
        "(score) Assign a score between 0 and 10 to different criteria based on the student's answer and the generated feedback. Criteria are: correctness, completeness, clarity.\n",
        "```\n",
        "\n",
        "Las instrucciones de salida de algunos miniprompts como feedback y analysis, se pueden definir usando el símbolo # en la primera línea del archivo.\n",
        "\n",
        "```\n",
        "#very detailed feedback considering previous analysis (in spanish, within 150 words)\n",
        "(feedback)\n",
        "Provide Feedback to the student considering the analysis. **Do not be strict at all**.\n",
        "It is enough that the student answer correctly and more or less completely the question. **Do not ask for additional information**.\n",
        "Start by stating whether the answer is good/excelent or poor/insatisfactory.\n",
        "If the answer is good/excelent, affirm the student's understanding and potentially add a brief note on why their response was particularly effective or comprehensive.\n",
        "If the answer is poor/insatisfactory, clearly identify the inaccuracies or errors. Provide specific suggestions on how to improve, ensuring the feedback is constructive.\n",
        "Within 150 words. In Spanish.\n",
        "```"
      ],
      "metadata": {
        "id": "T2uhIxI0JW1t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Realizar experimento"
      ],
      "metadata": {
        "id": "a2SphdjqaUJE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluar los prompts con la función ``experiment(dataset, prompts, repetitions, eval_function, eval_params=None, train_set_size=60, test_set_size=100, seed=42)``\n",
        "\n",
        "- **dataset** - Objeto de tipo DataFrame cargado en el punto 1.\n",
        "- **prompts** - Colección de prompts cargados en el punto 2.\n",
        "- **repetitions** - Número de repeticiones que se desea realizar la evaluación de cada prompt. Cada evaluación implica un nuevo conjunto de entrenamiento/prueba.\n",
        "- **eval_function** - Método para convertir los puntajes GPT a escala 0-3. Puede ser \"cuts\" o \"map\".\n",
        "- **eval_params** - Lista de parámetros usados para la conversión de puntajes. Son distintos dependiendo del valor de *eval_function*.\n",
        "- **train_set_size** - Tamaño total $n$ del conjunto de entrenamiento. El conjunto de entrenamiento se encuentra compuesto por $n/4$ muestras de cada puntaje (balanceado).\n",
        "- **test_set_size** - Tamaño total del conjunto de prueba (no balanceado).\n",
        "- **seed** - Semilla utilizada para la creación de los conjuntos de prueba y entrenamiento.\n",
        "\n",
        "Para ``eval_function = \"cuts\"`` los parámetros siguen la estructura $[w_1, w_2, ..., w_m, a, b, c]$\n",
        "\n",
        "Para ``eval_function = \"map\"`` los parámetros siguen la estructura $[w_1, w_2, ..., w_m, a, b]$\n",
        "\n",
        "En ambos casos, los primeros $m$ parámetros corresponden a las ponderaciones de cada criterio (en el mismo orden en que fueron definidos dentro del miniprompt score). La suma de las ponderaciones debe ser 1. En caso de no haber criterios, existe una única ponderación igual a 1.\n",
        "\n",
        "Para la evaluación por cortes, los parámetros $a, b, c$ corresponden a los puntajes de corte ordenados de menor a mayor. Por ejemplo, para un prompt con 2 criterios, una lista de parámetros válidos podría ser $[0.7, 0.3, 3, 5, 7]$\n",
        "\n",
        "Para la evaluación por mapeo, los parámetros $a, b$ representan los puntajes en escala 0-10 que corresponden a los puntajes 1 y 2 en escala 0-3. Por ejemplo:\n",
        "\n",
        "$\\text{map}(0) = 0$\n",
        "\n",
        "$\\text{map}(a) = 1$\n",
        "\n",
        "$\\text{map}(b) = 2$\n",
        "\n",
        "$\\text{map}(10) = 3$"
      ],
      "metadata": {
        "id": "QjpkYTTfa_ka"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementación paso a paso"
      ],
      "metadata": {
        "id": "IKjPLvH1RBpQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28 &> /dev/null\n",
        "!pip install openai-multi-client &> /dev/null\n",
        "!git clone https://github.com/rilianx/GPTEvaluator &> /dev/null"
      ],
      "metadata": {
        "id": "Blf2NA6gZUN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cargar dataset"
      ],
      "metadata": {
        "id": "qWo35VtxRK23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "# Muestra información relevante del dataset\n",
        "def show_dataset_info(dataset):\n",
        "    display(dataset.head())\n",
        "    print()\n",
        "    print(dataset.value_counts(\"real_eval\"), end=\"\\n\\n\")\n",
        "    print(dataset.value_counts(\"dataset\"))\n",
        "    pass\n",
        "\n",
        "# Carga un dataset a partir de un archivo xlsx y valida sus columnas\n",
        "def load_dataset(path, sheet_name, column_data):\n",
        "    df = pd.read_excel(path, sheet_name=sheet_name)\n",
        "\n",
        "    mandatory_cols = [\"context\", \"question\", \"answer\", \"real_eval\", \"dataset\"]\n",
        "    for key in mandatory_cols:\n",
        "        if key not in column_data.keys():\n",
        "            raise Exception(f\"Error: Debe especificar la columna para la variable {key}\")\n",
        "\n",
        "        value = column_data[key]\n",
        "        if value not in df.columns:\n",
        "            raise Exception(f\"Error: La columna {value} no existe\")\n",
        "\n",
        "        df = df.rename(columns={value: key})\n",
        "\n",
        "    df = df[mandatory_cols]\n",
        "    show_dataset_info(df)\n",
        "    return df"
      ],
      "metadata": {
        "id": "-vAnT6rTr6cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_data = {\n",
        "    \"context\": \"Contexto\",\n",
        "    \"question\": \"Pregunta\",\n",
        "    \"answer\": \"Respuesta\",\n",
        "    \"real_eval\": \"Promedio Redondeado\",\n",
        "    \"dataset\": \"DatasetProveniente\"\n",
        "}\n",
        "\n",
        "df = load_dataset(\"datasets_v2.xlsx\", \"AllDatasets (1dif)\", column_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "O2Hg6gO-uwzk",
        "outputId": "558d4240-7635-4268-9214-e97b90b18e7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        context  \\\n",
              "0                                                                                                                                                                                                                                                           Un montículo binario se mantiene completo insertando elementos en el siguiente espacio libre de la última fila y \"flotando\" el elemento si es necesario. Para eliminar, se intercambia el elemento de la raíz con el último elemento y luego se elimina el último elemento. Esta inserción y eliminación controlada asegura que el montículo siempre sea un árbol binario completo.   \n",
              "1                                                                                                                                                                                                                                                                                                                                                                          La utilidad de tener nodos con múltiples claves en árboles B/B+ radica en la capacidad de almacenar más información en cada nodo, lo que reduce la altura del árbol y, por lo tanto, el número de accesos a disco necesarios para buscar, insertar o eliminar datos.   \n",
              "2                                                                                                                                                                                                                                                                                                                                                                          La utilidad de tener nodos con múltiples claves en árboles B/B+ radica en la capacidad de almacenar más información en cada nodo, lo que reduce la altura del árbol y, por lo tanto, el número de accesos a disco necesarios para buscar, insertar o eliminar datos.   \n",
              "3                                                                                                                                                                                                                                                 Los árboles binarios autobalanceables como AVL y rojo-negro realizan rotaciones y ajustes durante las operaciones de inserción y eliminación para mantener el árbol balanceado. Estas rotaciones y rebalanceos garantizan que la altura del árbol se mantenga O(log n), lo que asegura que las operaciones de búsqueda, inserción y eliminación tengan una complejidad de tiempo logarítmica.   \n",
              "4  Un problema puede resolverse utilizando grafos y algoritmos de búsqueda si puede representarse mediante nodos (objetos, estados) y aristas (relaciones, transiciones) y si se busca una conexión, ruta, o patrón entre estos nodos. Para modelar el problema: 1) Identificar los nodos y aristas. 2) Determinar la estructura del grafo (dirigido/no dirigido, ponderado/no ponderado). 3) Elegir un algoritmo de búsqueda (BFS, DFS, Dijkstra, etc.) basado en el tipo de problema. Para resolverlo, aplicar el algoritmo seleccionado al grafo modelado, siguiendo los pasos específicos del algoritmo para encontrar la solución deseada.   \n",
              "\n",
              "                                                                                                                                                                                       question  \\\n",
              "0                                                              ¿Cómo se asegura que un montículo binario mantenga su forma completa (perfectamente balanceado) al agregar o eliminar elementos?   \n",
              "1                                                                                                         ¿Cuál es e la utilidad de tener nodos con múltiples claves en árboles B/B+? Explique.   \n",
              "2                                                                                                         ¿Cuál es e la utilidad de tener nodos con múltiples claves en árboles B/B+? Explique.   \n",
              "3                                                                ¿Por qué las operaciones de los árboles binarios autobalanceables (AVL y rojo-negro) tienen complejidad de tiempo logarítmica?   \n",
              "4  ¿Qué características debería tener un problema para poder resolverlo utilizando grafos y algoritmos de búsqueda? ¿Qué pasos debo seguir para modelar el problema? ¿Qué hago para resolverlo?   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             answer  \\\n",
              "0                                                                                                                                                                                                                                                                                                                                                    Para asegurar que se mantenga balanceado se comparan los nodos con sus nodos hijos, de modo que el valor máximo o mínimo siempre se mantengan en lo mas arriba del árbol, en la altura 0, y los nodos hijos se acomoden en base al nodo origen   \n",
              "1                                                                                                                                                                                                                                                                                                                                                                   Es útil ya que gracias a eso la altura de esos arboles es significativamente mas baja en comparación a la de otros arboles binarios de búsqueda. Además que es mas eficiente en la búsqueda de datos en específicos y en rango.   \n",
              "2                                                                                                                                                                                                                                          El tener nodos con múltiples claves en árboles B/B+ garantiza una mayor eficiencia, pues al ser árboles autobalanceables (gracias a sus divisiones y fusiones) asegura que su altura se mantendrá mínima, lo cual hace que sus operaciones de búsqueda, inserción y eliminación sean menos costosas lo que implica una complejidad temporal de O(log n).   \n",
              "3                                                                                                                                                                         Los árboles AVL y rojo-negro tienen complejidad de tiempo logarítmica debido a que estos árboles se balancean automáticamente después de cada inserción o eliminación, usando el método de rotaciones que mantienen el orden y equilibrio en el árbol. Con el balanceo se asegura que la altura del árbol sea baja y cada nivel este lo más lleno posible, lo que mantiene la complejidad de O(log n) en las operaciones.   \n",
              "4  Un problema para poder ser resulto con grafos y algoritmos de búsqueda debe plantearse un estado inicial y un estado final esperado por ejemplo en un cubo 2x2 es el estado mesclado y el estado final resuelto, y se debe general un grafo implícito por ejemplo que permita generar los siguientes niveles de nodos que para este caso sería las posibles combinaciones partiendo de un estado dado, y definir el algoritmo de búsqueda por profundidad o por anchura tan que se adapte mas a el problema en este caso búsqueda por anchura al revisar el mejor camino que lleva a a solución.   \n",
              "\n",
              "   real_eval       dataset  \n",
              "0          0  C3-Sample100  \n",
              "1          2  C3-Sample100  \n",
              "2          2  C3-Sample100  \n",
              "3          2  C3-Sample100  \n",
              "4          2  C3-Sample100  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-222bd753-4d36-49f1-951c-3693d953b33c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>real_eval</th>\n",
              "      <th>dataset</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Un montículo binario se mantiene completo insertando elementos en el siguiente espacio libre de la última fila y \"flotando\" el elemento si es necesario. Para eliminar, se intercambia el elemento de la raíz con el último elemento y luego se elimina el último elemento. Esta inserción y eliminación controlada asegura que el montículo siempre sea un árbol binario completo.</td>\n",
              "      <td>¿Cómo se asegura que un montículo binario mantenga su forma completa (perfectamente balanceado) al agregar o eliminar elementos?</td>\n",
              "      <td>Para asegurar que se mantenga balanceado se comparan los nodos con sus nodos hijos, de modo que el valor máximo o mínimo siempre se mantengan en lo mas arriba del árbol, en la altura 0, y los nodos hijos se acomoden en base al nodo origen</td>\n",
              "      <td>0</td>\n",
              "      <td>C3-Sample100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>La utilidad de tener nodos con múltiples claves en árboles B/B+ radica en la capacidad de almacenar más información en cada nodo, lo que reduce la altura del árbol y, por lo tanto, el número de accesos a disco necesarios para buscar, insertar o eliminar datos.</td>\n",
              "      <td>¿Cuál es e la utilidad de tener nodos con múltiples claves en árboles B/B+? Explique.</td>\n",
              "      <td>Es útil ya que gracias a eso la altura de esos arboles es significativamente mas baja en comparación a la de otros arboles binarios de búsqueda. Además que es mas eficiente en la búsqueda de datos en específicos y en rango.</td>\n",
              "      <td>2</td>\n",
              "      <td>C3-Sample100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>La utilidad de tener nodos con múltiples claves en árboles B/B+ radica en la capacidad de almacenar más información en cada nodo, lo que reduce la altura del árbol y, por lo tanto, el número de accesos a disco necesarios para buscar, insertar o eliminar datos.</td>\n",
              "      <td>¿Cuál es e la utilidad de tener nodos con múltiples claves en árboles B/B+? Explique.</td>\n",
              "      <td>El tener nodos con múltiples claves en árboles B/B+ garantiza una mayor eficiencia, pues al ser árboles autobalanceables (gracias a sus divisiones y fusiones) asegura que su altura se mantendrá mínima, lo cual hace que sus operaciones de búsqueda, inserción y eliminación sean menos costosas lo que implica una complejidad temporal de O(log n).</td>\n",
              "      <td>2</td>\n",
              "      <td>C3-Sample100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Los árboles binarios autobalanceables como AVL y rojo-negro realizan rotaciones y ajustes durante las operaciones de inserción y eliminación para mantener el árbol balanceado. Estas rotaciones y rebalanceos garantizan que la altura del árbol se mantenga O(log n), lo que asegura que las operaciones de búsqueda, inserción y eliminación tengan una complejidad de tiempo logarítmica.</td>\n",
              "      <td>¿Por qué las operaciones de los árboles binarios autobalanceables (AVL y rojo-negro) tienen complejidad de tiempo logarítmica?</td>\n",
              "      <td>Los árboles AVL y rojo-negro tienen complejidad de tiempo logarítmica debido a que estos árboles se balancean automáticamente después de cada inserción o eliminación, usando el método de rotaciones que mantienen el orden y equilibrio en el árbol. Con el balanceo se asegura que la altura del árbol sea baja y cada nivel este lo más lleno posible, lo que mantiene la complejidad de O(log n) en las operaciones.</td>\n",
              "      <td>2</td>\n",
              "      <td>C3-Sample100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Un problema puede resolverse utilizando grafos y algoritmos de búsqueda si puede representarse mediante nodos (objetos, estados) y aristas (relaciones, transiciones) y si se busca una conexión, ruta, o patrón entre estos nodos. Para modelar el problema: 1) Identificar los nodos y aristas. 2) Determinar la estructura del grafo (dirigido/no dirigido, ponderado/no ponderado). 3) Elegir un algoritmo de búsqueda (BFS, DFS, Dijkstra, etc.) basado en el tipo de problema. Para resolverlo, aplicar el algoritmo seleccionado al grafo modelado, siguiendo los pasos específicos del algoritmo para encontrar la solución deseada.</td>\n",
              "      <td>¿Qué características debería tener un problema para poder resolverlo utilizando grafos y algoritmos de búsqueda? ¿Qué pasos debo seguir para modelar el problema? ¿Qué hago para resolverlo?</td>\n",
              "      <td>Un problema para poder ser resulto con grafos y algoritmos de búsqueda debe plantearse un estado inicial y un estado final esperado por ejemplo en un cubo 2x2 es el estado mesclado y el estado final resuelto, y se debe general un grafo implícito por ejemplo que permita generar los siguientes niveles de nodos que para este caso sería las posibles combinaciones partiendo de un estado dado, y definir el algoritmo de búsqueda por profundidad o por anchura tan que se adapte mas a el problema en este caso búsqueda por anchura al revisar el mejor camino que lleva a a solución.</td>\n",
              "      <td>2</td>\n",
              "      <td>C3-Sample100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-222bd753-4d36-49f1-951c-3693d953b33c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-222bd753-4d36-49f1-951c-3693d953b33c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-222bd753-4d36-49f1-951c-3693d953b33c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8d5195f3-8be9-4dec-9b09-7f498a662cf0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8d5195f3-8be9-4dec-9b09-7f498a662cf0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8d5195f3-8be9-4dec-9b09-7f498a662cf0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df = load_dataset(\\\"datasets_v2\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"context\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"La utilidad de tener nodos con m\\u00faltiples claves en \\u00e1rboles B/B+ radica en la capacidad de almacenar m\\u00e1s informaci\\u00f3n en cada nodo, lo que reduce la altura del \\u00e1rbol y, por lo tanto, el n\\u00famero de accesos a disco necesarios para buscar, insertar o eliminar datos.\",\n          \"Un problema puede resolverse utilizando grafos y algoritmos de b\\u00fasqueda si puede representarse mediante nodos (objetos, estados) y aristas (relaciones, transiciones) y si se busca una conexi\\u00f3n, ruta, o patr\\u00f3n entre estos nodos. Para modelar el problema: 1) Identificar los nodos y aristas. 2) Determinar la estructura del grafo (dirigido/no dirigido, ponderado/no ponderado). 3) Elegir un algoritmo de b\\u00fasqueda (BFS, DFS, Dijkstra, etc.) basado en el tipo de problema. Para resolverlo, aplicar el algoritmo seleccionado al grafo modelado, siguiendo los pasos espec\\u00edficos del algoritmo para encontrar la soluci\\u00f3n deseada.\",\n          \"Un mont\\u00edculo binario se mantiene completo insertando elementos en el siguiente espacio libre de la \\u00faltima fila y \\\"flotando\\\" el elemento si es necesario. Para eliminar, se intercambia el elemento de la ra\\u00edz con el \\u00faltimo elemento y luego se elimina el \\u00faltimo elemento. Esta inserci\\u00f3n y eliminaci\\u00f3n controlada asegura que el mont\\u00edculo siempre sea un \\u00e1rbol binario completo.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"\\u00bfCu\\u00e1l es e la utilidad de tener nodos con m\\u00faltiples claves en \\u00e1rboles B/B+? Explique.\",\n          \"\\u00bfQu\\u00e9 caracter\\u00edsticas deber\\u00eda tener un problema para poder resolverlo utilizando grafos y algoritmos de b\\u00fasqueda? \\u00bfQu\\u00e9 pasos debo seguir para modelar el problema? \\u00bfQu\\u00e9 hago para resolverlo?\",\n          \"\\u00bfC\\u00f3mo se asegura que un mont\\u00edculo binario mantenga su forma completa (perfectamente balanceado) al agregar o eliminar elementos?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Es \\u00fatil ya que gracias a eso la altura de esos arboles es significativamente mas baja en comparaci\\u00f3n a la de otros arboles binarios de b\\u00fasqueda. Adem\\u00e1s que es mas eficiente en la b\\u00fasqueda de datos en espec\\u00edficos y en rango.\",\n          \"Un problema para poder ser resulto con grafos y algoritmos de b\\u00fasqueda debe plantearse un estado inicial y un estado final esperado por ejemplo en un cubo 2x2 es el estado mesclado y el estado final resuelto, y se debe general un grafo impl\\u00edcito por ejemplo que permita generar los siguientes niveles de nodos que para este caso ser\\u00eda las posibles combinaciones partiendo de un estado dado, y definir el algoritmo de b\\u00fasqueda por profundidad o por anchura tan que se adapte mas a el problema en este caso b\\u00fasqueda por anchura al revisar el mejor camino que lleva a a soluci\\u00f3n.\",\n          \"El tener nodos con m\\u00faltiples claves en \\u00e1rboles B/B+ garantiza una mayor eficiencia, pues al ser \\u00e1rboles autobalanceables (gracias a sus divisiones y fusiones) asegura que su altura se mantendr\\u00e1 m\\u00ednima, lo cual hace que sus operaciones de b\\u00fasqueda, inserci\\u00f3n y eliminaci\\u00f3n sean menos costosas lo que implica una complejidad temporal de O(log n).\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"real_eval\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dataset\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"C3-Sample100\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "real_eval\n",
            "3    127\n",
            "2     75\n",
            "0     52\n",
            "1     36\n",
            "Name: count, dtype: int64\n",
            "\n",
            "dataset\n",
            "C2-Nan                  92\n",
            "C3-Sample100            91\n",
            "C2-Sample100            90\n",
            "C1-OscarBadAnswers20    17\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generación prompts"
      ],
      "metadata": {
        "id": "mqHdu2soRNEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "import copy\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "\n",
        "class Prompt():\n",
        "    def __init__(self, structure, instructions, base_folder):\n",
        "        self.structure = structure\n",
        "        self.instructions = instructions\n",
        "        self.base_folder = base_folder\n",
        "        self.raw_text_structure = None\n",
        "        self.text_structure = None\n",
        "        self.criteria = None\n",
        "        self.output_instructions = None\n",
        "        self.prompt = None\n",
        "\n",
        "        self.read_files()\n",
        "        self.extract_metadata()\n",
        "        self.build_prompt()\n",
        "\n",
        "    # Retorna la estructura base del prompt (diccionario)\n",
        "    def base_structure(self):\n",
        "        structure = copy.deepcopy(self.structure)\n",
        "        structure['instructions'] = {}\n",
        "        for i in self.instructions:\n",
        "            structure['instructions'][i] = structure[i]\n",
        "            structure.pop(i, None)\n",
        "        return structure\n",
        "\n",
        "    # Crea un diccionario con el contenido de cada archivo en la estructura\n",
        "    def read_files(self):\n",
        "        self.raw_text_structure = copy.deepcopy(self.structure)\n",
        "\n",
        "        for key, value in self.raw_text_structure.items():\n",
        "            if key == \"instructions\": continue\n",
        "\n",
        "            path = f\"{self.base_folder}/{key}/{value}\"\n",
        "            try:\n",
        "                self.raw_text_structure[key] = open(path, 'r', encoding='utf-8').read()\n",
        "                self.raw_text_structure[key] += \"\\n\\n\"\n",
        "            except:\n",
        "                raise Exception(f\"Error: El archivo {path} no existe\")\n",
        "\n",
        "    # Extrae metadatos de los archivos como los criterios e instrucciones de salida\n",
        "    def extract_metadata(self):\n",
        "        self.text_structure = copy.deepcopy(self.raw_text_structure)\n",
        "\n",
        "        if 'score' in self.text_structure:\n",
        "            lines = self.text_structure['score'].split('\\n')\n",
        "            self.criteria = [line[1:] for line in lines if line.startswith('$')]\n",
        "            text = [line for line in lines if not line.startswith('$')]\n",
        "            self.text_structure['score'] = '\\n'.join(text)\n",
        "\n",
        "        self.output_instructions = {}\n",
        "        for key, value in self.text_structure.items():\n",
        "            if value.startswith('#'):\n",
        "                m = re.search(r'#(.*?)\\n', value).group(1)\n",
        "                self.output_instructions[key] = m\n",
        "                self.text_structure[key] = '\\n'.join(value.split('\\n')[1:])\n",
        "\n",
        "    # Construye el prompt en formato string\n",
        "    def build_prompt(self):\n",
        "        self.prompt = \"\"\n",
        "        for key, value in self.text_structure.items():\n",
        "            self.prompt += value\n",
        "\n",
        "        output = \"I expect a dict in python as answer: {{\"\n",
        "        for key, value in self.output_instructions.items():\n",
        "            output += f'\"{key}\": \\'{value}\\', '\n",
        "\n",
        "        if len(self.criteria) > 0:\n",
        "            for c in self.criteria:\n",
        "                output += f'\"{c}\": {c}_score, '\n",
        "            output = output[:-2]\n",
        "        else:\n",
        "            output += '\"score\": score'\n",
        "\n",
        "        output += \"}}\\n\\nPython dict:\"\n",
        "        self.prompt += output\n",
        "\n",
        "\n",
        "# Procesa y elimina los diccionarios anidados de prompt_data\n",
        "def normalize_prompt_dict(prompt_data):\n",
        "    instructions = []\n",
        "    if \"instructions\" in prompt_data:\n",
        "        for (key, value) in prompt_data[\"instructions\"].items():\n",
        "            prompt_data[key] = value\n",
        "            instructions.append(key)\n",
        "\n",
        "    prompt_data[\"instructions\"] = \"Instructions:\\n\"\n",
        "    return prompt_data, instructions\n",
        "\n",
        "# Retorna la lista de archivos para reemplazar el comodín *\n",
        "def expand_prompt_data(prompt_data, prompt_folder):\n",
        "    wildcard_field = None\n",
        "    for key, value in prompt_data.items():\n",
        "        if value == \"*\":\n",
        "            wildcard_field = key\n",
        "            break\n",
        "\n",
        "    if not wildcard_field: return None, None\n",
        "\n",
        "    wildcard_files = []\n",
        "    path = f\"{prompt_folder}/{wildcard_field}\"\n",
        "    for file in sorted(os.listdir(path)):\n",
        "        if os.path.isfile(os.path.join(path, file)):\n",
        "            wildcard_files.append(file)\n",
        "\n",
        "    return wildcard_field, wildcard_files\n",
        "\n",
        "# Genera una lista con los prompts a evaluar\n",
        "def generate_prompts(prompt_data, prompt_folder):\n",
        "    template, instructions = normalize_prompt_dict(prompt_data)\n",
        "    wildcard_field, wildcard_files = expand_prompt_data(template, prompt_folder)\n",
        "    prompts = []\n",
        "\n",
        "    if wildcard_field == None:\n",
        "        prompt = Prompt(template, instructions, prompt_folder)\n",
        "        prompts.append(prompt)\n",
        "        print(prompt.prompt)\n",
        "        return prompts\n",
        "\n",
        "    for file in wildcard_files:\n",
        "        structure = copy.deepcopy(template)\n",
        "        structure[wildcard_field] = file\n",
        "        prompt = Prompt(structure, instructions, prompt_folder)\n",
        "        prompts.append(prompt)\n",
        "\n",
        "    # Visualizar\n",
        "    template = copy.deepcopy(prompts[0])\n",
        "    template.raw_text_structure[wildcard_field] = f\"{{{wildcard_field}}}\\n\\n\"\n",
        "    template.extract_metadata()\n",
        "    template.build_prompt()\n",
        "    print(template.prompt)\n",
        "\n",
        "    print(f\"\\n\\nArchivos a utilizar ({len(wildcard_files)}):\\n\")\n",
        "    print(\"\\n\".join(wildcard_files))\n",
        "\n",
        "    return prompts"
      ],
      "metadata": {
        "id": "uuM-IEVRPDBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_data = {\n",
        "    \"examples\": \"examples_1.txt\",\n",
        "    \"context\": \"knowledge_1.txt\",\n",
        "    \"question\": \"question_1.txt\",\n",
        "    \"answer\": \"answer_1.txt\",\n",
        "    \"instructions\": {\n",
        "        \"analysis\": \"analysis_1.txt\",\n",
        "        \"feedback\": \"feedback_1.txt\",\n",
        "        \"score\": \"score_1.txt\",\n",
        "    }\n",
        "}\n",
        "\n",
        "prompt_folder = \"GPTEvaluator/Experiments/Miniprompts\"\n",
        "\n",
        "prompts = generate_prompts(prompt_data, prompt_folder)"
      ],
      "metadata": {
        "id": "8FgMzj4KRlS6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbe3eeab-f81d-493a-8eea-813057456355"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Examples:**\n",
            "Q: ¿Cómo se podría implementar un historial de navegación web usando dos pilas? El historial debe permitir ir hacia atrás y adelante con las páginas previamente visitadas. Describa un algoritmo.\n",
            "Incorrect Answer: Usamos dos pilas para ir hacia adelante y hacia atrás en el historial.  (Score: 0)\n",
            "\n",
            "Q: ¿Cómo se busca un valor en un árbol rojo-negro? Explique el proceso paso a paso.\n",
            "Incorrect Answer: PAra buscar el valor en un árbol rojo-negro debemos pasar por nodos rojos y negros hasta encontrar el valor. (Score: 0)\n",
            "\n",
            "Q: ¿Por qué el acceso a un elemento específico en un arreglo es O(1), es decir, no depende de la cantidad de datos?\n",
            "Incorrect Answer: El acceso es O(1) por que toma un tiempo constante y no depende de la cantidad de datos. (Score: 0)\n",
            "\n",
            "Q: ¿Cuando se recomienda utilizar arreglos en vez de listas enlazadas? Haga referencia a complejidades temporales en su explicación.\n",
            "Incorrect Answer: Un arreglo es recomendable en determinadas situaciones, mientras que la lista enlazada en otras.\n",
            "Feedback: La respuesta del estudiante es incorrecta ya que no proporciona información nueva y simplemente reformula la pregunta sin agregar profundidad o claridad. (Score: 0)\n",
            "\n",
            "**Knowledge:** {Context}\n",
            "\n",
            "\n",
            "**Question:** {Question}\n",
            "\n",
            "**Student's Answer:** {Answer}\n",
            "\n",
            "Instructions:\n",
            "(analysis)\n",
            "Analyse the \"Student's Answer\".\n",
            "Start by paraphrasing the answer in detail and commenting each sentence.\n",
            "It rewrites the same information provided in the question? or It correctly answers the question providing relevant and deep new information?\n",
            "It is complete, that is, answers all the questions?\n",
            "Use the Knowledge as a reference to validate the accuracy and relevance of the student's response.\n",
            "Focus on the alignment between the question asked and the answer provided.\n",
            "\n",
            "\n",
            "(feedback)\n",
            "Provide Feedback to the student considering the analysis. **Do not be strict at all**.\n",
            "It is enough that the student answer correctly and more or less completely the question. **Do not ask for additional information**.\n",
            "Start by stating whether the answer is good/excelent or poor/insatisfactory.\n",
            "If the answer is good/excelent, affirm the student's understanding and potentially add a brief note on why their response was particularly effective or comprehensive.\n",
            "If the answer is poor/insatisfactory, clearly identify the inaccuracies or errors. Provide specific suggestions on how to improve, ensuring the feedback is constructive.\n",
            "Within 150 words. In Spanish.\n",
            "\n",
            "(score) Assign a score between 0 and 10 to different criteria based on the student's answer and the generated feedback. Criteria are: correctness, completeness, clarity.\n",
            "\n",
            "I expect a dict in python as answer: {{\"analysis\": 'La respuesta del estudiante dice que...', \"feedback\": 'very detailed feedback considering previous analysis (in spanish, within 150 words)', \"correctness\": correctness_score, \"completeness\": completeness_score, \"clarity\": clarity_score}}\n",
            "\n",
            "Python dict:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimización parámetros"
      ],
      "metadata": {
        "id": "F-PYuT2HRSHu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.optimize import differential_evolution\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "### Optimización de cortes y ponderaciones ###\n",
        "class CutsEvaluator():\n",
        "    @staticmethod\n",
        "    def f(x, theta):\n",
        "        score = np.dot(x, theta[:-3])\n",
        "        y_pred = np.where(score > theta[-1], 3, np.where(score > theta[-2], 2, np.where(score > theta[-3], 1, 0)))\n",
        "        return y_pred\n",
        "\n",
        "class CutsOptimizer():\n",
        "    def __init__(self, criteria_scores, real_scores):\n",
        "        bounds =  [(0, 1) for _ in range(len(criteria_scores[0]))] + [(1, 4), (4, 7), (7, 10)]\n",
        "        result = differential_evolution(self.error, bounds, args=(criteria_scores, real_scores), seed=1, strategy='rand1exp', mutation=(0,1), recombination=1)\n",
        "        self.params = result.x.tolist()\n",
        "\n",
        "    def error(self, theta, x, y):\n",
        "        y_pred = CutsEvaluator.f(x, theta)\n",
        "        mse = np.mean((y - y_pred) ** 2)\n",
        "        penalty = 1e6 * np.abs(np.sum(theta[:-3]) - 1)\n",
        "        return mse + penalty\n",
        "\n",
        "\n",
        "####### Optimización mapeo de puntajes ########\n",
        "class MapEvaluator():\n",
        "    @staticmethod\n",
        "    def inverse_map(y_pred, theta):\n",
        "        a, b = theta[-2], theta[-1]\n",
        "        def single_inverse_map(y):\n",
        "            if y <= a:\n",
        "                return y / a\n",
        "            elif a < y <= b:\n",
        "                return 1 + (y - a) / (b - a)\n",
        "            else:\n",
        "                return 2 + (y - b) / (10 - b)\n",
        "\n",
        "        return np.array([single_inverse_map(y) for y in y_pred])\n",
        "\n",
        "    @staticmethod\n",
        "    def f(x, theta):\n",
        "        y_pred = np.dot(x, theta[:-2])\n",
        "        return MapEvaluator.inverse_map(y_pred, theta)\n",
        "\n",
        "class MapOptimizer():\n",
        "    def __init__(self, criteria_scores, real_scores):\n",
        "        bounds =  [(0, 1) for _ in range(len(criteria_scores[0]))] + [(1, 9), (1, 9)]\n",
        "        result = differential_evolution(self.error, bounds, args=(criteria_scores, real_scores), seed=1, strategy='rand1exp', mutation=(0,1), recombination=1)\n",
        "        self.params = result.x.tolist()\n",
        "\n",
        "    def error(self, theta, x, y):\n",
        "        y_pred = MapEvaluator.f(x, theta)\n",
        "        mse = np.sum((y - y_pred) ** 2)\n",
        "        penalty = 1e6 * np.abs(np.sum(theta[:-2]) - 1)\n",
        "        a, b = theta[-2], theta[-1]\n",
        "        if a > b: penalty += (a - b) * 1e5\n",
        "        return mse + penalty\n",
        "\n",
        "# Convierte una lista de diccionarios en una lista de tuplas\n",
        "def get_x(gpt_dicts, criteria):\n",
        "    if len(criteria) > 0:\n",
        "        return [\n",
        "            [gpt_dict[key] for key in criteria]\n",
        "            for gpt_dict in gpt_dicts\n",
        "        ]\n",
        "\n",
        "    return [[gpt_dict['score']] for gpt_dict in gpt_dicts]\n",
        "\n",
        "# Obtiene los parámetros óptimos para disminuir el error\n",
        "def optimize_params(gpt_dicts, real_scores, criteria, eval_function):\n",
        "    criteria_scores = get_x(gpt_dicts, criteria)\n",
        "    if eval_function == \"map\":\n",
        "        optimizer = MapOptimizer(criteria_scores, real_scores)\n",
        "    if eval_function == \"cuts\":\n",
        "        optimizer = CutsOptimizer(criteria_scores, real_scores)\n",
        "\n",
        "    return optimizer.params\n",
        "\n",
        "# Convierte los puntajes GPT a puntajes normalizados (0-3)\n",
        "def convert_gpt_scores(gpt_dicts, real_scores, criteria, eval_function, eval_params):\n",
        "    criteria_scores = get_x(gpt_dicts, criteria)\n",
        "    if eval_function == \"map\":\n",
        "        return MapEvaluator.f(criteria_scores, eval_params)\n",
        "    if eval_function == \"cuts\":\n",
        "        return CutsEvaluator.f(criteria_scores, eval_params)"
      ],
      "metadata": {
        "id": "9C0xfFjsE__M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt_dicts = [\n",
        "    {\n",
        "        'score': 9\n",
        "    },\n",
        "    {\n",
        "        'score': 8\n",
        "    },\n",
        "    {\n",
        "        'score': 4\n",
        "    }\n",
        "]\n",
        "\n",
        "real_scores = [3, 2, 1]\n",
        "criteria = []\n",
        "\n",
        "eval_params = optimize_params(gpt_dicts, real_scores, criteria, \"map\")\n",
        "print(eval_params)\n",
        "convert_gpt_scores(gpt_dicts, real_scores, criteria, \"map\", eval_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2v7vABfitpf",
        "outputId": "84ad7e69-6843-4ccb-ba07-15b925c47225"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.0, 4.000037881048441, 7.4999888512711514]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.60000178, 2.20000357, 0.99999053])"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt_dicts = [\n",
        "    {\n",
        "        'relevance': 8,\n",
        "        'clarity': 9,\n",
        "        'precision': 7\n",
        "    },\n",
        "    {\n",
        "        'relevance': 8,\n",
        "        'clarity': 5,\n",
        "        'precision': 3\n",
        "    },\n",
        "    {\n",
        "        'relevance': 4,\n",
        "        'clarity': 1,\n",
        "        'precision': 2\n",
        "    }\n",
        "]\n",
        "\n",
        "real_scores = [3, 2, 1]\n",
        "criteria = ['relevance', 'clarity', 'precision']\n",
        "\n",
        "eval_params = optimize_params(gpt_dicts, real_scores, criteria, \"map\")\n",
        "print(eval_params)\n",
        "convert_gpt_scores(gpt_dicts, real_scores, criteria, \"map\", eval_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qU9hjjTBQ6RI",
        "outputId": "6fe66d5b-0905-4cfa-c14b-b38453f64907"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.007063405579985471, 0.9736191598576271, 0.01931743420011689, 1.0250005164759606, 4.822870728613848]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.79801581, 2.03084424, 1.00408311])"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experimentos"
      ],
      "metadata": {
        "id": "H3mOMBM_S_QH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from GPTEvaluator.GPTEvaluator import chat_gpt_multiple\n",
        "from openai_multi_client import OpenAIMultiClient\n",
        "import openai\n",
        "from google.colab import userdata\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import os\n",
        "from datetime import datetime, timedelta\n",
        "import json\n",
        "import numpy\n",
        "\n",
        "openai.api_key = userdata.get('api_key')\n",
        "\n",
        "class SetPair():\n",
        "    def __init__(self, train_set, test_set):\n",
        "        self.train_set = train_set\n",
        "        self.test_set = test_set\n",
        "\n",
        "# Divide el dataset en conjuntos de entrenamiento/prueba\n",
        "def generate_sets(dataset, repetitions, train_set_size=60, test_set_size=100, group_size=15, seed=42):\n",
        "    sets = []\n",
        "    random.seed(seed)\n",
        "\n",
        "    group_size = train_set_size // 4\n",
        "    for i in range(repetitions):\n",
        "        train_set = dataset.groupby('real_eval', group_keys=False).apply(lambda x: x.sample(group_size, random_state=random.randint(0,100000)))\n",
        "        test_set = dataset[~dataset.index.isin(train_set.index)]\n",
        "        test_set = dataset.sample(n=test_set_size, random_state=random.randint(0,100000))\n",
        "        sets.append(SetPair(train_set, test_set))\n",
        "\n",
        "    return sets\n",
        "\n",
        "# Genera las respuestas con ChatGPT\n",
        "def eval_gpt(df, prompt):\n",
        "    api = OpenAIMultiClient(endpoint=\"chats\", data_template={\"model\": \"gpt-4o-mini\", \"temperature\": 0.1, \"n\": 1, \"timeout\":10}, concurrency=50, wait_interval=1, max_retries=3, retry_max=10, retry_multiplier=1)\n",
        "\n",
        "    texts = []\n",
        "    for i, row in df.iterrows():\n",
        "        text = prompt.format(Question=row['question'], Answer=row['answer'], Context=row['context'])\n",
        "        texts.append(text)\n",
        "\n",
        "    answers_gpt = chat_gpt_multiple(api, texts)\n",
        "    return answers_gpt\n",
        "\n",
        "# Extrae diccionario de salida de las respuestas GPT\n",
        "def extract_dicts(answers_gpt):\n",
        "    pattern = r'\\{[^{}]+\\}'\n",
        "\n",
        "    gpt_dicts = []\n",
        "    for answer_gpt in answers_gpt:\n",
        "        try:\n",
        "            answer = re.findall(pattern, answer_gpt[0])[0]\n",
        "            gpt_dicts.append(eval(answer))\n",
        "        except Exception as e:\n",
        "            print(f\"Error al extraer diccionario. Respuesta GPT: \\n{answer_gpt[0]}\\n\\n\")\n",
        "            gpt_dicts.append(None)\n",
        "\n",
        "    return gpt_dicts\n",
        "\n",
        "# Elimina filas del dataset donde hubo errores en la salida GPT\n",
        "def clean_set(dataset, gpt_dicts):\n",
        "    for i in reversed(range(len(gpt_dicts))):\n",
        "        if gpt_dicts[i] is None:\n",
        "            gpt_dicts.pop(i)\n",
        "            dataset.drop(index=i, inplace=True)\n",
        "\n",
        "# Obtiene los puntajes reales de un dataset\n",
        "def get_real_scores(dataset):\n",
        "    return dataset['real_eval'].tolist()\n",
        "\n",
        "# Prepara el set de entrenamiento y obtiene los parámetros óptimos para disminuir el error\n",
        "def train(train_set, prompt, criteria, eval_function):\n",
        "    train_set = train_set.copy()\n",
        "    answers_gpt = eval_gpt(train_set, prompt)\n",
        "    gpt_dicts = extract_dicts(answers_gpt)\n",
        "    clean_set(train_set, gpt_dicts)\n",
        "    real_scores = get_real_scores(train_set)\n",
        "    return optimize_params(gpt_dicts, real_scores, criteria, eval_function)\n",
        "\n",
        "# Prepara el set de prueba y calcula las métricas del modelo preentrenado usando el conjunto de prueba\n",
        "def test(test_set, prompt, criteria, eval_function, eval_params):\n",
        "    test_set = test_set.copy()\n",
        "    answers_gpt = eval_gpt(test_set, prompt)\n",
        "    gpt_dicts = extract_dicts(answers_gpt)\n",
        "    clean_set(test_set, gpt_dicts)\n",
        "    real_scores = get_real_scores(test_set)\n",
        "    pred_scores = convert_gpt_scores(gpt_dicts, real_scores, criteria, eval_function, eval_params)\n",
        "\n",
        "    result_set = test_set.copy(deep=True)\n",
        "    result_set['gpt_eval'] = pred_scores\n",
        "    return calculate_mse(result_set)\n",
        "\n",
        "# Retorna un dataset con el MSE por grupo\n",
        "def calculate_mse(result_set):\n",
        "    mse_dict = result_set.groupby('dataset').apply(lambda x: mean_squared_error(x['real_eval'], x['gpt_eval'])).to_dict()\n",
        "    overall_mse = mean_squared_error(result_set['real_eval'], result_set['gpt_eval'])\n",
        "    mse_dict['All'] = overall_mse\n",
        "    return mse_dict\n",
        "\n",
        "# Evalúa una lista de prompts obtienendo el MSE promedio en M repeticiones\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "def experiment(dataset, prompts, repetitions, eval_function, eval_params=None, train_set_size=60, test_set_size=100, seed=42):\n",
        "    sets = generate_sets(dataset, repetitions, train_set_size, test_set_size, seed)\n",
        "    stats = []\n",
        "\n",
        "    for i, prompt_data in enumerate(prompts):\n",
        "        prompt = prompt_data.prompt\n",
        "        criteria = prompt_data.criteria\n",
        "        stats.append([])\n",
        "\n",
        "        for j in range(repetitions):\n",
        "            train_set = sets[j].train_set\n",
        "            test_set = sets[j].test_set\n",
        "\n",
        "            iter_params = eval_params\n",
        "            if not eval_params:\n",
        "                print(f\"Entrenando Prompt {i+1} con Train Set {j+1}\")\n",
        "                iter_params = train(train_set, prompt, criteria, eval_function)\n",
        "\n",
        "            print(f\"\\nEvaluando Prompt {i+1} con Test Set {j+1}\")\n",
        "            metrics = test(test_set, prompt, criteria, eval_function, iter_params)\n",
        "            stats[i].append({\n",
        "                \"MSE\": metrics,\n",
        "                \"params\": iter_params\n",
        "            })\n",
        "            print()\n",
        "\n",
        "    filename = save_stats(prompts, stats, eval_function, train_set_size, test_set_size)\n",
        "    read_results(filename)\n",
        "\n",
        "    return stats\n",
        "\n",
        "# Guarda resultados en un archivo JSON\n",
        "def save_stats(prompts, stats, eval_function, train_set_size, test_set_size):\n",
        "    data = {\n",
        "        \"train_set_size\": train_set_size,\n",
        "        \"test_set_size\": test_set_size,\n",
        "        \"repetitions\": len(stats[0]),\n",
        "        \"results\": []\n",
        "    }\n",
        "\n",
        "    for i in range(len(stats)):\n",
        "        results = {\n",
        "            \"prompt\": prompts[i].base_structure(),\n",
        "            \"stats\": stats[i]\n",
        "        }\n",
        "        data[\"results\"].append(results)\n",
        "\n",
        "    dir = \"Results\"\n",
        "    if not os.path.exists(dir):\n",
        "        os.makedirs(dir)\n",
        "\n",
        "    date = datetime.now() - timedelta(hours=4)\n",
        "    formatted_date = date.strftime('%Y%m%d-%H%M')\n",
        "    path = f'{dir}/{formatted_date}.json'\n",
        "    with open(path, 'w', encoding='utf-8') as file:\n",
        "        json.dump(data, file, ensure_ascii=False)\n",
        "\n",
        "    return path\n",
        "\n",
        "# Lee y muestra resultados de un archivo JSON\n",
        "def read_results(path):\n",
        "    with open(path, 'r', encoding='utf-8') as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    rows = []\n",
        "    for result in data[\"results\"]:\n",
        "        for stat in result[\"stats\"]:\n",
        "            row = stat[\"MSE\"]\n",
        "            row[\"Prompt\"] = json.dumps(result[\"prompt\"])\n",
        "            rows.append(row)\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "    col = df.pop('Prompt')\n",
        "    df.insert(0, 'Prompt', col)\n",
        "    col = df.pop('All')\n",
        "    df.insert(1, 'All', col)\n",
        "\n",
        "    def std(x): return np.std(x)\n",
        "    df_mean = df.groupby('Prompt', as_index=False).mean().reset_index(drop=True)\n",
        "    df_std = df.groupby('Prompt', as_index=False).agg(std).reset_index(drop=True)\n",
        "\n",
        "    print(\"\\nTabla Promedio MSE\")\n",
        "    display(df_mean)\n",
        "    print(\"\\nTabla Desviación estándar\")\n",
        "    display(df_std)"
      ],
      "metadata": {
        "id": "iXoEKV3qzn0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = experiment(df, prompts, repetitions=2, eval_function=\"map\", eval_params=None, train_set_size=20, test_set_size=40, seed=42)"
      ],
      "metadata": {
        "id": "eoxYTKmiNLrL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7ee50f71-49aa-4b96-a865-0ad6813a76aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrenando Prompt 1 con Train Set 1\n",
            "10-15-8-5-0-4-13-3-18-2-17-14-1-9-16-7-6-12-11-19-\n",
            "Evaluando Prompt 1 con Test Set 1\n",
            "4-33-36-38-3-31-35-21-37-27-23-13-0-32-1-2-20-24-17-6-11-5-8-34-30-39-28-7-9-29-22-12-10-19-16-26-25-18-"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:openai_multi_client:Error processing Payload(endpoint='chats', data={'model': 'gpt-4o-mini', 'temperature': 0.1, 'n': 1, 'timeout': 10, 'messages': [{'role': 'user', 'content': '**Examples:**\\nQ: ¿Cómo se podría implementar un historial de navegación web usando dos pilas? El historial debe permitir ir hacia atrás y adelante con las páginas previamente visitadas. Describa un algoritmo.\\nIncorrect Answer: Usamos dos pilas para ir hacia adelante y hacia atrás en el historial.  (Score: 0)\\n\\nQ: ¿Cómo se busca un valor en un árbol rojo-negro? Explique el proceso paso a paso.\\nIncorrect Answer: PAra buscar el valor en un árbol rojo-negro debemos pasar por nodos rojos y negros hasta encontrar el valor. (Score: 0)\\n\\nQ: ¿Por qué el acceso a un elemento específico en un arreglo es O(1), es decir, no depende de la cantidad de datos?\\nIncorrect Answer: El acceso es O(1) por que toma un tiempo constante y no depende de la cantidad de datos. (Score: 0)\\n\\nQ: ¿Cuando se recomienda utilizar arreglos en vez de listas enlazadas? Haga referencia a complejidades temporales en su explicación.\\nIncorrect Answer: Un arreglo es recomendable en determinadas situaciones, mientras que la lista enlazada en otras.\\nFeedback: La respuesta del estudiante es incorrecta ya que no proporciona información nueva y simplemente reformula la pregunta sin agregar profundidad o claridad. (Score: 0)\\n\\n**Knowledge:** Las operaciones en un árbol binario son en general más lentas que en una tabla hash porque las operaciones en un árbol binario (inserción, búsqueda y eliminación) tienen una complejidad de O(log n) en el mejor de los casos (con un árbol balanceado). En contraste, las tablas hash están diseñadas para realizar estas operaciones en tiempo promedio O(1). Esto se debe a que las tablas hash utilizan una función hash para acceder directamente a la ubicación de un elemento, mientras que los árboles binarios requieren comparaciones en cada nivel del árbol.\\n\\n\\n**Question:** ¿Por qué las operaciones en un árbol binario son en general más lentas que en una tabla hash?\\n\\n**Student\\'s Answer:** Porque en una tabla hash se puede acceder directamente al valor buscado, por lo que tiene una complejidad o(1), en cambio en un árbol binario se tiene que recorrer los diferentes nodos y comparando valores hasta dar con el valor buscado, haciendo mas tardío el proceso de búsqueda, por lo que tendría complejidad o(log(n))\\n\\nInstructions:\\n(analysis)\\nAnalyse the \"Student\\'s Answer\".\\nStart by paraphrasing the answer in detail and commenting each sentence.\\nIt rewrites the same information provided in the question? or It correctly answers the question providing relevant and deep new information?\\nIt is complete, that is, answers all the questions?\\nUse the Knowledge as a reference to validate the accuracy and relevance of the student\\'s response.\\nFocus on the alignment between the question asked and the answer provided.\\n\\n\\n(feedback)\\nProvide Feedback to the student considering the analysis. **Do not be strict at all**.\\nIt is enough that the student answer correctly and more or less completely the question. **Do not ask for additional information**.\\nStart by stating whether the answer is good/excelent or poor/insatisfactory.\\nIf the answer is good/excelent, affirm the student\\'s understanding and potentially add a brief note on why their response was particularly effective or comprehensive.\\nIf the answer is poor/insatisfactory, clearly identify the inaccuracies or errors. Provide specific suggestions on how to improve, ensuring the feedback is constructive.\\nWithin 150 words. In Spanish.\\n\\n(score) Assign a score between 0 and 10 to different criteria based on the student\\'s answer and the generated feedback. Criteria are: correctness, completeness, clarity.\\n\\nI expect a dict in python as answer: {\"analysis\": \\'La respuesta del estudiante dice que...\\', \"feedback\": \\'very detailed feedback considering previous analysis (in spanish, within 150 words)\\', \"correctness\": correctness_score, \"completeness\": completeness_score, \"clarity\": clarity_score}\\n\\nPython dict:'}]}, metadata={'index': 14}, max_retries=3, retry_multiplier=1, retry_max=10, attempt=1, failed=False, response=None, callback=None)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai_multi_client/__init__.py\", line 111, in _worker\n",
            "    payload = await self._process_payload(payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai_multi_client/__init__.py\", line 81, in _process_payload\n",
            "    payload.response = await openai.ChatCompletion.acreate(**payload.data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_resources/chat_completion.py\", line 45, in acreate\n",
            "    return await super().acreate(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\", line 217, in acreate\n",
            "    response, _, api_key = await requestor.arequest(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 382, in arequest\n",
            "    resp, got_stream = await self._interpret_async_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 728, in _interpret_async_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
            "    raise self.handle_error_response(\n",
            "openai.error.APIError: Internal server error {\n",
            "    \"error\": {\n",
            "        \"message\": \"Internal server error\",\n",
            "        \"type\": \"auth_subrequest_error\",\n",
            "        \"param\": null,\n",
            "        \"code\": \"internal_error\"\n",
            "    }\n",
            "}\n",
            " 500 {'error': {'message': 'Internal server error', 'type': 'auth_subrequest_error', 'param': None, 'code': 'internal_error'}} <CIMultiDictProxy('Date': 'Wed, 07 Aug 2024 03:46:59 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Content-Length': '166', 'Connection': 'keep-alive', 'Vary': 'Origin', 'x-request-id': 'req_0d9b27552bb0f564c2c91189b0a9e765', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'CF-Cache-Status': 'DYNAMIC', 'Set-Cookie': '__cf_bm=4LJdNI2rW9eRnZTLTgpY3zgPEQ65yMXJMtJkpYHd..s-1723002419-1.0.1.1-uA_D_DRmHxVYVsab4T0mpi9WQpXakG.kV6VU7qZ6y_WiexrTTWFS0HiBYw6EhnoBLxUebO.z4gestoi6hliEkQ; path=/; expires=Wed, 07-Aug-24 04:16:59 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None', 'X-Content-Type-Options': 'nosniff', 'Set-Cookie': '_cfuvid=LtUeBj6I1mKNYxshV6fGV49q1wpglvBzluV7m5ZS6dk-1723002419016-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None', 'Server': 'cloudflare', 'CF-RAY': '8af4483de93f578e-IAD', 'alt-svc': 'h3=\":443\"; ma=86400')>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15-14-\n",
            "Entrenando Prompt 1 con Train Set 2\n",
            "15-6-11-2-0-16-17-4-1-3-19-8-10-18-9-13-14-"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:openai_multi_client:Error processing Payload(endpoint='chats', data={'model': 'gpt-4o-mini', 'temperature': 0.1, 'n': 1, 'timeout': 10, 'messages': [{'role': 'user', 'content': '**Examples:**\\nQ: ¿Cómo se podría implementar un historial de navegación web usando dos pilas? El historial debe permitir ir hacia atrás y adelante con las páginas previamente visitadas. Describa un algoritmo.\\nIncorrect Answer: Usamos dos pilas para ir hacia adelante y hacia atrás en el historial.  (Score: 0)\\n\\nQ: ¿Cómo se busca un valor en un árbol rojo-negro? Explique el proceso paso a paso.\\nIncorrect Answer: PAra buscar el valor en un árbol rojo-negro debemos pasar por nodos rojos y negros hasta encontrar el valor. (Score: 0)\\n\\nQ: ¿Por qué el acceso a un elemento específico en un arreglo es O(1), es decir, no depende de la cantidad de datos?\\nIncorrect Answer: El acceso es O(1) por que toma un tiempo constante y no depende de la cantidad de datos. (Score: 0)\\n\\nQ: ¿Cuando se recomienda utilizar arreglos en vez de listas enlazadas? Haga referencia a complejidades temporales en su explicación.\\nIncorrect Answer: Un arreglo es recomendable en determinadas situaciones, mientras que la lista enlazada en otras.\\nFeedback: La respuesta del estudiante es incorrecta ya que no proporciona información nueva y simplemente reformula la pregunta sin agregar profundidad o claridad. (Score: 0)\\n\\n**Knowledge:** Los árboles AVL son considerados más rápidos que los árboles rojo-negro en términos de búsqueda debido a su balance más estricto. Un árbol AVL mantiene un factor de balanceo de -1, 0 o +1 en todos los nodos, lo que significa que el árbol es más plano en comparación con los árboles rojo-negro. Esta rigurosidad en el balance asegura que la distancia máxima desde la raíz hasta cualquier hoja (la altura del árbol) sea mínima e igual a 1.44 log n, lo que puede resultar en búsquedas más rápidas, especialmente cuando se realizan muchas operaciones de búsqueda.\\n\\n\\n**Question:** ¿Por qué se dice que los árboles AVL son más rápidos que los árboles rojo-negro en términos de búsqueda? Explique en profundidad.\\n\\n**Student\\'s Answer:** Los arboles AVL son mas rapidos que los arboles rojo negro ya que los arboles Abl son mas rigidos estructuralmente por lo que dificulta la busqueda de sus elementos porque a la vez estara haciendo balanceos constantemente a diferencia del arbol rojo negro que no estan estricto como el avl\\n\\nInstructions:\\n(analysis)\\nAnalyse the \"Student\\'s Answer\".\\nStart by paraphrasing the answer in detail and commenting each sentence.\\nIt rewrites the same information provided in the question? or It correctly answers the question providing relevant and deep new information?\\nIt is complete, that is, answers all the questions?\\nUse the Knowledge as a reference to validate the accuracy and relevance of the student\\'s response.\\nFocus on the alignment between the question asked and the answer provided.\\n\\n\\n(feedback)\\nProvide Feedback to the student considering the analysis. **Do not be strict at all**.\\nIt is enough that the student answer correctly and more or less completely the question. **Do not ask for additional information**.\\nStart by stating whether the answer is good/excelent or poor/insatisfactory.\\nIf the answer is good/excelent, affirm the student\\'s understanding and potentially add a brief note on why their response was particularly effective or comprehensive.\\nIf the answer is poor/insatisfactory, clearly identify the inaccuracies or errors. Provide specific suggestions on how to improve, ensuring the feedback is constructive.\\nWithin 150 words. In Spanish.\\n\\n(score) Assign a score between 0 and 10 to different criteria based on the student\\'s answer and the generated feedback. Criteria are: correctness, completeness, clarity.\\n\\nI expect a dict in python as answer: {\"analysis\": \\'La respuesta del estudiante dice que...\\', \"feedback\": \\'very detailed feedback considering previous analysis (in spanish, within 150 words)\\', \"correctness\": correctness_score, \"completeness\": completeness_score, \"clarity\": clarity_score}\\n\\nPython dict:'}]}, metadata={'index': 5}, max_retries=3, retry_multiplier=1, retry_max=10, attempt=1, failed=False, response=None, callback=None)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai_multi_client/__init__.py\", line 111, in _worker\n",
            "    payload = await self._process_payload(payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai_multi_client/__init__.py\", line 81, in _process_payload\n",
            "    payload.response = await openai.ChatCompletion.acreate(**payload.data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_resources/chat_completion.py\", line 45, in acreate\n",
            "    return await super().acreate(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\", line 217, in acreate\n",
            "    response, _, api_key = await requestor.arequest(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 382, in arequest\n",
            "    resp, got_stream = await self._interpret_async_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 728, in _interpret_async_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 765, in _interpret_response_line\n",
            "    raise self.handle_error_response(\n",
            "openai.error.APIError: Internal server error {\n",
            "    \"error\": {\n",
            "        \"message\": \"Internal server error\",\n",
            "        \"type\": \"auth_subrequest_error\",\n",
            "        \"param\": null,\n",
            "        \"code\": \"internal_error\"\n",
            "    }\n",
            "}\n",
            " 500 {'error': {'message': 'Internal server error', 'type': 'auth_subrequest_error', 'param': None, 'code': 'internal_error'}} <CIMultiDictProxy('Date': 'Wed, 07 Aug 2024 03:47:10 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Content-Length': '166', 'Connection': 'keep-alive', 'Vary': 'Origin', 'x-request-id': 'req_09c5e19bf120563247ff096c91db589e', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'CF-Cache-Status': 'DYNAMIC', 'Set-Cookie': '__cf_bm=KmbuYCnXaj0ayk5.C6UW5U8s96TpSF6Z.EWOSHaVHEg-1723002430-1.0.1.1-gD.lLCt7ZJlZDXKNy7kVFy432VZZlsk4rLEUDR9FXEqJhvri0eCz6iwUPM.q12_hEHGXYQxz54mVHgj2GCY4TA; path=/; expires=Wed, 07-Aug-24 04:17:10 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None', 'X-Content-Type-Options': 'nosniff', 'Set-Cookie': '_cfuvid=Cu8f.3w.dGrDMZTmeuCUPyE5wxs8mXaRO9hiBderzeI-1723002430414-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None', 'Server': 'cloudflare', 'CF-RAY': '8af4487f6ab72431-IAD', 'alt-svc': 'h3=\":443\"; ma=86400')>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7-12-5-\n",
            "Evaluando Prompt 1 con Test Set 2\n",
            "0-7-34-2-16-22-35-36-8-3-5-12-30-19-23-26-1-15-18-39-38-13-31-4-37-17-25-9-21-11-33-24-10-29-28-27-20-6-14-32-\n",
            "\n",
            "Tabla Promedio MSE\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                                                                                                                                                                                       Prompt  \\\n",
              "0  {\"examples\": \"examples_1.txt\", \"context\": \"knowledge_1.txt\", \"question\": \"question_1.txt\", \"answer\": \"answer_1.txt\", \"instructions\": {\"analysis\": \"analysis_1.txt\", \"feedback\": \"feedback_1.txt\", \"score\": \"score_1.txt\"}}   \n",
              "\n",
              "       All  C1-OscarBadAnswers20   C2-Nan  C2-Sample100  C3-Sample100  \n",
              "0  0.87596              1.512279  0.73201      1.111855       0.64353  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d5d00d43-9d9a-42e2-ab56-990c5d4212d1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prompt</th>\n",
              "      <th>All</th>\n",
              "      <th>C1-OscarBadAnswers20</th>\n",
              "      <th>C2-Nan</th>\n",
              "      <th>C2-Sample100</th>\n",
              "      <th>C3-Sample100</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{\"examples\": \"examples_1.txt\", \"context\": \"knowledge_1.txt\", \"question\": \"question_1.txt\", \"answer\": \"answer_1.txt\", \"instructions\": {\"analysis\": \"analysis_1.txt\", \"feedback\": \"feedback_1.txt\", \"score\": \"score_1.txt\"}}</td>\n",
              "      <td>0.87596</td>\n",
              "      <td>1.512279</td>\n",
              "      <td>0.73201</td>\n",
              "      <td>1.111855</td>\n",
              "      <td>0.64353</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d5d00d43-9d9a-42e2-ab56-990c5d4212d1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d5d00d43-9d9a-42e2-ab56-990c5d4212d1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d5d00d43-9d9a-42e2-ab56-990c5d4212d1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"x = experiment(df, prompts, repetitions=2, eval_function=\\\"map\\\", eval_params=None, train_set_size=20, test_set_size=40, seed=42)\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"{\\\"examples\\\": \\\"examples_1.txt\\\", \\\"context\\\": \\\"knowledge_1.txt\\\", \\\"question\\\": \\\"question_1.txt\\\", \\\"answer\\\": \\\"answer_1.txt\\\", \\\"instructions\\\": {\\\"analysis\\\": \\\"analysis_1.txt\\\", \\\"feedback\\\": \\\"feedback_1.txt\\\", \\\"score\\\": \\\"score_1.txt\\\"}}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"All\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.875960021481649,\n        \"max\": 0.875960021481649,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.875960021481649\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"C1-OscarBadAnswers20\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.512279462328899,\n        \"max\": 1.512279462328899,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.512279462328899\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"C2-Nan\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.7320096975477474,\n        \"max\": 0.7320096975477474,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.7320096975477474\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"C2-Sample100\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.1118546719012232,\n        \"max\": 1.1118546719012232,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.1118546719012232\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"C3-Sample100\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.6435304567665681,\n        \"max\": 0.6435304567665681,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6435304567665681\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tabla Desviación estándar\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                                                                                                                                                                                       Prompt  \\\n",
              "0  {\"examples\": \"examples_1.txt\", \"context\": \"knowledge_1.txt\", \"question\": \"question_1.txt\", \"answer\": \"answer_1.txt\", \"instructions\": {\"analysis\": \"analysis_1.txt\", \"feedback\": \"feedback_1.txt\", \"score\": \"score_1.txt\"}}   \n",
              "\n",
              "        All  C1-OscarBadAnswers20    C2-Nan  C2-Sample100  C3-Sample100  \n",
              "0  0.095144              0.667108  0.255411       0.14933      0.358255  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cb42fbb1-ea81-4577-9f37-899d5492c74c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prompt</th>\n",
              "      <th>All</th>\n",
              "      <th>C1-OscarBadAnswers20</th>\n",
              "      <th>C2-Nan</th>\n",
              "      <th>C2-Sample100</th>\n",
              "      <th>C3-Sample100</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{\"examples\": \"examples_1.txt\", \"context\": \"knowledge_1.txt\", \"question\": \"question_1.txt\", \"answer\": \"answer_1.txt\", \"instructions\": {\"analysis\": \"analysis_1.txt\", \"feedback\": \"feedback_1.txt\", \"score\": \"score_1.txt\"}}</td>\n",
              "      <td>0.095144</td>\n",
              "      <td>0.667108</td>\n",
              "      <td>0.255411</td>\n",
              "      <td>0.14933</td>\n",
              "      <td>0.358255</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cb42fbb1-ea81-4577-9f37-899d5492c74c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cb42fbb1-ea81-4577-9f37-899d5492c74c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cb42fbb1-ea81-4577-9f37-899d5492c74c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"x = experiment(df, prompts, repetitions=2, eval_function=\\\"map\\\", eval_params=None, train_set_size=20, test_set_size=40, seed=42)\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"{\\\"examples\\\": \\\"examples_1.txt\\\", \\\"context\\\": \\\"knowledge_1.txt\\\", \\\"question\\\": \\\"question_1.txt\\\", \\\"answer\\\": \\\"answer_1.txt\\\", \\\"instructions\\\": {\\\"analysis\\\": \\\"analysis_1.txt\\\", \\\"feedback\\\": \\\"feedback_1.txt\\\", \\\"score\\\": \\\"score_1.txt\\\"}}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"All\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.09514391493996799,\n        \"max\": 0.09514391493996799,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.09514391493996799\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"C1-OscarBadAnswers20\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.6671079246295996,\n        \"max\": 0.6671079246295996,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6671079246295996\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"C2-Nan\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.25541129767947807,\n        \"max\": 0.25541129767947807,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.25541129767947807\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"C2-Sample100\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.14933004090319468,\n        \"max\": 0.14933004090319468,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.14933004090319468\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"C3-Sample100\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.35825530355995155,\n        \"max\": 0.35825530355995155,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.35825530355995155\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "read_results(\"Results/20240806-2347.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "5nCG2Gktn73M",
        "outputId": "107aff5a-a384-4435-dc84-2f97cb900058"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tabla Promedio MSE\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                                                                                                                                                                                       Prompt  \\\n",
              "0  {\"examples\": \"examples_1.txt\", \"context\": \"knowledge_1.txt\", \"question\": \"question_1.txt\", \"answer\": \"answer_1.txt\", \"instructions\": {\"analysis\": \"analysis_1.txt\", \"feedback\": \"feedback_1.txt\", \"score\": \"score_1.txt\"}}   \n",
              "\n",
              "       All  C1-OscarBadAnswers20   C2-Nan  C2-Sample100  C3-Sample100  \n",
              "0  0.87596              1.512279  0.73201      1.111855       0.64353  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1678a2d4-c9db-4368-9f16-07c16c1b019f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prompt</th>\n",
              "      <th>All</th>\n",
              "      <th>C1-OscarBadAnswers20</th>\n",
              "      <th>C2-Nan</th>\n",
              "      <th>C2-Sample100</th>\n",
              "      <th>C3-Sample100</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{\"examples\": \"examples_1.txt\", \"context\": \"knowledge_1.txt\", \"question\": \"question_1.txt\", \"answer\": \"answer_1.txt\", \"instructions\": {\"analysis\": \"analysis_1.txt\", \"feedback\": \"feedback_1.txt\", \"score\": \"score_1.txt\"}}</td>\n",
              "      <td>0.87596</td>\n",
              "      <td>1.512279</td>\n",
              "      <td>0.73201</td>\n",
              "      <td>1.111855</td>\n",
              "      <td>0.64353</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1678a2d4-c9db-4368-9f16-07c16c1b019f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1678a2d4-c9db-4368-9f16-07c16c1b019f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1678a2d4-c9db-4368-9f16-07c16c1b019f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"read_results(\\\"Results/20240806-2347\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"{\\\"examples\\\": \\\"examples_1.txt\\\", \\\"context\\\": \\\"knowledge_1.txt\\\", \\\"question\\\": \\\"question_1.txt\\\", \\\"answer\\\": \\\"answer_1.txt\\\", \\\"instructions\\\": {\\\"analysis\\\": \\\"analysis_1.txt\\\", \\\"feedback\\\": \\\"feedback_1.txt\\\", \\\"score\\\": \\\"score_1.txt\\\"}}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"All\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.875960021481649,\n        \"max\": 0.875960021481649,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.875960021481649\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"C1-OscarBadAnswers20\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.512279462328899,\n        \"max\": 1.512279462328899,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.512279462328899\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"C2-Nan\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.7320096975477474,\n        \"max\": 0.7320096975477474,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.7320096975477474\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"C2-Sample100\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.1118546719012232,\n        \"max\": 1.1118546719012232,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.1118546719012232\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"C3-Sample100\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.6435304567665681,\n        \"max\": 0.6435304567665681,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6435304567665681\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tabla Desviación estándar\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                                                                                                                                                                                       Prompt  \\\n",
              "0  {\"examples\": \"examples_1.txt\", \"context\": \"knowledge_1.txt\", \"question\": \"question_1.txt\", \"answer\": \"answer_1.txt\", \"instructions\": {\"analysis\": \"analysis_1.txt\", \"feedback\": \"feedback_1.txt\", \"score\": \"score_1.txt\"}}   \n",
              "\n",
              "        All  C1-OscarBadAnswers20    C2-Nan  C2-Sample100  C3-Sample100  \n",
              "0  0.095144              0.667108  0.255411       0.14933      0.358255  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9332d086-29b7-471d-9a53-7c0045aac5f7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prompt</th>\n",
              "      <th>All</th>\n",
              "      <th>C1-OscarBadAnswers20</th>\n",
              "      <th>C2-Nan</th>\n",
              "      <th>C2-Sample100</th>\n",
              "      <th>C3-Sample100</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{\"examples\": \"examples_1.txt\", \"context\": \"knowledge_1.txt\", \"question\": \"question_1.txt\", \"answer\": \"answer_1.txt\", \"instructions\": {\"analysis\": \"analysis_1.txt\", \"feedback\": \"feedback_1.txt\", \"score\": \"score_1.txt\"}}</td>\n",
              "      <td>0.095144</td>\n",
              "      <td>0.667108</td>\n",
              "      <td>0.255411</td>\n",
              "      <td>0.14933</td>\n",
              "      <td>0.358255</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9332d086-29b7-471d-9a53-7c0045aac5f7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9332d086-29b7-471d-9a53-7c0045aac5f7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9332d086-29b7-471d-9a53-7c0045aac5f7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"read_results(\\\"Results/20240806-2347\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"{\\\"examples\\\": \\\"examples_1.txt\\\", \\\"context\\\": \\\"knowledge_1.txt\\\", \\\"question\\\": \\\"question_1.txt\\\", \\\"answer\\\": \\\"answer_1.txt\\\", \\\"instructions\\\": {\\\"analysis\\\": \\\"analysis_1.txt\\\", \\\"feedback\\\": \\\"feedback_1.txt\\\", \\\"score\\\": \\\"score_1.txt\\\"}}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"All\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.09514391493996799,\n        \"max\": 0.09514391493996799,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.09514391493996799\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"C1-OscarBadAnswers20\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.6671079246295996,\n        \"max\": 0.6671079246295996,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6671079246295996\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"C2-Nan\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.25541129767947807,\n        \"max\": 0.25541129767947807,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.25541129767947807\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"C2-Sample100\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.14933004090319468,\n        \"max\": 0.14933004090319468,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.14933004090319468\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"C3-Sample100\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.35825530355995155,\n        \"max\": 0.35825530355995155,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.35825530355995155\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}