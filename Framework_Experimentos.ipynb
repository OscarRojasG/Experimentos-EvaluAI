{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPoEJxCz3fqFkbXVDFIfn7U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OscarRojasG/Experimentos-GPTValidator/blob/main/Framework_Experimentos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Framework para experimentos GPTValidator"
      ],
      "metadata": {
        "id": "wAu6OvJu7hBs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El objetivo de este framework consiste en proporcionar un conjunto de funciones previamente implementadas para facilitar la evaluación y comparación de prompts para el proyecto EvaluAI."
      ],
      "metadata": {
        "id": "3ixHfITmnzVF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instrucciones de uso"
      ],
      "metadata": {
        "id": "NtGhcZhln18k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para la utilización del framework, se deben ejecutar **todas** las celdas de código. Una vez hecho esto, se creará una carpeta llamada **Experiments** con la siguiente estructura interna:\n",
        "\n",
        "```\n",
        "Experiments/\n",
        "├── Datasets\n",
        "├── Miniprompts\n",
        "│   ├── Ejemplos\n",
        "│   ├── Contexto\n",
        "│   ├── Pregunta\n",
        "│   ├── Respuesta\n",
        "│   ├── Criteria\n",
        "│   ├── Reflection\n",
        "│   └── Feedback\n",
        "└── Results\n",
        "```\n",
        "\n",
        "**Datasets**: Contiene datasets en formato *xlsx* con las siguientes columnas:\n",
        "\n",
        "* Pregunta\n",
        "* Respuesta real o contexto\n",
        "* Respuesta del estudiante\n",
        "* Evaluación manual (puntaje 0-3)\n",
        "\n",
        "**Miniprompts**: Cada prompt se construye en base a una serie de miniprompts previamente definidos. Estos miniprompts deben ir en formato *txt* dentro de la carpeta correspondiente. Se pueden usar los strings `{context}`, `{question}` y `{answer}` como *placeholders* para reemplazar el contexto, la pregunta y la respuesta del estudiante respectivamente.\n",
        "\n",
        "**Results**: Resultados de los experimentos en formato *json*."
      ],
      "metadata": {
        "id": "MgIgM8i5-UDB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Funciones"
      ],
      "metadata": {
        "id": "dH2Qj0lirV-n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experiment\n",
        "\n",
        "`\n",
        "experiment(dataset, sheet_name, column_data, prompt_data, criteria, repetitions, eval_function, eval_params=None)\n",
        "`\n",
        "\n",
        "Evalúa un prompt a partir de un dataset y retorna las métricas de evaluación.\n",
        "\n",
        "Parámetros:\n",
        "\n",
        "- **dataset** - Nombre del archivo xlsx con el dataset a utilizar.\n",
        "\n",
        "- **sheet_name** - Nombre de la hoja donde se encuentran los datos.\n",
        "\n",
        "- **column_data** - Diccionario para asociar las columnas obligatorias del dataset (clave) con su nombre real (valor). Debe tener las siguientes claves: *question*, *context*, *answer*, *real_eval*.\n",
        "\n",
        "- **prompt_data** - Diccionario para especificar la estructura del prompt. Las claves almacenan el nombre del miniprompt al cual se hace referencia, por ejemplo, *examples*, *context*. El valor de cada clave corresponde al archivo *txt* donde se define el miniprompt a utilizar y que se encuentra en la carpeta del miniprompt correspondiente. La clave reservada *instructions* contiene un diccionario anidado donde se definen los miniprompts para las instrucciones del modelo (reflection, feedback, score).\n",
        "<br>Se puede cambiar el orden de las claves y agregar o quitar miniprompts según sea necesario. Además, se puede usar el comodín \\* como valor para evaluar todos los miniprompts que existan dentro de la carpeta.\n",
        "\n",
        "- **criteria** - Lista con los criterios a evaluar, por ejemplo, *correctness*, *completeness*, *clarity*.\n",
        "\n",
        "- **repetitions** - Cantidad de veces a repetir el experimento.\n",
        "\n",
        "- **eval_function** - Método a utilizar para calcular los puntajes finales obtenidos por GPT. Puede ser *cuts* o *map*.\n",
        "\n",
        " - *cuts* pondera cada criterio y retorna valores discretos entre 0 y 3 dependiendo de los puntajes de corte.\n",
        " - *map* pondera cada criterio y mapea los puntajes a valores continuos entre 0 y 3.\n",
        "\n",
        "- **eval_params** *(opcional)* - Lista con los parámetros a utilizar para el método *eval_function* elegido. Si es *None*, se calculan automáticamente los parámetros óptimos que minimicen el MSE. Dependiendo de *eval_function*, las listas deben contener los siguientes parámetros en orden:\n",
        "\n",
        " - *cuts* - $[w_1, w_2, ..., w_m, a, b, c]$ - donde $w_i$ corresponde a la ponderación del criterio $i$ especificado en la lista *criteria*, mientras que $a$, $b$ y $c$ son los puntajes de corte ordenados de menor a mayor.\n",
        "\n",
        " - *map* - $[w_1, w_2, ..., w_m, a, b]$ - donde $w_i$ corresponde a la ponderación del criterio $i$ especificado en la lista *criteria*, $a$ es el puntaje 0-10 equivalente a 1 en escala 0-3, $b$ es el puntaje 0-10 equivalente a 2 en escala 0-3.\n",
        "\n",
        "\n",
        "### visualize_prompt\n",
        "\n",
        "`\n",
        "visualize_prompt(prompt_data)\n",
        "`\n",
        "\n",
        "Permite previsualizar un prompt antes de un experimento.\n",
        "\n",
        "Parámetros:\n",
        "\n",
        "- **prompt_data** - Diccionario para especificar la estructura del prompt.\n",
        "\n",
        "\n",
        "### show_results\n",
        "\n",
        "`\n",
        "show_results(dir)\n",
        "`\n",
        "\n",
        "Imprime los resultados de un experimento previamente realizado.\n",
        "\n",
        "Parámetros:\n",
        "\n",
        "* **dir** - Ruta a la carpeta con los datos del experimento, por ejemplo, *Experiments/Results/20240622-1520*\n",
        "\n",
        "### download\n",
        "\n",
        "`\n",
        "download()\n",
        "`\n",
        "\n",
        "Descarga la carpeta con los experimentos. Debe encontrarse en la raíz del proyecto con el nombre \"Experiments\".\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrzhdxHQrB9x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resultados"
      ],
      "metadata": {
        "id": "xllXckDhyBhF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los resultados de los experimentos se guardarán en la carpeta *Experiments/Results*. Cada experimento estará asociado a una carpeta identificada por la fecha de ejecución del experimento. Dentro de ella, se encuentran las estadísticas obtenidas en formato *json* para cada uno de los prompts evaluados.\n",
        "\n",
        "```\n",
        "Experiments\n",
        "└── Results\n",
        "    └── 20240723-1328\n",
        "        ├── examples_1.json\n",
        "        ├── examples_2.json\n",
        "        └── examples_3.json\n",
        "```\n",
        "\n",
        "En caso de usar el comodín * en el diccionario *prompt_data*, el nombre de cada archivo corresponderá al miniprompt utilizado para ese prompt en particular. En caso contrario, la carpeta contendrá un único archivo con el nombre de *results.json*\n",
        "\n",
        "Cada archivo *json* presentará una estructura como la del siguiente ejemplo:\n",
        "\n",
        "```\n",
        "{\n",
        "    \"filename\": \"datasets.xlsx\",\n",
        "    \"sheet_name\": \"Control3-2024\",\n",
        "    \"dataset_size\": 100,\n",
        "    \"prompt\": \"Examples: ... Context: ... Question: ... Answer: ... Instructions: ...\",\n",
        "    \"field\": \"examples\",\n",
        "    \"field_id\": \"examples_1.json\",\n",
        "    \"eval_function\": \"map\",\n",
        "    \"results\" [\n",
        "        {\n",
        "            \"real_scores\": [0, 2, 1, 2, ..., 3],\n",
        "            \"gpt_scores\": [0.54, 1.57, 1.13, 1.55, ..., 2.67],\n",
        "            \"sample_size\": 99,\n",
        "            \"params\": {\n",
        "                \"weights\": {\n",
        "                    \"correctness\": 0.53,\n",
        "                    \"completeness\": 0.22,\n",
        "                    \"clarity\": 0.25\n",
        "                }\n",
        "                \"a\": 5.42,\n",
        "                \"b\": 7.24\n",
        "            },\n",
        "            \"stats\": {\n",
        "                \"mse\": 0.89,\n",
        "                \"mae\": 0.77,\n",
        "                \"r2\": 0.78\n",
        "            }\n",
        "        },\n",
        "        ...\n",
        "        {\n",
        "            ...\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "```\n",
        "\n",
        "### Descripción de los campos\n",
        "\n",
        "* **filename** - Nombre del archivo xlsx.\n",
        "* **sheet_name** - Nombre de la hoja utilizada.\n",
        "* **dataset_size** - Tamaño real del dataset.\n",
        "* **prompt** - Prompt final utilizado.\n",
        "* **field** - Miniprompt sin especificar (comodín)\n",
        "* **field_id** - Archivo utilizado para reemplazar el comodín.\n",
        "* **eval_function** - Función utilizada para optimizar los puntajes.\n",
        "* **results** - Lista con los datos de cada iteración.\n",
        "    * **real_scores** - Puntajes reales del dataset.\n",
        "    * **gpt_scores** - Puntajes calculados por el modelo.\n",
        "    * **sample_size** - Tamaño de la muestra final. Generalmente es igual a *dataset_size* a no ser que ocurran errores al procesar algunas respuestas de la API (errores en la generación del output/diccionario).\n",
        "    * **params** - Parámetros asociados a la función de evaluación (map/cuts).\n",
        "    * **stats** - Métricas de evaluación del prompt. Estas son: MAE, MSE y R². Para la función de evaluación *cuts* se añade la exactitud (accuracy) y la matriz de confusión."
      ],
      "metadata": {
        "id": "M7KaPolCyDHl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementación"
      ],
      "metadata": {
        "id": "VKJVfoXg2Qu_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28 &> /dev/null\n",
        "!pip install openai-multi-client &> /dev/null\n",
        "!git clone https://github.com/rilianx/GPTEvaluator &> /dev/null"
      ],
      "metadata": {
        "id": "Lb7AtYXA7QVg"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.optimize import differential_evolution\n",
        "import numpy as np\n",
        "\n",
        "gpt_dicts = [\n",
        "    {\n",
        "        'relevance': 10,\n",
        "        'clarity': 8,\n",
        "        'precision': 7\n",
        "    },\n",
        "    {\n",
        "        'relevance': 3,\n",
        "        'clarity': 6,\n",
        "        'precision': 4\n",
        "    }\n",
        "]\n",
        "\n",
        "real_scores = [3, 2]\n",
        "criteria = ['relevance', 'clarity', 'precision']\n",
        "\n",
        "class Optimizer():\n",
        "    def __init__(self, gpt_dicts, real_scores, criteria):\n",
        "        self.gpt_dicts = gpt_dicts\n",
        "        self.real_scores = real_scores\n",
        "        self.criteria = criteria\n",
        "\n",
        "    def get_x(self):\n",
        "        return [\n",
        "            [gpt_dict[key] for key in self.criteria]\n",
        "            for gpt_dict in self.gpt_dicts\n",
        "        ]\n",
        "\n",
        "    def get_weight_bounds(self):\n",
        "        return [(0, 1) for _ in range(len(self.criteria))]\n",
        "\n",
        "\n",
        "### Optimización de cortes y ponderaciones ###\n",
        "class CutsOptimizer(Optimizer):\n",
        "    def __init__(self, gpt_dicts, real_scores, criteria, eval_params):\n",
        "        super().__init__(gpt_dicts, real_scores, criteria)\n",
        "\n",
        "        if eval_params == None:\n",
        "            bounds = self.get_weight_bounds() + [(1, 4), (4, 7), (7, 10)]\n",
        "            result = differential_evolution(self.error, bounds, args=(self.get_x(), real_scores), seed=1, strategy='rand1exp', mutation=(0,1), recombination=1)\n",
        "            self.params = result.x.tolist()\n",
        "        else:\n",
        "            self.params = eval_params\n",
        "\n",
        "    def f(self, x, theta):\n",
        "        score = np.dot(x, theta[:-3])\n",
        "        y_pred = np.where(score > theta[-1], 3, np.where(score > theta[-2], 2, np.where(score > theta[-3], 1, 0)))\n",
        "        return y_pred\n",
        "\n",
        "    def error(self, theta, x, y):\n",
        "        y_pred = self.f(x, theta)\n",
        "        mse = np.mean((y - y_pred) ** 2)\n",
        "        penalty = 1e6 * np.abs(np.sum(theta[:-3]) - 1)\n",
        "        return mse + penalty\n",
        "\n",
        "    def get_parameters(self):\n",
        "        params = [round(p, 2) for p in self.params]\n",
        "        return {\n",
        "            \"weights\": dict(zip(criteria, params[:-2])),\n",
        "            \"cuts\": params[-3:]\n",
        "        }\n",
        "\n",
        "    def get_scores(self):\n",
        "        return self.f(self.get_x(), self.params).tolist()\n",
        "\n",
        "\n",
        "####### Optimización mapeo de puntajes ########\n",
        "class MapOptimizer(Optimizer):\n",
        "    def __init__(self, gpt_dicts, real_scores, criteria, eval_params=None):\n",
        "        super().__init__(gpt_dicts, real_scores, criteria)\n",
        "\n",
        "        if eval_params == None:\n",
        "            bounds = self.get_weight_bounds() + [(1, 9), (1, 9)]\n",
        "            result = differential_evolution(self.error, bounds, args=(self.get_x(), real_scores), seed=1, strategy='rand1exp', mutation=(0,1), recombination=1)\n",
        "            self.params = result.x.tolist()\n",
        "        else:\n",
        "            self.params = eval_params\n",
        "\n",
        "    def inverse_map(self, y_pred, theta):\n",
        "        a, b = theta[-2], theta[-1]\n",
        "        def single_inverse_map(y):\n",
        "            if y <= a:\n",
        "                return y / a\n",
        "            elif a < y <= b:\n",
        "                return 1 + (y - a) / (b - a)\n",
        "            else:\n",
        "                return min(10, 2 + (y - b) / (10 - b))\n",
        "\n",
        "        return np.array([single_inverse_map(y) for y in y_pred])\n",
        "\n",
        "    def f(self, x, theta):\n",
        "        return np.dot(x, theta[:-2])\n",
        "\n",
        "    def error(self, theta, x, y):\n",
        "        y_pred = self.f(x, theta)\n",
        "        mse = np.sum((y - self.inverse_map(y_pred, theta)) ** 2)\n",
        "        penalty = 1e6 * np.abs(np.sum(theta[:-2]) - 1)\n",
        "        a, b = theta[-2], theta[-1]\n",
        "        if a > b: penalty += (a - b) * 1e5\n",
        "        return mse + penalty\n",
        "\n",
        "    def get_parameters(self):\n",
        "        params = [round(p, 2) for p in self.params]\n",
        "        return {\n",
        "            \"weights\": dict(zip(self.criteria, params[:-2])),\n",
        "            \"a\": params[-2],\n",
        "            \"b\": params[-1]\n",
        "        }\n",
        "\n",
        "    def get_scores(self):\n",
        "        y_pred = self.f(self.get_x(), self.params)\n",
        "        return [round(n, 2) for n in self.inverse_map(y_pred, self.params)]\n",
        "\n",
        "\n",
        "# Función para convertir puntajes GPT a puntajes reales entre 0 y 3\n",
        "def convert_scores(gpt_dicts, real_scores, criteria, eval_function, eval_params=None):\n",
        "    if eval_function == \"map\":\n",
        "        optimizer = MapOptimizer(gpt_dicts, real_scores, criteria, eval_params)\n",
        "    if eval_function == \"cuts\":\n",
        "        optimizer = CutsOptimizer(gpt_dicts, real_scores, criteria, eval_params)\n",
        "\n",
        "    return optimizer.get_scores(), optimizer.get_parameters()"
      ],
      "metadata": {
        "id": "26ZFxmDVlRKT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, mean_absolute_error, mean_squared_error\n",
        "from sklearn.metrics import confusion_matrix, classification_report, r2_score, accuracy_score\n",
        "from GPTEvaluator.GPTEvaluator import chat_gpt_multiple\n",
        "from openai_multi_client import OpenAIMultiClient\n",
        "from datetime import datetime, timedelta\n",
        "from google.colab import userdata, files\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import openai\n",
        "import shutil\n",
        "import getpass\n",
        "import json\n",
        "import copy\n",
        "import re\n",
        "import os\n",
        "\n",
        "openai.api_key = userdata.get('api_key')\n",
        "\n",
        "# Retorna un diccionario con el contenido de cada miniprompt\n",
        "def read_miniprompts(data):\n",
        "    def read_file(folder, filename):\n",
        "        path = f\"Experiments/Miniprompts/{folder}/{filename}\"\n",
        "        try:\n",
        "            return open(path, 'r', encoding='utf-8').read()\n",
        "        except:\n",
        "            raise Exception(f\"Error: El archivo {path} no existe\")\n",
        "\n",
        "    mdata = copy.deepcopy(data)\n",
        "    for i, (key, value) in enumerate(data.items()):\n",
        "        if key == \"instructions\":\n",
        "            mdata[\"instructions\"] = \"Instructions:\\n\"\n",
        "            for j, (key2, value2) in enumerate(data[key].items()):\n",
        "                mdata[key2] = read_file(key2, value2) + \"\\n\\n\"\n",
        "        else:\n",
        "            mdata[key] = read_file(key, value) + \"\\n\\n\"\n",
        "\n",
        "    return mdata\n",
        "\n",
        "# Genera un prompt a partir de un diccionario con el contenido de cada miniprompt\n",
        "def generate_prompt(data, criteria):\n",
        "    def generate_criteria(criteria):\n",
        "        return \" Criteria are: \" + ', '.join(criteria) + \".\"\n",
        "\n",
        "    def add_output_criteria(output, criteria):\n",
        "        for e in criteria:\n",
        "            output += f'\"{e}\": {e}_score, '\n",
        "        return output[:-2]\n",
        "\n",
        "    def add_output_key(output, key, value):\n",
        "        m = re.search(r'#(.*?)\\n', value)\n",
        "        if m:\n",
        "            output += f'\"{key}\": \\'{m.group(1)}\\', '\n",
        "        return output\n",
        "\n",
        "    prompt = \"\"\n",
        "    output = \"I expect a dict in python as answer: {{\"\n",
        "    for key, value in data.items():\n",
        "        if value.startswith('#'):\n",
        "            output = add_output_key(output, key, value)\n",
        "            value = '\\n'.join(value.split('\\n')[1:]) # Quitar primera línea\n",
        "\n",
        "        prompt += value\n",
        "        if key == \"score\":\n",
        "            prompt = prompt[:-2] + generate_criteria(criteria) + \"\\n\\n\"\n",
        "\n",
        "    output = add_output_criteria(output, criteria)\n",
        "    prompt += output + \"}}\\n\\nPython dict:\"\n",
        "    return prompt\n",
        "\n",
        "# Carga un dataset a partir de un archivo xlsx y valida sus columnas\n",
        "def load_dataset(filename, sheet_name, column_data):\n",
        "  path = f\"Experiments/Datasets/{filename}\"\n",
        "  df = pd.read_excel(path, sheet_name=sheet_name)\n",
        "\n",
        "  mandatory_cols = [\"context\", \"question\", \"answer\", \"real_eval\"]\n",
        "  for key in mandatory_cols:\n",
        "    if key not in column_data.keys():\n",
        "      raise Exception(f\"Error: Debe especificar la columna para la variable {key}\")\n",
        "\n",
        "    value = column_data[key]\n",
        "    if value not in df.columns:\n",
        "      raise Exception(f\"Error: La columna {value} no existe\")\n",
        "\n",
        "    df = df.rename(columns={value: key})\n",
        "\n",
        "  return df\n",
        "\n",
        "# Genera las respuestas con ChatGPT\n",
        "def eval_gpt(df, prompt):\n",
        "  api = OpenAIMultiClient(endpoint=\"chats\", data_template={\"model\": \"gpt-3.5-turbo\", \"temperature\": 0.2, \"n\": 1, \"timeout\":10}, concurrency=50, wait_interval=1, max_retries=3, retry_max=10, retry_multiplier=1)\n",
        "\n",
        "  texts = []\n",
        "  for i, row in df.iterrows():\n",
        "    text = prompt.format(Question=row['question'], Answer=row['answer'], Context=row['context'])\n",
        "    texts.append(text)\n",
        "\n",
        "  answers_gpt = chat_gpt_multiple(api, texts)\n",
        "  return answers_gpt\n",
        "\n",
        "# Convierte la respuesta de GPT en un diccionario\n",
        "def get_gpt_dicts(answers_gpt):\n",
        "    pattern = r'\\{[^{}]+\\}'\n",
        "\n",
        "    gpt_dicts = []\n",
        "    for answer_gpt in answers_gpt:\n",
        "        try:\n",
        "            answer = re.findall(pattern, answer_gpt[0])[0]\n",
        "            gpt_dicts.append(eval(answer))\n",
        "        except Exception as e:\n",
        "            print(f\"Error al extraer diccionario. Respuesta GPT: \\n{answer_gpt[0]}\\n\\n\")\n",
        "            gpt_dicts.append(None)\n",
        "\n",
        "    return gpt_dicts\n",
        "\n",
        "# Obtiene los puntajes reales de un dataset\n",
        "def get_real_scores(df):\n",
        "    return df['real_eval'].tolist()\n",
        "\n",
        "# Calcula las métricas de evaluación\n",
        "def get_stats(real_scores, gpt_scores, eval_function):\n",
        "    if eval_function == \"cuts\":\n",
        "        stats = {\n",
        "            \"confusion_matrix\": confusion_matrix(real_scores, gpt_scores, labels=[0,1,2,3]).tolist(),\n",
        "            \"mse\": round(mean_squared_error(real_scores, gpt_scores), 2),\n",
        "            \"mae\": round(mean_absolute_error(real_scores, gpt_scores), 2),\n",
        "            \"r2\": round(r2_score(real_scores, gpt_scores), 2),\n",
        "            \"accuracy\": round(accuracy_score(real_scores, gpt_scores), 2),\n",
        "        }\n",
        "    elif eval_function == \"map\":\n",
        "        stats = {\n",
        "            \"mse\": round(mean_squared_error(real_scores, gpt_scores), 2),\n",
        "            \"mae\": round(mean_absolute_error(real_scores, gpt_scores), 2),\n",
        "            \"r2\": round(r2_score(real_scores, gpt_scores), 2),\n",
        "        }\n",
        "\n",
        "    return stats\n",
        "\n",
        "def save_results(filename, sheet_name, dataset_size, prompt, results, eval_function, filepath):\n",
        "  with open(filepath, 'w', encoding='utf-8') as file:\n",
        "    data = {\n",
        "        \"filename\": filename,\n",
        "        \"sheet_name\": sheet_name,\n",
        "        \"dataset_size\": dataset_size,\n",
        "        \"prompt\": prompt['prompt'],\n",
        "        \"field\": prompt['field'],\n",
        "        \"field_id\": prompt['file'],\n",
        "        \"eval_function\": eval_function,\n",
        "        \"results\": results\n",
        "    }\n",
        "    json.dump(data, file, ensure_ascii=False)\n",
        "\n",
        "def remove_invalid_samples(gpt_dicts, real_scores):\n",
        "    for i in reversed(range(len(gpt_dicts))):\n",
        "        if gpt_dicts[i] == None:\n",
        "            gpt_dicts.pop(i)\n",
        "            real_scores.pop(i)\n",
        "\n",
        "# Evalúa un prompt y retorna las estadísticas obtenidas\n",
        "def evaluate_prompt(df, prompt, criteria, eval_function, eval_params):\n",
        "    try:\n",
        "        answers_gpt = eval_gpt(df, prompt)\n",
        "        real_scores = get_real_scores(df)\n",
        "        gpt_dicts = get_gpt_dicts(answers_gpt)\n",
        "        remove_invalid_samples(gpt_dicts, real_scores)\n",
        "        gpt_scores, eval_params = convert_scores(gpt_dicts, real_scores, criteria, eval_function, eval_params)\n",
        "        stats = get_stats(real_scores, gpt_scores, eval_function)\n",
        "\n",
        "        return {\n",
        "            'real_scores': real_scores,\n",
        "            'gpt_scores': gpt_scores,\n",
        "            \"sample_size\": len(real_scores),\n",
        "            'params': eval_params,\n",
        "            'stats': stats\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "# Evalúa un prompt para N repeticiones\n",
        "def evaluate_prompt_n(df, prompt, criteria, repetitions, eval_function, eval_params):\n",
        "    result_list = []\n",
        "\n",
        "    for _ in range(repetitions):\n",
        "        result = evaluate_prompt(df, prompt, criteria, eval_function, eval_params)\n",
        "        result_list.append(result)\n",
        "\n",
        "    return result_list\n",
        "\n",
        "# Retorna una lista con la metadata necesaria para generar cada prompt\n",
        "def transform_prompt_data(prompt_data):\n",
        "    folder_key = None\n",
        "    instruction = False\n",
        "    update_count = 0\n",
        "\n",
        "    for key, value in prompt_data.items():\n",
        "        if key == \"instructions\":\n",
        "            for key2, value2 in prompt_data[key].items():\n",
        "                if value2 == \"*\":\n",
        "                    folder_key = key2\n",
        "                    instruction = True\n",
        "                    update_count += 1\n",
        "\n",
        "        elif value == \"*\":\n",
        "            folder_key = key\n",
        "            update_count += 1\n",
        "\n",
        "    if update_count == 0: # Sin carpetas, evaluar archivos directamente\n",
        "        return [{'data': prompt_data, 'field': None, 'file': None}]\n",
        "    elif update_count > 1:\n",
        "        raise Exception(f\"Error: Solo una carpeta a la vez como máximo\")\n",
        "\n",
        "    # Recorrer archivos en la carpeta y generar lista de metadatos\n",
        "    prompt_data_list = []\n",
        "    path = f\"Experiments/Miniprompts/{folder_key}\"\n",
        "    for file in os.listdir(path):\n",
        "        if os.path.isfile(os.path.join(path, file)):\n",
        "            prompt_data_copy = copy.deepcopy(prompt_data)\n",
        "            if instruction:\n",
        "                prompt_data_copy[\"instructions\"][folder_key] = file\n",
        "            else:\n",
        "                prompt_data_copy[folder_key] = file\n",
        "\n",
        "            prompt_data_list.append({'data': prompt_data_copy, 'field_in_instructions': instruction, 'field': folder_key, 'file': file})\n",
        "\n",
        "    return prompt_data_list\n",
        "\n",
        "# Genera los prompts a partir de un objeto prompt_data\n",
        "def generate_prompts(prompt_data, criteria):\n",
        "    prompt_data_list = transform_prompt_data(prompt_data)\n",
        "\n",
        "    for prompt_data in prompt_data_list:\n",
        "        miniprompt_data = read_miniprompts(prompt_data['data'])\n",
        "        prompt_data['prompt'] = generate_prompt(miniprompt_data, criteria)\n",
        "\n",
        "    return prompt_data_list\n",
        "\n",
        "# Muestra un histograma a partir de la frecuencia de puntajes\n",
        "def show_histogram(real_counts, pred_counts):\n",
        "    bins = np.arange(-0.5, 4, 1)\n",
        "    bin_centers = 0.5 * (bins[:-1] + bins[1:])\n",
        "    width = 0.35\n",
        "    plt.bar(bin_centers - width/2, real_counts, width=width, label='Real Eval', align='center')\n",
        "    plt.bar(bin_centers + width/2, pred_counts, width=width, label='GPT Eval', align='center')\n",
        "\n",
        "    plt.xlabel('Valor')\n",
        "    plt.ylabel('Frecuencia')\n",
        "    plt.title('Histograma')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Muestra resultados del experimento\n",
        "def show_results(dir):\n",
        "    print(f\"{'':<20} {'Métrica':<15} {'Media':<15} Desviación estándar\\n\")\n",
        "    for filename in sorted(os.listdir(dir)):\n",
        "        path = os.path.join(dir, filename)\n",
        "        if os.path.isfile(path):\n",
        "            file = open(path, 'r', encoding='utf-8')\n",
        "            data = json.load(file)\n",
        "            file.close()\n",
        "\n",
        "            if data['eval_function'] == \"cuts\":\n",
        "                show_results_cuts(data)\n",
        "            elif data['eval_function'] == \"map\":\n",
        "                show_results_map(data)\n",
        "\n",
        "# Muestra resultados de un experimento usando la función cuts\n",
        "def show_results_cuts(data):\n",
        "    maes = []\n",
        "    mses = []\n",
        "    r2s = []\n",
        "    accuracies = []\n",
        "    matrices = []\n",
        "\n",
        "    for result in data['results']:\n",
        "        stats = result['stats']\n",
        "        maes.append(stats['mae'])\n",
        "        mses.append(stats['mse'])\n",
        "        r2s.append(stats['r2'])\n",
        "        accuracies.append(stats['accuracy'])\n",
        "        matrices.append(stats['confusion_matrix'])\n",
        "\n",
        "    prompt_file = data['field_id']\n",
        "    if prompt_file == None: prompt_file = \"Prompt\"\n",
        "\n",
        "    print(f\"{f'{prompt_file}':<20} {'MAE':<15} {round(np.mean(maes),2):<15} {round(np.std(maes),2):<15}\")\n",
        "    print(f\"{'':<20} {'MSE':<15} {round(np.mean(mses),2):<15} {round(np.std(mses),2):<15}\")\n",
        "    print(f\"{'':<20} {'R2':<15} {round(np.mean(r2s),2):<15} {round(np.std(r2s),2):<15}\")\n",
        "    print(f\"{'':<20} {'Accuracy':<15} {round(np.mean(accuracies),2):<15} {round(np.std(accuracies),2):<15}\\n\")\n",
        "\n",
        "    matrices_np = np.array(matrices)\n",
        "    matrix_sum = np.sum(matrices_np, axis=0)\n",
        "    formatted_matrix_sum = str(matrix_sum).split('\\n')\n",
        "    print(f\"{'':<20} {'Matriz confusión'}\")\n",
        "    for row in formatted_matrix_sum:\n",
        "        print(f\"{'':<20} {row}\")\n",
        "    print()\n",
        "\n",
        "    real_counts = [sum(row) for row in matrix_sum]\n",
        "    pred_counts = [sum(col) for col in list(zip(*matrix_sum))]\n",
        "    show_histogram(real_counts, pred_counts)\n",
        "    print()\n",
        "\n",
        "# Muestra resultados de un experimento usando la función map\n",
        "def show_results_map(data):\n",
        "    maes = []\n",
        "    mses = []\n",
        "    r2s = []\n",
        "    real_scores = []\n",
        "    gpt_scores = []\n",
        "\n",
        "    for result in data['results']:\n",
        "        stats = result['stats']\n",
        "        maes.append(stats['mae'])\n",
        "        mses.append(stats['mse'])\n",
        "        r2s.append(stats['r2'])\n",
        "        real_scores.append(result['real_scores'])\n",
        "        gpt_scores.append(result['gpt_scores'])\n",
        "\n",
        "    prompt_file = data['field_id']\n",
        "    if prompt_file == None: prompt_file = \"Prompt\"\n",
        "\n",
        "    print(f\"{f'{prompt_file}':<20} {'MAE':<15} {round(np.mean(maes),2):<15} {round(np.std(maes),2):<15}\")\n",
        "    print(f\"{'':<20} {'MSE':<15} {round(np.mean(mses),2):<15} {round(np.std(mses),2):<15}\")\n",
        "    print(f\"{'':<20} {'R2':<15} {round(np.mean(r2s),2):<15} {round(np.std(r2s),2):<15}\\n\")\n",
        "\n",
        "    idx = np.argsort(mses)[len(mses) // 2]\n",
        "    real_scores = real_scores[idx]\n",
        "    gpt_scores = gpt_scores[idx]\n",
        "\n",
        "    groups = {v: [a for a, b in zip(gpt_scores, real_scores) if b == v] for v in set(real_scores)}\n",
        "    plt.boxplot(groups.values(), labels=groups.keys())\n",
        "    plt.title('Distribución de puntajes GPT')\n",
        "    plt.xlabel('Puntaje real')\n",
        "    plt.ylabel('Puntaje GPT')\n",
        "    plt.show()\n",
        "    print()\n",
        "\n",
        "\n",
        "# Evalúa varios prompts a la vez con N repeticiones\n",
        "def experiment(dataset, sheet_name, column_data, prompt_data, criteria, repetitions, eval_function, eval_params=None):\n",
        "    def create_dir():\n",
        "        date = datetime.now() - timedelta(hours=4)\n",
        "        formatted_date = date.strftime('%Y%m%d-%H%M')\n",
        "\n",
        "        dir = f\"Experiments/Results/{formatted_date}\"\n",
        "        if not os.path.exists(dir):\n",
        "            os.makedirs(dir)\n",
        "        return dir\n",
        "\n",
        "    valid_functions = [\"cuts\", \"map\"]\n",
        "    if eval_function not in valid_functions:\n",
        "        raise Exception(f\"Error: El parámetro eval_function debe ser 'cuts' o 'map'\")\n",
        "\n",
        "    visualize_prompt(prompt_data, criteria)\n",
        "\n",
        "    df = load_dataset(dataset, sheet_name, column_data)\n",
        "    prompts = generate_prompts(prompt_data, criteria)\n",
        "    dir = create_dir()\n",
        "\n",
        "    for i, prompt in enumerate(prompts):\n",
        "        if prompt['file']:\n",
        "            filename = os.path.splitext(prompt['file'])[0]\n",
        "        else:\n",
        "            filename = \"results\"\n",
        "\n",
        "        filepath = f\"{dir}/{filename}.json\"\n",
        "        result_list = evaluate_prompt_n(df, prompt['prompt'], criteria, repetitions, eval_function, eval_params)\n",
        "        save_results(dataset, sheet_name, len(df), prompt, result_list, eval_function, filepath)\n",
        "\n",
        "    print('\\n')\n",
        "    show_results(dir)\n",
        "\n",
        "# Muestra el prompt generado a partir de un diccionario prompt_data\n",
        "def visualize_prompt(prompt_data, criteria):\n",
        "    prompt_data_list = transform_prompt_data(prompt_data)\n",
        "    miniprompt_data = read_miniprompts(prompt_data_list[0]['data'])\n",
        "\n",
        "    if len(prompt_data_list) == 1:\n",
        "        print(generate_prompt(miniprompt_data, criteria))\n",
        "    else:\n",
        "        prompt_data = prompt_data_list[0]\n",
        "        if prompt_data['field_in_instructions']:\n",
        "            miniprompt_data['instructions'][prompt_data['field']] = f\"{{{prompt_data['field']}}}\"\n",
        "        else:\n",
        "            miniprompt_data[prompt_data['field']] = f\"{{{prompt_data['field']}}}\"\n",
        "        print(generate_prompt(miniprompt_data, criteria))\n",
        "\n",
        "# Descarga la carpeta de experimentos\n",
        "def download():\n",
        "    folder = 'Experiments'\n",
        "    shutil.make_archive(folder, 'zip', folder)\n",
        "\n",
        "    files.download(f'{folder}.zip')\n"
      ],
      "metadata": {
        "id": "gmAq6DONnhJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_data = {\n",
        "    \"examples\": \"examples_3.txt\",\n",
        "    \"context\": \"context_1.txt\",\n",
        "    \"question\": \"question_1.txt\",\n",
        "    \"answer\": \"answer_1.txt\",\n",
        "    \"instructions\": {\n",
        "        \"analysis\": \"analysis_1.txt\",\n",
        "        \"feedback\": \"feedback_1.txt\",\n",
        "        \"score\": \"score_1.txt\",\n",
        "    }\n",
        "}\n",
        "\n",
        "column_data = {\n",
        "    \"context\": \"Contexto\",\n",
        "    \"question\": \"Pregunta\",\n",
        "    \"answer\": \"Respuesta\",\n",
        "    \"real_eval\": \"EvalProfe\"\n",
        "}\n",
        "\n",
        "criteria = [\"correctness\", \"completeness\", \"clarity\"]\n",
        "\n",
        "'''\n",
        "experiment(\n",
        "    dataset=\"test.xlsx\",\n",
        "    sheet_name=\"C2-claim\",\n",
        "    column_data=column_data,\n",
        "    prompt_data=prompt_data,\n",
        "    criteria=criteria,\n",
        "    repetitions=1,\n",
        "    eval_function=\"map\"\n",
        ")\n",
        "'''\n",
        "\n",
        "visualize_prompt(prompt_data, criteria)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 930
        },
        "id": "MeQMKKgTE3nj",
        "outputId": "7bbd6cd2-213a-4149-8297-e94a87172736"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Examples:**\n",
            "Q: ¿Cómo se podría implementar un historial de navegación web usando dos pilas? El historial debe permitir ir hacia atrás y adelante con las páginas previamente visitadas. Describa un algoritmo.\n",
            "**Insatisfactory Answer**: Usamos dos pilas para ir hacia adelante y hacia atrás en el historial.\n",
            "(Score: 0)\n",
            "\n",
            "Q: ¿Por qué el acceso a un elemento específico en un arreglo es O(1), es decir, no depende de la cantidad de datos?\n",
            "**Insatisfactory Answer**: El acceso es O(1) por que toma un tiempo constante y no depende de la cantidad de datos.\n",
            "(Score: 0)\n",
            "\n",
            "Q: ¿Cuando se recomienda utilizar arreglos en vez de listas enlazadas? Haga referencia a complejidades temporales en su explicación.\n",
            "**Insatisfactory Answer**: Un arreglo es recomendable en determinadas situaciones, mientras que la lista enlazada en otras.\n",
            "Feedback: La respuesta del estudiante es incorrecta ya que no proporciona información nueva y simplemente reformula la pregunta sin agregar profundidad o claridad.\n",
            "(Score: 0)\n",
            "\n",
            "Q: ¿Cuál es la complejidad temporal del peor caso para la operación de búsqueda en una tabla hash y por qué? Describe las condiciones que debe tener la tabla para encontrarse en este peor caso.\n",
            "**Excelent Answer**: La complejidad del peor caso es O(n). Esta puede ocurrir cuando todos los datos de la tabla se encuentran contiguos en el arreglo, y cuando se busca una clave, está búsqueda hace colisión con todos los datos que estaban almacenados.\n",
            "(Score: 10)\n",
            "\n",
            "**Context (not visible to students):** {Context}\n",
            "\n",
            "**Question:** {Question}\n",
            "\n",
            "**Student's Answer:** {Answer}\n",
            "\n",
            "Instructions:\n",
            "(analysis)\n",
            "Analyse the \"Student's Answer\".\n",
            "Start by paraphrasing the answer in detail and commenting each sentence.\n",
            "It rewrites the same information provided in the question? or It correctly answers the question providing relevant and deep new information?\n",
            "It is complete, that is, answers all the questions?\n",
            "Use the hidden context as a reference to validate the accuracy and relevance of the student's response.\n",
            "Focus on the alignment between the question asked and the answer provided.\n",
            "\n",
            "(feedback)\n",
            "Provide Feedback to the student considering the analysis. **Do not be strict at all**.\n",
            "It is enough that the student answer correctly and more or less completely the question. **Do not ask for additional information**.\n",
            "Start by stating whether the answer is good/excelent or poor/insatisfactory.\n",
            "If the answer is good/excelent, affirm the student's understanding and potentially add a brief note on why their response was particularly effective or comprehensive.\n",
            "If the answer is poor/insatisfactory, clearly identify the inaccuracies or errors. Provide specific suggestions on how to improve, ensuring the feedback is constructive.\n",
            "Within 150 words. In Spanish.\n",
            "\n",
            "(score) Assign a score between 0 and 10 to different criteria based on the student's answer and the generated feedback. Criteria are: correctness, completeness, clarity.\n",
            "\n",
            "I expect a dict in python as answer: {{\"analysis\": 'La respuesta del estudiante dice que...', \"feedback\": 'very detailed feedback considering previous analysis (in spanish, within 150 words)', \"correctness\": correctness_score, \"completeness\": completeness_score, \"clarity\": clarity_score}}\n",
            "\n",
            "Python dict:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_results(\"Experiments/Results/20240723-1518\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        },
        "id": "MG8sDmwrcZ5u",
        "outputId": "065d5b7d-2fe6-4bff-cc53-564488a2bc65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     Métrica         Media           Desviación estándar\n",
            "\n",
            "Prompt               MAE             0.76            0.01           \n",
            "                     MSE             0.87            0.03           \n",
            "                     R2              0.25            0.02           \n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "download()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "hi178Zj5pfLg",
        "outputId": "e955b20f-322f-4d51-9878-a805a3a73362"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3d081f49-5e15-43f4-9e08-ea1d075866dc\", \"Experiments.zip\", 69819)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementación paso a paso"
      ],
      "metadata": {
        "id": "IKjPLvH1RBpQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28 &> /dev/null\n",
        "!pip install openai-multi-client &> /dev/null\n",
        "!git clone https://github.com/rilianx/GPTEvaluator &> /dev/null"
      ],
      "metadata": {
        "id": "Blf2NA6gZUN0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cargar dataset"
      ],
      "metadata": {
        "id": "qWo35VtxRK23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "# Muestra información relevante del dataset\n",
        "def show_dataset_info(dataset):\n",
        "    display(dataset.head())\n",
        "    print()\n",
        "    print(dataset.value_counts(\"real_eval\"), end=\"\\n\\n\")\n",
        "    print(dataset.value_counts(\"dataset\"))\n",
        "    pass\n",
        "\n",
        "# Carga un dataset a partir de un archivo xlsx y valida sus columnas\n",
        "def load_dataset(path, sheet_name, column_data):\n",
        "    df = pd.read_excel(path, sheet_name=sheet_name)\n",
        "\n",
        "    mandatory_cols = [\"context\", \"question\", \"answer\", \"real_eval\", \"dataset\"]\n",
        "    for key in mandatory_cols:\n",
        "        if key not in column_data.keys():\n",
        "            raise Exception(f\"Error: Debe especificar la columna para la variable {key}\")\n",
        "\n",
        "        value = column_data[key]\n",
        "        if value not in df.columns:\n",
        "            raise Exception(f\"Error: La columna {value} no existe\")\n",
        "\n",
        "        df = df.rename(columns={value: key})\n",
        "\n",
        "    df = df[mandatory_cols]\n",
        "    show_dataset_info(df)\n",
        "    return df"
      ],
      "metadata": {
        "id": "-vAnT6rTr6cn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_data = {\n",
        "    \"context\": \"Contexto\",\n",
        "    \"question\": \"Pregunta\",\n",
        "    \"answer\": \"Respuesta\",\n",
        "    \"real_eval\": \"Promedio Redondeado\",\n",
        "    \"dataset\": \"DatasetProveniente\"\n",
        "}\n",
        "\n",
        "df = load_dataset(\"datasets_v2.xlsx\", \"AllDatasets (1dif)\", column_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "O2Hg6gO-uwzk",
        "outputId": "42cba8d8-637e-425c-b5cb-37602d5b7078"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                             context  \\\n",
              "0  Un montículo binario se mantiene completo inse...   \n",
              "1  La utilidad de tener nodos con múltiples clave...   \n",
              "2  La utilidad de tener nodos con múltiples clave...   \n",
              "3  Los árboles binarios autobalanceables como AVL...   \n",
              "4  Un problema puede resolverse utilizando grafos...   \n",
              "\n",
              "                                            question  \\\n",
              "0  ¿Cómo se asegura que un montículo binario mant...   \n",
              "1  ¿Cuál es e la utilidad de tener nodos con múlt...   \n",
              "2  ¿Cuál es e la utilidad de tener nodos con múlt...   \n",
              "3  ¿Por qué las operaciones de los árboles binari...   \n",
              "4  ¿Qué características debería tener un problema...   \n",
              "\n",
              "                                              answer  real_eval       dataset  \n",
              "0  Para asegurar que se mantenga balanceado se co...          0  C3-Sample100  \n",
              "1  Es útil ya que gracias a eso la altura de esos...          2  C3-Sample100  \n",
              "2  El tener nodos con múltiples claves en árboles...          2  C3-Sample100  \n",
              "3  Los árboles AVL y rojo-negro tienen complejida...          2  C3-Sample100  \n",
              "4  Un problema para poder ser resulto con grafos ...          2  C3-Sample100  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9e921133-8c94-4bd7-bf84-2a2f38acc5e1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>real_eval</th>\n",
              "      <th>dataset</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Un montículo binario se mantiene completo inse...</td>\n",
              "      <td>¿Cómo se asegura que un montículo binario mant...</td>\n",
              "      <td>Para asegurar que se mantenga balanceado se co...</td>\n",
              "      <td>0</td>\n",
              "      <td>C3-Sample100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>La utilidad de tener nodos con múltiples clave...</td>\n",
              "      <td>¿Cuál es e la utilidad de tener nodos con múlt...</td>\n",
              "      <td>Es útil ya que gracias a eso la altura de esos...</td>\n",
              "      <td>2</td>\n",
              "      <td>C3-Sample100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>La utilidad de tener nodos con múltiples clave...</td>\n",
              "      <td>¿Cuál es e la utilidad de tener nodos con múlt...</td>\n",
              "      <td>El tener nodos con múltiples claves en árboles...</td>\n",
              "      <td>2</td>\n",
              "      <td>C3-Sample100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Los árboles binarios autobalanceables como AVL...</td>\n",
              "      <td>¿Por qué las operaciones de los árboles binari...</td>\n",
              "      <td>Los árboles AVL y rojo-negro tienen complejida...</td>\n",
              "      <td>2</td>\n",
              "      <td>C3-Sample100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Un problema puede resolverse utilizando grafos...</td>\n",
              "      <td>¿Qué características debería tener un problema...</td>\n",
              "      <td>Un problema para poder ser resulto con grafos ...</td>\n",
              "      <td>2</td>\n",
              "      <td>C3-Sample100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9e921133-8c94-4bd7-bf84-2a2f38acc5e1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9e921133-8c94-4bd7-bf84-2a2f38acc5e1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9e921133-8c94-4bd7-bf84-2a2f38acc5e1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-48480328-c4c7-408a-87dd-7b834dcfc50a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-48480328-c4c7-408a-87dd-7b834dcfc50a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-48480328-c4c7-408a-87dd-7b834dcfc50a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df = load_dataset(\\\"datasets_v2\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"context\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"La utilidad de tener nodos con m\\u00faltiples claves en \\u00e1rboles B/B+ radica en la capacidad de almacenar m\\u00e1s informaci\\u00f3n en cada nodo, lo que reduce la altura del \\u00e1rbol y, por lo tanto, el n\\u00famero de accesos a disco necesarios para buscar, insertar o eliminar datos.\",\n          \"Un problema puede resolverse utilizando grafos y algoritmos de b\\u00fasqueda si puede representarse mediante nodos (objetos, estados) y aristas (relaciones, transiciones) y si se busca una conexi\\u00f3n, ruta, o patr\\u00f3n entre estos nodos. Para modelar el problema: 1) Identificar los nodos y aristas. 2) Determinar la estructura del grafo (dirigido/no dirigido, ponderado/no ponderado). 3) Elegir un algoritmo de b\\u00fasqueda (BFS, DFS, Dijkstra, etc.) basado en el tipo de problema. Para resolverlo, aplicar el algoritmo seleccionado al grafo modelado, siguiendo los pasos espec\\u00edficos del algoritmo para encontrar la soluci\\u00f3n deseada.\",\n          \"Un mont\\u00edculo binario se mantiene completo insertando elementos en el siguiente espacio libre de la \\u00faltima fila y \\\"flotando\\\" el elemento si es necesario. Para eliminar, se intercambia el elemento de la ra\\u00edz con el \\u00faltimo elemento y luego se elimina el \\u00faltimo elemento. Esta inserci\\u00f3n y eliminaci\\u00f3n controlada asegura que el mont\\u00edculo siempre sea un \\u00e1rbol binario completo.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"\\u00bfCu\\u00e1l es e la utilidad de tener nodos con m\\u00faltiples claves en \\u00e1rboles B/B+? Explique.\",\n          \"\\u00bfQu\\u00e9 caracter\\u00edsticas deber\\u00eda tener un problema para poder resolverlo utilizando grafos y algoritmos de b\\u00fasqueda? \\u00bfQu\\u00e9 pasos debo seguir para modelar el problema? \\u00bfQu\\u00e9 hago para resolverlo?\",\n          \"\\u00bfC\\u00f3mo se asegura que un mont\\u00edculo binario mantenga su forma completa (perfectamente balanceado) al agregar o eliminar elementos?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Es \\u00fatil ya que gracias a eso la altura de esos arboles es significativamente mas baja en comparaci\\u00f3n a la de otros arboles binarios de b\\u00fasqueda. Adem\\u00e1s que es mas eficiente en la b\\u00fasqueda de datos en espec\\u00edficos y en rango.\",\n          \"Un problema para poder ser resulto con grafos y algoritmos de b\\u00fasqueda debe plantearse un estado inicial y un estado final esperado por ejemplo en un cubo 2x2 es el estado mesclado y el estado final resuelto, y se debe general un grafo impl\\u00edcito por ejemplo que permita generar los siguientes niveles de nodos que para este caso ser\\u00eda las posibles combinaciones partiendo de un estado dado, y definir el algoritmo de b\\u00fasqueda por profundidad o por anchura tan que se adapte mas a el problema en este caso b\\u00fasqueda por anchura al revisar el mejor camino que lleva a a soluci\\u00f3n.\",\n          \"El tener nodos con m\\u00faltiples claves en \\u00e1rboles B/B+ garantiza una mayor eficiencia, pues al ser \\u00e1rboles autobalanceables (gracias a sus divisiones y fusiones) asegura que su altura se mantendr\\u00e1 m\\u00ednima, lo cual hace que sus operaciones de b\\u00fasqueda, inserci\\u00f3n y eliminaci\\u00f3n sean menos costosas lo que implica una complejidad temporal de O(log n).\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"real_eval\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dataset\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"C3-Sample100\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "real_eval\n",
            "3    127\n",
            "2     75\n",
            "0     52\n",
            "1     36\n",
            "Name: count, dtype: int64\n",
            "\n",
            "dataset\n",
            "C2-Nan                  92\n",
            "C3-Sample100            91\n",
            "C2-Sample100            90\n",
            "C1-OscarBadAnswers20    17\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generación prompts"
      ],
      "metadata": {
        "id": "mqHdu2soRNEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "import copy\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "\n",
        "class Prompt():\n",
        "    def __init__(self, structure, instructions, base_folder):\n",
        "        self.structure = structure\n",
        "        self.instructions = instructions\n",
        "        self.base_folder = base_folder\n",
        "        self.raw_text_structure = None\n",
        "        self.text_structure = None\n",
        "        self.criteria = None\n",
        "        self.output_instructions = None\n",
        "        self.prompt = None\n",
        "\n",
        "        self.read_files()\n",
        "        self.extract_metadata()\n",
        "        self.build_prompt()\n",
        "\n",
        "    # Retorna la estructura base del prompt (diccionario)\n",
        "    def base_structure(self):\n",
        "        structure = copy.deepcopy(self.structure)\n",
        "        structure['instructions'] = {}\n",
        "        for i in self.instructions:\n",
        "            structure['instructions'][i] = structure[i]\n",
        "            structure.pop(i, None)\n",
        "        return structure\n",
        "\n",
        "    # Crea un diccionario con el contenido de cada archivo en la estructura\n",
        "    def read_files(self):\n",
        "        self.raw_text_structure = copy.deepcopy(self.structure)\n",
        "\n",
        "        for key, value in self.raw_text_structure.items():\n",
        "            if key == \"instructions\": continue\n",
        "\n",
        "            path = f\"{self.base_folder}/{key}/{value}\"\n",
        "            try:\n",
        "                self.raw_text_structure[key] = open(path, 'r', encoding='utf-8').read()\n",
        "                self.raw_text_structure[key] += \"\\n\\n\"\n",
        "            except:\n",
        "                raise Exception(f\"Error: El archivo {path} no existe\")\n",
        "\n",
        "    # Extrae metadatos de los archivos como los criterios e instrucciones de salida\n",
        "    def extract_metadata(self):\n",
        "        self.text_structure = copy.deepcopy(self.raw_text_structure)\n",
        "\n",
        "        if 'score' in self.text_structure:\n",
        "            lines = self.text_structure['score'].split('\\n')\n",
        "            self.criteria = [line[1:] for line in lines if line.startswith('$')]\n",
        "            text = [line for line in lines if not line.startswith('$')]\n",
        "            self.text_structure['score'] = '\\n'.join(text)\n",
        "\n",
        "        self.output_instructions = {}\n",
        "        for key, value in self.text_structure.items():\n",
        "            if value.startswith('#'):\n",
        "                m = re.search(r'#(.*?)\\n', value).group(1)\n",
        "                self.output_instructions[key] = m\n",
        "                self.text_structure[key] = '\\n'.join(value.split('\\n')[1:])\n",
        "\n",
        "    # Construye el prompt en formato string\n",
        "    def build_prompt(self):\n",
        "        self.prompt = \"\"\n",
        "        for key, value in self.text_structure.items():\n",
        "            self.prompt += value\n",
        "\n",
        "        output = \"I expect a dict in python as answer: {{\"\n",
        "        for key, value in self.output_instructions.items():\n",
        "            output += f'\"{key}\": \\'{value}\\', '\n",
        "\n",
        "        if len(self.criteria) > 0:\n",
        "            for c in self.criteria:\n",
        "                output += f'\"{c}\": {c}_score, '\n",
        "            output = output[:-2]\n",
        "        else:\n",
        "            output += '\"score\": score'\n",
        "\n",
        "        output += \"}}\\n\\nPython dict:\"\n",
        "        self.prompt += output\n",
        "\n",
        "\n",
        "# Procesa y elimina los diccionarios anidados de prompt_data\n",
        "def normalize_prompt_dict(prompt_data):\n",
        "    instructions = []\n",
        "    if \"instructions\" in prompt_data:\n",
        "        for (key, value) in prompt_data[\"instructions\"].items():\n",
        "            prompt_data[key] = value\n",
        "            instructions.append(key)\n",
        "\n",
        "    prompt_data[\"instructions\"] = \"Instructions:\\n\"\n",
        "    return prompt_data, instructions\n",
        "\n",
        "# Retorna la lista de archivos para reemplazar el comodín *\n",
        "def expand_prompt_data(prompt_data, prompt_folder):\n",
        "    wildcard_field = None\n",
        "    for key, value in prompt_data.items():\n",
        "        if value == \"*\":\n",
        "            wildcard_field = key\n",
        "            break\n",
        "\n",
        "    if not wildcard_field: return None, None\n",
        "\n",
        "    wildcard_files = []\n",
        "    path = f\"{prompt_folder}/{wildcard_field}\"\n",
        "    for file in sorted(os.listdir(path)):\n",
        "        if os.path.isfile(os.path.join(path, file)):\n",
        "            wildcard_files.append(file)\n",
        "\n",
        "    return wildcard_field, wildcard_files\n",
        "\n",
        "# Genera una lista con los prompts a evaluar\n",
        "def generate_prompts(prompt_data, prompt_folder):\n",
        "    template, instructions = normalize_prompt_dict(prompt_data)\n",
        "    wildcard_field, wildcard_files = expand_prompt_data(template, prompt_folder)\n",
        "    prompts = []\n",
        "\n",
        "    if wildcard_field == None:\n",
        "        prompt = Prompt(template, instructions, prompt_folder)\n",
        "        prompts.append(prompt)\n",
        "        print(prompt.prompt)\n",
        "        return prompts\n",
        "\n",
        "    for file in wildcard_files:\n",
        "        structure = copy.deepcopy(template)\n",
        "        structure[wildcard_field] = file\n",
        "        prompt = Prompt(structure, instructions, prompt_folder)\n",
        "        prompts.append(prompt)\n",
        "\n",
        "    # Visualizar\n",
        "    template = copy.deepcopy(prompts[0])\n",
        "    template.raw_text_structure[wildcard_field] = f\"{{{wildcard_field}}}\\n\\n\"\n",
        "    template.extract_metadata()\n",
        "    template.build_prompt()\n",
        "    print(template.prompt)\n",
        "\n",
        "    print(f\"\\n\\nArchivos a utilizar ({len(wildcard_files)}):\\n\")\n",
        "    print(\"\\n\".join(wildcard_files))\n",
        "\n",
        "    return prompts"
      ],
      "metadata": {
        "id": "uuM-IEVRPDBj"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_data = {\n",
        "    \"examples\": \"examples_1.txt\",\n",
        "    \"context\": \"knowledge_1.txt\",\n",
        "    \"question\": \"question_1.txt\",\n",
        "    \"answer\": \"answer_1.txt\",\n",
        "    \"instructions\": {\n",
        "        \"analysis\": \"analysis_1.txt\",\n",
        "        \"feedback\": \"feedback_1.txt\",\n",
        "        \"score\": \"score_2.txt\",\n",
        "    }\n",
        "}\n",
        "\n",
        "prompt_folder = \"Miniprompts\"\n",
        "\n",
        "prompts = generate_prompts(prompt_data, prompt_folder)"
      ],
      "metadata": {
        "id": "8FgMzj4KRlS6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d04d94e-41b2-49d6-f1c6-4c684c92ea85"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Examples:**\n",
            "Q: ¿Cómo se podría implementar un historial de navegación web usando dos pilas? El historial debe permitir ir hacia atrás y adelante con las páginas previamente visitadas. Describa un algoritmo.\n",
            "Incorrect Answer: Usamos dos pilas para ir hacia adelante y hacia atrás en el historial.  (Score: 0)\n",
            "\n",
            "Q: ¿Cómo se busca un valor en un árbol rojo-negro? Explique el proceso paso a paso.\n",
            "Incorrect Answer: PAra buscar el valor en un árbol rojo-negro debemos pasar por nodos rojos y negros hasta encontrar el valor. (Score: 0)\n",
            "\n",
            "Q: ¿Por qué el acceso a un elemento específico en un arreglo es O(1), es decir, no depende de la cantidad de datos?\n",
            "Incorrect Answer: El acceso es O(1) por que toma un tiempo constante y no depende de la cantidad de datos. (Score: 0)\n",
            "\n",
            "Q: ¿Cuando se recomienda utilizar arreglos en vez de listas enlazadas? Haga referencia a complejidades temporales en su explicación.\n",
            "Incorrect Answer: Un arreglo es recomendable en determinadas situaciones, mientras que la lista enlazada en otras.\n",
            "Feedback: La respuesta del estudiante es incorrecta ya que no proporciona información nueva y simplemente reformula la pregunta sin agregar profundidad o claridad. (Score: 0)\n",
            "\n",
            "**Knowledge:** {Context}\n",
            "\n",
            "\n",
            "**Question:** {Question}\n",
            "\n",
            "**Student's Answer:** {Answer}\n",
            "\n",
            "Instructions:\n",
            "(analysis)\n",
            "Analyse the \"Student's Answer\".\n",
            "Start by paraphrasing the answer in detail and commenting each sentence.\n",
            "It rewrites the same information provided in the question? or It correctly answers the question providing relevant and deep new information?\n",
            "It is complete, that is, answers all the questions?\n",
            "Use the Knowledge as a reference to validate the accuracy and relevance of the student's response.\n",
            "Focus on the alignment between the question asked and the answer provided.\n",
            "\n",
            "\n",
            "(feedback)\n",
            "Provide Feedback to the student considering the analysis. **Do not be strict at all**.\n",
            "It is enough that the student answer correctly and more or less completely the question. **Do not ask for additional information**.\n",
            "Start by stating whether the answer is good/excelent or poor/insatisfactory.\n",
            "If the answer is good/excelent, affirm the student's understanding and potentially add a brief note on why their response was particularly effective or comprehensive.\n",
            "If the answer is poor/insatisfactory, clearly identify the inaccuracies or errors. Provide specific suggestions on how to improve, ensuring the feedback is constructive.\n",
            "Within 150 words. In Spanish.\n",
            "\n",
            "(score) Assign a single score between 0 and 10 to the student's answer based on the generated feedback. The score should reflect the overall quality of the answer.\n",
            "\n",
            "I expect a dict in python as answer: {{\"analysis\": 'La respuesta del estudiante dice que...', \"feedback\": 'very detailed feedback considering previous analysis (in spanish, within 150 words)', \"score\": score}}\n",
            "\n",
            "Python dict:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimización parámetros"
      ],
      "metadata": {
        "id": "F-PYuT2HRSHu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.optimize import differential_evolution\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "### Optimización de cortes y ponderaciones ###\n",
        "class CutsEvaluator():\n",
        "    @staticmethod\n",
        "    def f(x, theta):\n",
        "        score = np.dot(x, theta[:-3])\n",
        "        y_pred = np.where(score > theta[-1], 3, np.where(score > theta[-2], 2, np.where(score > theta[-3], 1, 0)))\n",
        "        return y_pred\n",
        "\n",
        "class CutsOptimizer():\n",
        "    def __init__(self, criteria_scores, real_scores):\n",
        "        bounds =  [(0, 1) for _ in range(len(criteria_scores[0]))] + [(1, 4), (4, 7), (7, 10)]\n",
        "        result = differential_evolution(self.error, bounds, args=(criteria_scores, real_scores), seed=1, strategy='rand1exp', mutation=(0,1), recombination=1)\n",
        "        self.params = result.x.tolist()\n",
        "\n",
        "    def error(self, theta, x, y):\n",
        "        y_pred = CutsEvaluator.f(x, theta)\n",
        "        mse = np.mean((y - y_pred) ** 2)\n",
        "        penalty = 1e6 * np.abs(np.sum(theta[:-3]) - 1)\n",
        "        return mse + penalty\n",
        "\n",
        "\n",
        "####### Optimización mapeo de puntajes ########\n",
        "class MapEvaluator():\n",
        "    @staticmethod\n",
        "    def inverse_map(y_pred, theta):\n",
        "        a, b = theta[-2], theta[-1]\n",
        "        def single_inverse_map(y):\n",
        "            if y <= a:\n",
        "                return y / a\n",
        "            elif a < y <= b:\n",
        "                return 1 + (y - a) / (b - a)\n",
        "            else:\n",
        "                return 2 + (y - b) / (10 - b)\n",
        "\n",
        "        return np.array([single_inverse_map(y) for y in y_pred])\n",
        "\n",
        "    @staticmethod\n",
        "    def f(x, theta):\n",
        "        y_pred = np.dot(x, theta[:-2])\n",
        "        return MapEvaluator.inverse_map(y_pred, theta)\n",
        "\n",
        "class MapOptimizer():\n",
        "    def __init__(self, criteria_scores, real_scores):\n",
        "        bounds =  [(0, 1) for _ in range(len(criteria_scores[0]))] + [(1, 9), (1, 9)]\n",
        "        result = differential_evolution(self.error, bounds, args=(criteria_scores, real_scores), seed=1, strategy='rand1exp', mutation=(0,1), recombination=1)\n",
        "        self.params = result.x.tolist()\n",
        "\n",
        "    def error(self, theta, x, y):\n",
        "        y_pred = MapEvaluator.f(x, theta)\n",
        "        mse = np.sum((y - y_pred) ** 2)\n",
        "        penalty = 1e6 * np.abs(np.sum(theta[:-2]) - 1)\n",
        "        a, b = theta[-2], theta[-1]\n",
        "        if a > b: penalty += (a - b) * 1e5\n",
        "        return mse + penalty\n",
        "\n",
        "# Convierte una lista de diccionarios en una lista de tuplas\n",
        "def get_x(gpt_dicts, criteria):\n",
        "    if len(criteria) > 0:\n",
        "        return [\n",
        "            [gpt_dict[key] for key in criteria]\n",
        "            for gpt_dict in gpt_dicts\n",
        "        ]\n",
        "\n",
        "    return [[gpt_dict['score']] for gpt_dict in gpt_dicts]\n",
        "\n",
        "# Obtiene los parámetros óptimos para disminuir el error\n",
        "def optimize_params(gpt_dicts, real_scores, criteria, eval_function):\n",
        "    criteria_scores = get_x(gpt_dicts, criteria)\n",
        "    if eval_function == \"map\":\n",
        "        optimizer = MapOptimizer(criteria_scores, real_scores)\n",
        "    if eval_function == \"cuts\":\n",
        "        optimizer = CutsOptimizer(criteria_scores, real_scores)\n",
        "\n",
        "    return optimizer.params\n",
        "\n",
        "# Convierte los puntajes GPT a puntajes normalizados (0-3)\n",
        "def convert_gpt_scores(gpt_dicts, real_scores, criteria, eval_function, eval_params):\n",
        "    criteria_scores = get_x(gpt_dicts, criteria)\n",
        "    if eval_function == \"map\":\n",
        "        return MapEvaluator.f(criteria_scores, eval_params)\n",
        "    if eval_function == \"cuts\":\n",
        "        return CutsEvaluator.f(criteria_scores, eval_params)"
      ],
      "metadata": {
        "id": "9C0xfFjsE__M"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt_dicts = [\n",
        "    {\n",
        "        'score': 9\n",
        "    },\n",
        "    {\n",
        "        'score': 8\n",
        "    },\n",
        "    {\n",
        "        'score': 4\n",
        "    }\n",
        "]\n",
        "\n",
        "real_scores = [3, 2, 1]\n",
        "criteria = []\n",
        "\n",
        "eval_params = optimize_params(gpt_dicts, real_scores, criteria, \"map\")\n",
        "print(eval_params)\n",
        "convert_gpt_scores(gpt_dicts, real_scores, criteria, \"map\", eval_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2v7vABfitpf",
        "outputId": "58592e70-790d-4e74-a787-0506a0bad232"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.0, 4.000037881048441, 7.4999888512711514]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.60000178, 2.20000357, 0.99999053])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt_dicts = [\n",
        "    {\n",
        "        'relevance': 8,\n",
        "        'clarity': 9,\n",
        "        'precision': 7\n",
        "    },\n",
        "    {\n",
        "        'relevance': 8,\n",
        "        'clarity': 5,\n",
        "        'precision': 3\n",
        "    },\n",
        "    {\n",
        "        'relevance': 4,\n",
        "        'clarity': 1,\n",
        "        'precision': 2\n",
        "    }\n",
        "]\n",
        "\n",
        "real_scores = [3, 2, 1]\n",
        "criteria = ['relevance', 'clarity', 'precision']\n",
        "\n",
        "eval_params = optimize_params(gpt_dicts, real_scores, criteria, \"map\")\n",
        "print(eval_params)\n",
        "convert_gpt_scores(gpt_dicts, real_scores, criteria, \"map\", eval_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qU9hjjTBQ6RI",
        "outputId": "209ef607-8910-49ad-8bb5-f5493cdadb48"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.007063405579985471, 0.9736191598576271, 0.01931743420011689, 1.0250005164759606, 4.822870728613848]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.79801581, 2.03084424, 1.00408311])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experimentos"
      ],
      "metadata": {
        "id": "H3mOMBM_S_QH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from GPTEvaluator.GPTEvaluator import chat_gpt_multiple\n",
        "from openai_multi_client import OpenAIMultiClient\n",
        "import openai\n",
        "from google.colab import userdata\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "openai.api_key = userdata.get('api_key')\n",
        "\n",
        "class SetPair():\n",
        "    def __init__(self, train_set, test_set):\n",
        "        self.train_set = train_set\n",
        "        self.test_set = test_set\n",
        "\n",
        "# Divide el dataset en conjuntos de entrenamiento/prueba\n",
        "def generate_sets(dataset, repetitions, train_set_size=60, test_set_size=100, group_size=15, seed=42):\n",
        "    sets = []\n",
        "    random.seed(seed)\n",
        "\n",
        "    group_size = train_set_size // 4\n",
        "    for i in range(repetitions):\n",
        "        train_set = dataset.groupby('real_eval', group_keys=False).apply(lambda x: x.sample(group_size, random_state=random.randint(0,100000)))\n",
        "        test_set = dataset[~dataset.index.isin(train_set.index)]\n",
        "        test_set = dataset.sample(n=test_set_size, random_state=random.randint(0,100000))\n",
        "        sets.append(SetPair(train_set, test_set))\n",
        "\n",
        "    return sets\n",
        "\n",
        "# Genera las respuestas con ChatGPT\n",
        "def eval_gpt(df, prompt):\n",
        "    api = OpenAIMultiClient(endpoint=\"chats\", data_template={\"model\": \"gpt-4o-mini\", \"temperature\": 0.1, \"n\": 1, \"timeout\":10}, concurrency=50, wait_interval=1, max_retries=3, retry_max=10, retry_multiplier=1)\n",
        "\n",
        "    texts = []\n",
        "    for i, row in df.iterrows():\n",
        "        text = prompt.format(Question=row['question'], Answer=row['answer'], Context=row['context'])\n",
        "        texts.append(text)\n",
        "\n",
        "    answers_gpt = chat_gpt_multiple(api, texts)\n",
        "    return answers_gpt\n",
        "\n",
        "# Extrae diccionario de salida de las respuestas GPT\n",
        "def extract_dicts(answers_gpt):\n",
        "    pattern = r'\\{[^{}]+\\}'\n",
        "\n",
        "    gpt_dicts = []\n",
        "    for answer_gpt in answers_gpt:\n",
        "        try:\n",
        "            answer = re.findall(pattern, answer_gpt[0])[0]\n",
        "            gpt_dicts.append(eval(answer))\n",
        "        except Exception as e:\n",
        "            print(f\"Error al extraer diccionario. Respuesta GPT: \\n{answer_gpt[0]}\\n\\n\")\n",
        "            gpt_dicts.append(None)\n",
        "\n",
        "    return gpt_dicts\n",
        "\n",
        "# Elimina filas del dataset donde hubo errores en la salida GPT\n",
        "def clean_set(dataset, gpt_dicts):\n",
        "    for i in reversed(range(len(gpt_dicts))):\n",
        "        if gpt_dicts[i] == None:\n",
        "            gpt_dicts.pop(i)\n",
        "            dataset.drop(index=i)\n",
        "\n",
        "# Obtiene los puntajes reales de un dataset\n",
        "def get_real_scores(dataset):\n",
        "    return dataset['real_eval'].tolist()\n",
        "\n",
        "# Prepara el set de entrenamiento y obtiene los parámetros óptimos para disminuir el error\n",
        "def train(train_set, prompt, criteria, eval_function):\n",
        "    answers_gpt = eval_gpt(train_set, prompt)\n",
        "    gpt_dicts = extract_dicts(answers_gpt)\n",
        "    clean_set(train_set, gpt_dicts)\n",
        "    real_scores = get_real_scores(train_set)\n",
        "    return optimize_params(gpt_dicts, real_scores, criteria, eval_function)\n",
        "\n",
        "# Prepara el set de prueba y calcula las métricas del modelo preentrenado usando el conjunto de prueba\n",
        "def test(test_set, prompt, criteria, eval_function, eval_params):\n",
        "    answers_gpt = eval_gpt(test_set, prompt)\n",
        "    gpt_dicts = extract_dicts(answers_gpt)\n",
        "    clean_set(test_set, gpt_dicts)\n",
        "    real_scores = get_real_scores(test_set)\n",
        "    pred_scores = convert_gpt_scores(gpt_dicts, real_scores, criteria, eval_function, eval_params)\n",
        "\n",
        "    result_set = test_set.copy(deep=True)\n",
        "    result_set['gpt_eval'] = pred_scores\n",
        "    return calculate_mse(result_set)\n",
        "\n",
        "# Retorna un dataset con el MSE por grupo\n",
        "def calculate_mse(result_set):\n",
        "    stats = result_set.groupby('dataset').apply(lambda x: mean_squared_error(x['real_eval'], x['gpt_eval'])).reset_index()\n",
        "    stats = stats.rename(columns={0: 'MSE'})\n",
        "\n",
        "    row = {\n",
        "        \"dataset\": \"All\",\n",
        "        \"MSE\": mean_squared_error(result_set['real_eval'], result_set['gpt_eval'])\n",
        "    }\n",
        "    df_row = pd.DataFrame([row])\n",
        "    return pd.concat([df_row, stats], ignore_index=True)\n",
        "\n",
        "# Evalúa una lista de prompts obtienendo el MSE promedio en M repeticiones\n",
        "def experiment(dataset, prompts, repetitions, eval_function, eval_params=None, train_set_size=60, test_set_size=100, seed=42):\n",
        "    sets = generate_sets(dataset, repetitions, train_set_size, test_set_size, seed)\n",
        "    stats = []\n",
        "\n",
        "    for i, prompt_data in enumerate(prompts):\n",
        "        prompt = prompt_data.prompt\n",
        "        criteria = prompt_data.criteria\n",
        "        stats.append([])\n",
        "\n",
        "        for j in range(repetitions):\n",
        "            train_set = sets[j].train_set\n",
        "            test_set = sets[j].test_set\n",
        "\n",
        "            iter_params = eval_params\n",
        "            if not eval_params:\n",
        "                print(f\"Entrenando Prompt {i+1} con Train Set {j+1}\")\n",
        "                iter_params = train(train_set, prompt, criteria, eval_function)\n",
        "\n",
        "            print(f\"\\nEvaluando Prompt {i+1} con Test Set {j+1}\")\n",
        "            metrics = test(test_set, prompt, criteria, eval_function, iter_params)\n",
        "            stats[i].append(metrics)\n",
        "            print()\n",
        "\n",
        "    # Promediar MSE/dataset por prompt\n",
        "    for i in range(len(stats)):\n",
        "        p = pd.concat(stats[i], ignore_index=True)\n",
        "        p = p.groupby('dataset')['MSE'].mean().reset_index()\n",
        "        p = p.set_index('dataset').transpose()\n",
        "        p = p.reset_index(drop=True, names=None)\n",
        "        p.columns.name = None\n",
        "        p.insert(loc=0, column='Prompt', value=prompts[i].base_structure())\n",
        "        stats[i] = p\n",
        "\n",
        "    stats = pd.concat(stats, ignore_index=True)\n",
        "    display(stats)\n",
        "\n",
        "    return stats"
      ],
      "metadata": {
        "id": "iXoEKV3qzn0y"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = experiment(df, prompts, repetitions=1, eval_function=\"map\", eval_params=None, train_set_size=4, test_set_size=4, seed=42)"
      ],
      "metadata": {
        "id": "eoxYTKmiNLrL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "0b968236-9c15-4da9-bd50-2291b7f7fbcf"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrenando Prompt 1 con Train Set 1\n",
            "1-3-2-0-\n",
            "Evaluando Prompt 1 con Test Set 1\n",
            "2-1-3-0-\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                              Prompt       All  \\\n",
              "0  {\\n    \"examples\": \"examples_1.txt\",\\n    \"con...  0.247302   \n",
              "\n",
              "   C1-OscarBadAnswers20    C2-Nan  C2-Sample100  C3-Sample100  \n",
              "0              0.337852  0.137724      0.175778      0.337852  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6d971954-1282-42cb-914a-139f78ea5b31\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prompt</th>\n",
              "      <th>All</th>\n",
              "      <th>C1-OscarBadAnswers20</th>\n",
              "      <th>C2-Nan</th>\n",
              "      <th>C2-Sample100</th>\n",
              "      <th>C3-Sample100</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{\\n    \"examples\": \"examples_1.txt\",\\n    \"con...</td>\n",
              "      <td>0.247302</td>\n",
              "      <td>0.337852</td>\n",
              "      <td>0.137724</td>\n",
              "      <td>0.175778</td>\n",
              "      <td>0.337852</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d971954-1282-42cb-914a-139f78ea5b31')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6d971954-1282-42cb-914a-139f78ea5b31 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6d971954-1282-42cb-914a-139f78ea5b31');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"x = experiment(df, prompts, repetitions=1, eval_function=\\\"map\\\", eval_params=None, train_set_size=4, test_set_size=4, seed=42)\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"{\\n    \\\"examples\\\": \\\"examples_1.txt\\\",\\n    \\\"context\\\": \\\"knowledge_1.txt\\\",\\n    \\\"question\\\": \\\"question_1.txt\\\",\\n    \\\"answer\\\": \\\"answer_1.txt\\\",\\n    \\\"instructions\\\": {\\n        \\\"analysis\\\": \\\"analysis_1.txt\\\",\\n        \\\"feedback\\\": \\\"feedback_1.txt\\\",\\n        \\\"score\\\": \\\"score_2.txt\\\"\\n    }\\n}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"All\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.24730156332317293,\n        \"max\": 0.24730156332317293,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.24730156332317293\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"C1-OscarBadAnswers20\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.3378521251819497,\n        \"max\": 0.3378521251819497,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.3378521251819497\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"C2-Nan\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.1377243456761002,\n        \"max\": 0.1377243456761002,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.1377243456761002\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"C2-Sample100\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.17577765725269218,\n        \"max\": 0.17577765725269218,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.17577765725269218\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"C3-Sample100\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.3378521251819497,\n        \"max\": 0.3378521251819497,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.3378521251819497\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}