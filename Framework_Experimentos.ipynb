{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNrrP8R2H/NsykkrQumvvvR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OscarRojasG/Experimentos-GPTValidator/blob/main/Framework_Experimentos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Framework para experimentos GPTValidator"
      ],
      "metadata": {
        "id": "wAu6OvJu7hBs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El objetivo de este framework consiste en proporcionar un conjunto de funciones previamente implementadas para facilitar la evaluación y comparación de prompts para el proyecto EvaluAI."
      ],
      "metadata": {
        "id": "3ixHfITmnzVF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instrucciones de uso"
      ],
      "metadata": {
        "id": "NtGhcZhln18k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En primer lugar, es necesario ejecutar **TODAS** las celdas de código de la sección Implementación."
      ],
      "metadata": {
        "id": "ExLyT4Rm3Bhx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Cargar dataset"
      ],
      "metadata": {
        "id": "pV4tFiFvGSY4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Subir archivo .xlsx con todos los datasets combinados. Debe contener al menos 5 columnas con los siguientes datos:\n",
        "    * **Contexto** (context): Conocimiento previo que necesita el modelo para evaluar la respuesta del estudiante.\n",
        "    * **Pregunta** (question)\n",
        "    * **Respuesta** (answer): Respuesta del estudiante\n",
        "    * **Evaluación manual** (real_eval): Puntaje de referencia dado por uno o más evaluadores humanos.\n",
        "    * **Dataset de origen** (dataset): Dataset del cual provienen los datos para una fila en particular.\n",
        "\n",
        "2. Especificar el nombre de las columnas en un diccionario con la siguiente estructura (ejemplo):\n",
        "\n",
        "    ```\n",
        "    column_data = {\n",
        "            \"context\": \"Contexto\",\n",
        "            \"question\": \"Pregunta\",\n",
        "            \"answer\": \"Respuesta\",\n",
        "            \"real_eval\": \"EvalManual\",\n",
        "            \"dataset\": \"Dataset\"\n",
        "    }\n",
        "    ```\n",
        "\n",
        "3. Cargar dataset con la función `load_dataset(path, sheet_name, column_data)`\n",
        "\n",
        "    - **path** - Ruta del archivo xlsx a utilizar.\n",
        "    - **sheet_name** - Nombre de la hoja donde se encuentran los datos.\n",
        "    - **column_data** - Diccionario explicado en el punto anterior."
      ],
      "metadata": {
        "id": "AKWV5dgcCGKv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Definir miniprompts a evaluar"
      ],
      "metadata": {
        "id": "Q0nCnpHNaR9O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Subir carpeta con la colección de miniprompts. Los miniprompts deben estar definidos en archivos txt y agrupados en carpetas por categoría (ejemplos, analysis, feedback, etc.). **Se pueden crear nuevas carpetas sin restricciones**.\n",
        "\n",
        "2. Seleccionar los miniprompts a utilizar para la generación de los prompts. Estos deben ser definidos en un diccionario donde la clave corresponde al nombre de la carpeta y el valor es el nombre del archivo txt con el miniprompt correspondiente. Se puede utilizar el comodín * como valor para probar con todos los miniprompts de esa carpeta.\n",
        "\n",
        "    ```\n",
        "    prompt_data = {\n",
        "        \"examples\": \"examples_XX.txt\",\n",
        "        \"context\": \"knowledge_XX.txt\",\n",
        "        \"question\": \"...\",\n",
        "        \"answer\": \"...\",\n",
        "        \"instructions\": {\n",
        "            \"analysis\": \"*\",\n",
        "            \"feedback\": \"...\",\n",
        "            \"score\": \"...\",\n",
        "        }\n",
        "    }\n",
        "    ```\n",
        "\n",
        "3. Cargar prompts con la función ``generate_prompts(prompt_data, prompt_folder)``\n",
        "\n",
        "    - **prompt_data** - Diccionario explicado en el punto anterior.\n",
        "    - **prompt_folder** - Ruta de la carpeta donde se encuentra la colección de miniprompts. (Ej: Experiments/Miniprompts)\n",
        "\n",
        "#### Notas adicionales\n",
        "\n",
        "En caso de tener problemas al subir la carpeta a colab, subirla como zip y ejecutar el comando\n",
        "\n",
        "```\n",
        "!unzip nombre_carpeta.zip\n",
        "```\n",
        "\n",
        "Los criterios deben ser definidos en las primeras líneas del miniprompt score con el símbolo $.\n",
        "\n",
        "```\n",
        "$correctness\n",
        "$completeness\n",
        "$clarity\n",
        "(score) Assign a score between 0 and 10 to different criteria based on the student's answer and the generated feedback. Criteria are: correctness, completeness, clarity.\n",
        "```\n",
        "\n",
        "Las instrucciones de salida de algunos miniprompts como feedback y analysis, se pueden definir usando el símbolo # en la primera línea del archivo.\n",
        "\n",
        "```\n",
        "#very detailed feedback considering previous analysis (in spanish, within 150 words)\n",
        "(feedback)\n",
        "Provide Feedback to the student considering the analysis. **Do not be strict at all**.\n",
        "It is enough that the student answer correctly and more or less completely the question. **Do not ask for additional information**.\n",
        "Start by stating whether the answer is good/excelent or poor/insatisfactory.\n",
        "If the answer is good/excelent, affirm the student's understanding and potentially add a brief note on why their response was particularly effective or comprehensive.\n",
        "If the answer is poor/insatisfactory, clearly identify the inaccuracies or errors. Provide specific suggestions on how to improve, ensuring the feedback is constructive.\n",
        "Within 150 words. In Spanish.\n",
        "```"
      ],
      "metadata": {
        "id": "T2uhIxI0JW1t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Realizar experimento"
      ],
      "metadata": {
        "id": "a2SphdjqaUJE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluar los prompts con la función ``experiment(dataset, prompts, repetitions, eval_function, eval_params=None, train_set_size=60, test_set_size=100, seed=42)``\n",
        "\n",
        "- **dataset** - Objeto de tipo DataFrame cargado en el punto 1.\n",
        "- **prompts** - Colección de prompts cargados en el punto 2.\n",
        "- **repetitions** - Número de repeticiones que se desea realizar la evaluación de cada prompt. Cada evaluación implica un nuevo conjunto de entrenamiento/prueba.\n",
        "- **eval_function** - Método para convertir los puntajes GPT a escala 0-3. Puede ser \"cuts\" o \"map\".\n",
        "- **eval_params** - Lista de parámetros usados para la conversión de puntajes. Son distintos dependiendo del valor de *eval_function*.\n",
        "- **train_set_size** - Tamaño total $n$ del conjunto de entrenamiento. El conjunto de entrenamiento se encuentra compuesto por $n/4$ muestras de cada puntaje (balanceado).\n",
        "- **test_set_size** - Tamaño total del conjunto de prueba (no balanceado).\n",
        "- **seed** - Semilla utilizada para la creación de los conjuntos de prueba y entrenamiento.\n",
        "\n",
        "Para ``eval_function = \"cuts\"`` los parámetros siguen la estructura $[w_1, w_2, ..., w_m, a, b, c]$\n",
        "\n",
        "Para ``eval_function = \"map\"`` los parámetros siguen la estructura $[w_1, w_2, ..., w_m, a, b]$\n",
        "\n",
        "En ambos casos, los primeros $m$ parámetros corresponden a las ponderaciones de cada criterio (en el mismo orden en que fueron definidos dentro del miniprompt score). La suma de las ponderaciones debe ser 1. En caso de no haber criterios, existe una única ponderación igual a 1.\n",
        "\n",
        "Para la evaluación por cortes, los parámetros $a, b, c$ corresponden a los puntajes de corte ordenados de menor a mayor. Por ejemplo, para un prompt con 2 criterios, una lista de parámetros válidos podría ser $[0.7, 0.3, 3, 5, 7]$\n",
        "\n",
        "Para la evaluación por mapeo, los parámetros $a, b$ representan los puntajes en escala 0-10 que corresponden a los puntajes 1 y 2 en escala 0-3. Por ejemplo:\n",
        "\n",
        "$\\text{map}(0) = 0$\n",
        "\n",
        "$\\text{map}(a) = 1$\n",
        "\n",
        "$\\text{map}(b) = 2$\n",
        "\n",
        "$\\text{map}(10) = 3$"
      ],
      "metadata": {
        "id": "QjpkYTTfa_ka"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementación"
      ],
      "metadata": {
        "id": "IKjPLvH1RBpQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28 &> /dev/null\n",
        "!pip install openai-multi-client &> /dev/null\n",
        "!git clone https://github.com/rilianx/GPTEvaluator &> /dev/null"
      ],
      "metadata": {
        "id": "Blf2NA6gZUN0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cargar dataset"
      ],
      "metadata": {
        "id": "qWo35VtxRK23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "# Muestra información relevante del dataset\n",
        "def show_dataset_info(dataset):\n",
        "    display(dataset.head())\n",
        "    print()\n",
        "    print(dataset.value_counts(\"real_eval\"), end=\"\\n\\n\")\n",
        "    print(dataset.value_counts(\"dataset\"))\n",
        "    pass\n",
        "\n",
        "# Carga un dataset a partir de un archivo xlsx y valida sus columnas\n",
        "def load_dataset(path, sheet_name, column_data):\n",
        "    df = pd.read_excel(path, sheet_name=sheet_name)\n",
        "\n",
        "    mandatory_cols = [\"context\", \"question\", \"answer\", \"real_eval\", \"dataset\"]\n",
        "    for key in mandatory_cols:\n",
        "        if key not in column_data.keys():\n",
        "            raise Exception(f\"Error: Debe especificar la columna para la variable {key}\")\n",
        "\n",
        "        value = column_data[key]\n",
        "        if value not in df.columns:\n",
        "            raise Exception(f\"Error: La columna {value} no existe\")\n",
        "\n",
        "        df = df.rename(columns={value: key})\n",
        "\n",
        "    df = df[mandatory_cols]\n",
        "    show_dataset_info(df)\n",
        "    return df"
      ],
      "metadata": {
        "id": "-vAnT6rTr6cn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generación prompts"
      ],
      "metadata": {
        "id": "mqHdu2soRNEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "import copy\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "\n",
        "class Prompt():\n",
        "    def __init__(self, structure, instructions, base_folder):\n",
        "        self.structure = structure\n",
        "        self.instructions = instructions\n",
        "        self.base_folder = base_folder\n",
        "        self.raw_text_structure = None\n",
        "        self.text_structure = None\n",
        "        self.criteria = None\n",
        "        self.output_instructions = None\n",
        "        self.prompt = None\n",
        "\n",
        "        self.read_files()\n",
        "        self.extract_metadata()\n",
        "        self.build_prompt()\n",
        "\n",
        "    # Retorna la estructura base del prompt (diccionario)\n",
        "    def base_structure(self):\n",
        "        structure = copy.deepcopy(self.structure)\n",
        "        structure['instructions'] = {}\n",
        "        for i in self.instructions:\n",
        "            structure['instructions'][i] = structure[i]\n",
        "            structure.pop(i, None)\n",
        "        return structure\n",
        "\n",
        "    # Crea un diccionario con el contenido de cada archivo en la estructura\n",
        "    def read_files(self):\n",
        "        self.raw_text_structure = copy.deepcopy(self.structure)\n",
        "\n",
        "        for key, value in self.raw_text_structure.items():\n",
        "            if key == \"instructions\": continue\n",
        "\n",
        "            path = f\"{self.base_folder}/{key}/{value}\"\n",
        "            try:\n",
        "                self.raw_text_structure[key] = open(path, 'r', encoding='utf-8').read()\n",
        "                self.raw_text_structure[key] += \"\\n\\n\"\n",
        "            except:\n",
        "                raise Exception(f\"Error: El archivo {path} no existe\")\n",
        "\n",
        "    # Extrae metadatos de los archivos como los criterios e instrucciones de salida\n",
        "    def extract_metadata(self):\n",
        "        self.text_structure = copy.deepcopy(self.raw_text_structure)\n",
        "\n",
        "        if 'score' in self.text_structure:\n",
        "            lines = self.text_structure['score'].split('\\n')\n",
        "            self.criteria = [line[1:] for line in lines if line.startswith('$')]\n",
        "            text = [line for line in lines if not line.startswith('$')]\n",
        "            self.text_structure['score'] = '\\n'.join(text)\n",
        "\n",
        "        self.output_instructions = {}\n",
        "        output_mp = [\"analysis\", \"feedback\"]\n",
        "        for key in output_mp:\n",
        "            if key not in self.text_structure: continue\n",
        "            value = self.text_structure[key]\n",
        "\n",
        "            if value.startswith('#'):\n",
        "                m = re.search(r'#(.*?)\\n', value).group(1)\n",
        "                self.output_instructions[key] = m\n",
        "                self.text_structure[key] = '\\n'.join(value.split('\\n')[1:])\n",
        "\n",
        "    # Construye el prompt en formato string\n",
        "    def build_prompt(self):\n",
        "        self.prompt = \"\"\n",
        "        for key, value in self.text_structure.items():\n",
        "            self.prompt += value\n",
        "\n",
        "        output = \"I expect a dict in python as answer: {{\"\n",
        "        for key, value in self.output_instructions.items():\n",
        "            output += f'\"{key}\": \\'{value}\\', '\n",
        "\n",
        "        if len(self.criteria) > 0:\n",
        "            for c in self.criteria:\n",
        "                output += f'\"{c}\": {c}_score, '\n",
        "            output = output[:-2]\n",
        "        else:\n",
        "            output += '\"score\": score'\n",
        "\n",
        "        output += \"}}\\n\\nPython dict:\"\n",
        "        self.prompt += output\n",
        "\n",
        "\n",
        "# Procesa y elimina los diccionarios anidados de prompt_data\n",
        "def normalize_prompt_dict(prompt_data):\n",
        "    instructions = []\n",
        "    if \"instructions\" in prompt_data:\n",
        "        for (key, value) in prompt_data[\"instructions\"].items():\n",
        "            prompt_data[key] = value\n",
        "            instructions.append(key)\n",
        "\n",
        "    prompt_data[\"instructions\"] = \"Instructions:\\n\"\n",
        "    return prompt_data, instructions\n",
        "\n",
        "# Retorna la lista de archivos para reemplazar el comodín *\n",
        "def expand_prompt_data(prompt_data, prompt_folder):\n",
        "    wildcard_field = None\n",
        "    for key, value in prompt_data.items():\n",
        "        if value == \"*\":\n",
        "            wildcard_field = key\n",
        "            break\n",
        "\n",
        "    if not wildcard_field: return None, None\n",
        "\n",
        "    wildcard_files = []\n",
        "    path = f\"{prompt_folder}/{wildcard_field}\"\n",
        "    for file in sorted(os.listdir(path)):\n",
        "        if os.path.isfile(os.path.join(path, file)):\n",
        "            wildcard_files.append(file)\n",
        "\n",
        "    return wildcard_field, wildcard_files\n",
        "\n",
        "# Genera una lista con los prompts a evaluar\n",
        "def generate_prompts(prompt_data, prompt_folder):\n",
        "    template, instructions = normalize_prompt_dict(prompt_data)\n",
        "    wildcard_field, wildcard_files = expand_prompt_data(template, prompt_folder)\n",
        "    prompts = []\n",
        "\n",
        "    if wildcard_field == None:\n",
        "        prompt = Prompt(template, instructions, prompt_folder)\n",
        "        prompts.append(prompt)\n",
        "        print(prompt.prompt)\n",
        "        return prompts\n",
        "\n",
        "    for file in wildcard_files:\n",
        "        structure = copy.deepcopy(template)\n",
        "        structure[wildcard_field] = file\n",
        "        prompt = Prompt(structure, instructions, prompt_folder)\n",
        "        prompts.append(prompt)\n",
        "\n",
        "    # Visualizar\n",
        "    template = copy.deepcopy(prompts[0])\n",
        "    template.raw_text_structure[wildcard_field] = f\"{{{wildcard_field}}}\\n\\n\"\n",
        "    template.extract_metadata()\n",
        "    template.build_prompt()\n",
        "    print(template.prompt)\n",
        "\n",
        "    print(f\"\\n\\nArchivos a utilizar ({len(wildcard_files)}):\\n\")\n",
        "    print(\"\\n\".join(wildcard_files))\n",
        "\n",
        "    return prompts"
      ],
      "metadata": {
        "id": "uuM-IEVRPDBj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimización parámetros"
      ],
      "metadata": {
        "id": "F-PYuT2HRSHu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.optimize import differential_evolution\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "### Optimización de cortes y ponderaciones ###\n",
        "class CutsEvaluator():\n",
        "    @staticmethod\n",
        "    def f(x, theta):\n",
        "        score = np.dot(x, theta[:-3])\n",
        "        y_pred = np.where(score > theta[-1], 3, np.where(score > theta[-2], 2, np.where(score > theta[-3], 1, 0)))\n",
        "        return y_pred\n",
        "\n",
        "class CutsOptimizer():\n",
        "    def __init__(self, criteria_scores, real_scores):\n",
        "        bounds =  [(0, 1) for _ in range(len(criteria_scores[0]))] + [(1, 4), (4, 7), (7, 10)]\n",
        "        result = differential_evolution(self.error, bounds, args=(criteria_scores, real_scores), seed=1, strategy='rand1exp', mutation=(0,1), recombination=1)\n",
        "        self.params = result.x.tolist()\n",
        "\n",
        "    def error(self, theta, x, y):\n",
        "        y_pred = CutsEvaluator.f(x, theta)\n",
        "        mse = np.mean((y - y_pred) ** 2)\n",
        "        penalty = 1e6 * np.abs(np.sum(theta[:-3]) - 1)\n",
        "        return mse + penalty\n",
        "\n",
        "\n",
        "####### Optimización mapeo de puntajes ########\n",
        "class MapEvaluator():\n",
        "    @staticmethod\n",
        "    def inverse_map(y_pred, theta):\n",
        "        a, b = theta[-2], theta[-1]\n",
        "        def single_inverse_map(y):\n",
        "            if y <= a:\n",
        "                return y / a\n",
        "            elif a < y <= b:\n",
        "                return 1 + (y - a) / (b - a)\n",
        "            else:\n",
        "                return 2 + (y - b) / (10 - b)\n",
        "\n",
        "        return np.array([single_inverse_map(y) for y in y_pred])\n",
        "\n",
        "    @staticmethod\n",
        "    def f(x, theta):\n",
        "        y_pred = np.dot(x, theta[:-2])\n",
        "        return MapEvaluator.inverse_map(y_pred, theta)\n",
        "\n",
        "class MapOptimizer():\n",
        "    def __init__(self, criteria_scores, real_scores):\n",
        "        bounds =  [(0, 1) for _ in range(len(criteria_scores[0]))] + [(1, 9), (1, 9)]\n",
        "        result = differential_evolution(self.error, bounds, args=(criteria_scores, real_scores), seed=1, strategy='rand1exp', mutation=(0,1), recombination=1)\n",
        "        self.params = result.x.tolist()\n",
        "\n",
        "    def error(self, theta, x, y):\n",
        "        y_pred = MapEvaluator.f(x, theta)\n",
        "        mse = np.sum((y - y_pred) ** 2)\n",
        "        penalty = 1e6 * np.abs(np.sum(theta[:-2]) - 1)\n",
        "        a, b = theta[-2], theta[-1]\n",
        "        if a > b: penalty += (a - b) * 1e5\n",
        "        return mse + penalty\n",
        "\n",
        "# Convierte una lista de diccionarios en una lista de tuplas\n",
        "def get_x(gpt_dicts, criteria):\n",
        "    if len(criteria) > 0:\n",
        "        return [\n",
        "            [gpt_dict[key] for key in criteria]\n",
        "            for gpt_dict in gpt_dicts\n",
        "        ]\n",
        "\n",
        "    return [[gpt_dict['score']] for gpt_dict in gpt_dicts]\n",
        "\n",
        "# Obtiene los parámetros óptimos para disminuir el error\n",
        "def optimize_params(gpt_dicts, real_scores, criteria, eval_function):\n",
        "    criteria_scores = get_x(gpt_dicts, criteria)\n",
        "    if eval_function == \"map\":\n",
        "        optimizer = MapOptimizer(criteria_scores, real_scores)\n",
        "    if eval_function == \"cuts\":\n",
        "        optimizer = CutsOptimizer(criteria_scores, real_scores)\n",
        "\n",
        "    return optimizer.params\n",
        "\n",
        "# Convierte los puntajes GPT a puntajes normalizados (0-3)\n",
        "def convert_gpt_scores(gpt_dicts, real_scores, criteria, eval_function, eval_params):\n",
        "    criteria_scores = get_x(gpt_dicts, criteria)\n",
        "    if eval_function == \"map\":\n",
        "        return MapEvaluator.f(criteria_scores, eval_params)\n",
        "    if eval_function == \"cuts\":\n",
        "        return CutsEvaluator.f(criteria_scores, eval_params)"
      ],
      "metadata": {
        "id": "9C0xfFjsE__M"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt_dicts = [\n",
        "    {\n",
        "        'score': 9\n",
        "    },\n",
        "    {\n",
        "        'score': 8\n",
        "    },\n",
        "    {\n",
        "        'score': 4\n",
        "    }\n",
        "]\n",
        "\n",
        "real_scores = [3, 2, 1]\n",
        "criteria = []\n",
        "\n",
        "eval_params = optimize_params(gpt_dicts, real_scores, criteria, \"map\")\n",
        "print(eval_params)\n",
        "convert_gpt_scores(gpt_dicts, real_scores, criteria, \"map\", eval_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2v7vABfitpf",
        "outputId": "f5bc9b49-c765-43c8-8b58-0a7ae1d68af2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.0, 4.000037881048441, 7.4999888512711514]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.60000178, 2.20000357, 0.99999053])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt_dicts = [\n",
        "    {\n",
        "        'relevance': 8,\n",
        "        'clarity': 9,\n",
        "        'precision': 7\n",
        "    },\n",
        "    {\n",
        "        'relevance': 8,\n",
        "        'clarity': 5,\n",
        "        'precision': 3\n",
        "    },\n",
        "    {\n",
        "        'relevance': 4,\n",
        "        'clarity': 1,\n",
        "        'precision': 2\n",
        "    }\n",
        "]\n",
        "\n",
        "real_scores = [3, 2, 1]\n",
        "criteria = ['relevance', 'clarity', 'precision']\n",
        "\n",
        "eval_params = optimize_params(gpt_dicts, real_scores, criteria, \"map\")\n",
        "print(eval_params)\n",
        "convert_gpt_scores(gpt_dicts, real_scores, criteria, \"map\", eval_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qU9hjjTBQ6RI",
        "outputId": "a73fef6e-2de9-411c-83ef-19becf64c142"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.007063405579985471, 0.9736191598576271, 0.01931743420011689, 1.0250005164759606, 4.822870728613848]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.79801581, 2.03084424, 1.00408311])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experimentos"
      ],
      "metadata": {
        "id": "H3mOMBM_S_QH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from GPTEvaluator.GPTEvaluator import chat_gpt_multiple\n",
        "from openai_multi_client import OpenAIMultiClient\n",
        "import openai\n",
        "from google.colab import userdata\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import os\n",
        "from datetime import datetime, timedelta\n",
        "import json\n",
        "import numpy\n",
        "\n",
        "openai.api_key = userdata.get('api_key')\n",
        "\n",
        "class SetPair():\n",
        "    def __init__(self, train_set, test_set):\n",
        "        self.train_set = train_set\n",
        "        self.test_set = test_set\n",
        "\n",
        "# Divide el dataset en conjuntos de entrenamiento/prueba\n",
        "def generate_sets(dataset, repetitions, train_set_size, test_set_size, seed=42):\n",
        "    sets = []\n",
        "    random.seed(seed)\n",
        "\n",
        "    group_size = train_set_size // 4\n",
        "    for i in range(repetitions):\n",
        "        proportions = df['real_eval'].value_counts(normalize=True)\n",
        "        samples_per_class = (proportions * test_set_size).round().astype(int)\n",
        "        test_set = df.groupby('real_eval', group_keys=False)[df.columns.tolist()].apply(lambda x: x.sample(samples_per_class[x.name], random_state=random.randint(0,100000)))\n",
        "        test_set = test_set.reset_index(drop=True)\n",
        "\n",
        "        train_set = dataset[~dataset.index.isin(test_set.index)]\n",
        "        train_set = train_set.groupby('real_eval', group_keys=False)[df.columns.tolist()].apply(lambda x: x.sample(group_size, random_state=random.randint(0,100000)))\n",
        "        train_set = train_set.reset_index(drop=True)\n",
        "        sets.append(SetPair(train_set, test_set))\n",
        "\n",
        "    return sets\n",
        "\n",
        "# Genera las respuestas con ChatGPT\n",
        "def eval_gpt(df, prompt, model, temperature):\n",
        "    api = OpenAIMultiClient(endpoint=\"chats\", data_template={\"model\": model, \"temperature\": temperature, \"n\": 1, \"timeout\":10}, concurrency=50, wait_interval=1, max_retries=3, retry_max=10, retry_multiplier=1)\n",
        "\n",
        "    texts = []\n",
        "    for i, row in df.iterrows():\n",
        "        text = prompt.format(Question=row['question'], Answer=row['answer'], Context=row['context'])\n",
        "        texts.append(text)\n",
        "\n",
        "    answers_gpt = chat_gpt_multiple(api, texts)\n",
        "    return answers_gpt\n",
        "\n",
        "# Extrae diccionario de salida de las respuestas GPT\n",
        "def extract_dicts(answers_gpt):\n",
        "    pattern = r'\\{[^{}]+\\}'\n",
        "\n",
        "    gpt_dicts = []\n",
        "    for answer_gpt in answers_gpt:\n",
        "        try:\n",
        "            answer = re.findall(pattern, answer_gpt[0])[0]\n",
        "            gpt_dicts.append(eval(answer))\n",
        "        except Exception as e:\n",
        "            print(f\"Error al extraer diccionario. Respuesta GPT: \\n{answer_gpt[0]}\\n\\n\")\n",
        "            gpt_dicts.append(None)\n",
        "\n",
        "    return gpt_dicts\n",
        "\n",
        "# Elimina filas del dataset donde hubo errores en la salida GPT\n",
        "def clean_set(dataset, gpt_dicts, criteria):\n",
        "    for i in reversed(range(len(gpt_dicts))):\n",
        "        if gpt_dicts[i] is None:\n",
        "            gpt_dicts.pop(i)\n",
        "            dataset.drop(index=i, inplace=True)\n",
        "        elif all(key in gpt_dicts[i] for key in criteria) == False:\n",
        "            print(gpt_dicts[i])\n",
        "            gpt_dicts.pop(i)\n",
        "            dataset.drop(index=i, inplace=True)\n",
        "    dataset.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Obtiene los puntajes reales de un dataset\n",
        "def get_real_scores(dataset):\n",
        "    return dataset['real_eval'].tolist()\n",
        "\n",
        "# Prepara el set de entrenamiento y obtiene los parámetros óptimos para disminuir el error\n",
        "def train(train_set, prompt, criteria, eval_function, model, temperature):\n",
        "    train_set = train_set.copy()\n",
        "    answers_gpt = eval_gpt(train_set, prompt, model, temperature)\n",
        "    gpt_dicts = extract_dicts(answers_gpt)\n",
        "    clean_set(train_set, gpt_dicts, criteria)\n",
        "    real_scores = get_real_scores(train_set)\n",
        "    return optimize_params(gpt_dicts, real_scores, criteria, eval_function)\n",
        "\n",
        "# Prepara el set de prueba y calcula las métricas del modelo preentrenado usando el conjunto de prueba\n",
        "def test(test_set, prompt, criteria, eval_function, eval_params, model, temperature, normalize_mse):\n",
        "    test_set2 = test_set.copy()\n",
        "    answers_gpt = eval_gpt(test_set2, prompt, model, temperature)\n",
        "    gpt_dicts = extract_dicts(answers_gpt)\n",
        "    clean_set(test_set2, gpt_dicts, criteria)\n",
        "    real_scores = get_real_scores(test_set2)\n",
        "    pred_scores = convert_gpt_scores(gpt_dicts, real_scores, criteria, eval_function, eval_params)\n",
        "\n",
        "    test_set2['gpt_eval'] = pred_scores\n",
        "    df_dicts = pd.DataFrame(gpt_dicts)\n",
        "    result_set = pd.concat([test_set2, df_dicts], axis=1)\n",
        "\n",
        "    return calculate_mse(result_set, normalize_mse), result_set\n",
        "\n",
        "# Retorna un dataset con el MSE por grupo\n",
        "def calculate_mse(result_set, normalize):\n",
        "    if normalize:\n",
        "        mse_dict = result_set.groupby('dataset').apply(lambda x: mean_squared_error(x['real_eval']/3, x['gpt_eval']/3)).to_dict()\n",
        "        overall_mse = mean_squared_error(result_set['real_eval']/3, result_set['gpt_eval']/3)\n",
        "    else:\n",
        "        mse_dict = result_set.groupby('dataset').apply(lambda x: mean_squared_error(x['real_eval'], x['gpt_eval'])).to_dict()\n",
        "        overall_mse = mean_squared_error(result_set['real_eval'], result_set['gpt_eval'])\n",
        "\n",
        "    mse_dict['All'] = overall_mse\n",
        "    return mse_dict\n",
        "\n",
        "# Evalúa una lista de prompts obtienendo el MSE promedio en M repeticiones\n",
        "def experiment(dataset, prompts, repetitions, eval_function, eval_params=None, train_set_size=40, test_set_size=60, seed=42, model=\"gpt-4o-mini\", temperature=0.1, normalize_mse=False):\n",
        "    sets = generate_sets(dataset, repetitions, train_set_size, test_set_size, seed)\n",
        "    stats = []\n",
        "    full_df = pd.DataFrame()\n",
        "\n",
        "    for i, prompt_data in enumerate(prompts):\n",
        "        prompt = prompt_data.prompt\n",
        "        criteria = prompt_data.criteria\n",
        "        stats.append([])\n",
        "\n",
        "        for j in range(repetitions):\n",
        "            train_set = sets[j].train_set\n",
        "            test_set = sets[j].test_set\n",
        "\n",
        "            iter_params = eval_params\n",
        "            if not eval_params:\n",
        "                print(f\"Entrenando Prompt {i+1} con Train Set {j+1}\")\n",
        "                iter_params = train(train_set, prompt, criteria, eval_function, model, temperature)\n",
        "                print()\n",
        "\n",
        "            print(f\"Evaluando Prompt {i+1} con Test Set {j+1}\")\n",
        "            metrics, result_set = test(test_set, prompt, criteria, eval_function, iter_params, model, temperature, normalize_mse)\n",
        "            stats[i].append({\n",
        "                \"MSE\": metrics,\n",
        "                \"params\": iter_params\n",
        "            })\n",
        "            print()\n",
        "\n",
        "            result_set['prompt'] = prompt\n",
        "            result_set['repetition'] = j+1\n",
        "            full_df = pd.concat([full_df, result_set], ignore_index=True)\n",
        "\n",
        "    full_df.to_excel('final_set.xlsx', index=False)\n",
        "    filename = save_stats(prompts, stats, eval_function, train_set_size, test_set_size, model, temperature)\n",
        "    read_results(filename)\n",
        "\n",
        "    return stats\n",
        "\n",
        "# Guarda resultados en un archivo JSON\n",
        "def save_stats(prompts, stats, eval_function, train_set_size, test_set_size, model, temperature):\n",
        "    data = {\n",
        "        \"model\": model,\n",
        "        \"temperature\": temperature,\n",
        "        \"train_set_size\": train_set_size,\n",
        "        \"test_set_size\": test_set_size,\n",
        "        \"repetitions\": len(stats[0]),\n",
        "        \"results\": []\n",
        "    }\n",
        "\n",
        "    for i in range(len(stats)):\n",
        "        results = {\n",
        "            \"prompt\": prompts[i].base_structure(),\n",
        "            \"stats\": stats[i]\n",
        "        }\n",
        "        data[\"results\"].append(results)\n",
        "\n",
        "    dir = \"Results\"\n",
        "    if not os.path.exists(dir):\n",
        "        os.makedirs(dir)\n",
        "\n",
        "    date = datetime.now() - timedelta(hours=4)\n",
        "    formatted_date = date.strftime('%Y%m%d-%H%M')\n",
        "    path = f'{dir}/{formatted_date}.json'\n",
        "    with open(path, 'w', encoding='utf-8') as file:\n",
        "        json.dump(data, file, ensure_ascii=False)\n",
        "\n",
        "    return path\n",
        "\n",
        "# Lee y muestra resultados de un archivo JSON\n",
        "def read_results(path):\n",
        "    with open(path, 'r', encoding='utf-8') as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    rows = []\n",
        "    for result in data[\"results\"]:\n",
        "        for i, stat in enumerate(result[\"stats\"]):\n",
        "            row = stat[\"MSE\"]\n",
        "            row[\"Prompt\"] = json.dumps(result[\"prompt\"])\n",
        "            row[\"Repetition\"] = i+1\n",
        "            rows.append(row)\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "    col = df.pop('Prompt')\n",
        "    df.insert(0, 'Prompt', col)\n",
        "    col = df.pop('All')\n",
        "    df.insert(1, 'All', col)\n",
        "\n",
        "    pd.set_option('display.max_columns', None)\n",
        "    pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "    # Normalizar std\n",
        "    '''\n",
        "    def std(x): return np.std(x)\n",
        "    df_norm = df[['Repetition', 'Prompt', 'All']].copy()\n",
        "\n",
        "    mean_per_rep = df_norm[['Repetition', 'All']].groupby('Repetition', as_index=False).mean().reset_index(drop=True)\n",
        "    mean_per_rep.rename(columns={'All': 'Mean'}, inplace=True)\n",
        "    std_per_rep = df_norm[['Repetition', 'All']].groupby('Repetition', as_index=False).agg(std).reset_index(drop=True)\n",
        "    std_per_rep.rename(columns={'All': 'Std'}, inplace=True)\n",
        "\n",
        "    df_norm = df_norm.merge(mean_per_rep, on='Repetition', how='inner')\n",
        "    df_norm = df_norm.merge(std_per_rep, on='Repetition', how='inner')\n",
        "\n",
        "    df_norm['Norm'] = (df_norm['All'] - df_norm['Mean'])/df_norm['Std']\n",
        "    df_norm = df_norm[['Prompt', 'Norm']].groupby('Prompt', as_index=False).agg(Mean=('Norm', 'mean'), Std=('Norm', std)).reset_index(drop=True)\n",
        "    df_norm = df_norm.sort_values('Mean')\n",
        "\n",
        "    print(\"\\nTabla MSE normalizado\")\n",
        "    display(df_norm)\n",
        "    '''\n",
        "\n",
        "    # Sin normalizar std\n",
        "    def std(x): return np.std(x)\n",
        "    df_mean = df.drop(columns=[\"Repetition\"]).groupby('Prompt', as_index=False).mean().reset_index(drop=True)\n",
        "    df_mean = df_mean.sort_values('All')\n",
        "    df_std = df.drop(columns=[\"Repetition\"]).groupby('Prompt', as_index=False).agg(std).reset_index(drop=True)\n",
        "    df_std = df_std.loc[df_mean.index]\n",
        "\n",
        "    print(\"\\nTabla Promedio MSE\")\n",
        "    display(df_mean)\n",
        "    print(\"\\nTabla Desviación estándar\")\n",
        "    display(df_std)\n",
        "\n",
        "    pd.reset_option('^display.', silent=True)"
      ],
      "metadata": {
        "id": "iXoEKV3qzn0y"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Espacio para experimentos"
      ],
      "metadata": {
        "id": "chb-5XuP2MRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "column_data = {\n",
        "    \"context\": \"Contexto detallado\",\n",
        "    \"question\": \"Pregunta\",\n",
        "    \"answer\": \"Respuesta\",\n",
        "    \"real_eval\": \"Promedio Redondeado\",\n",
        "    \"dataset\": \"DataSet\"\n",
        "}\n",
        "\n",
        "df = load_dataset(\"datasets_v2.xlsx\", \"AllDatasets (1dif)\", column_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "9THpDAIu2ZRj",
        "outputId": "cde5b3c1-f95c-4667-8867-fc6c69920a07"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                             context  \\\n",
              "0  BFS es preferible en problemas donde se busca ...   \n",
              "1  BFS es preferible en problemas donde se busca ...   \n",
              "2  BFS es preferible en problemas donde se busca ...   \n",
              "3  BFS es preferible en problemas donde se busca ...   \n",
              "4  La principal diferencia entre BFS y DFS radica...   \n",
              "\n",
              "                                            question  \\\n",
              "0  ¿En qué tipo de problemas una búsqueda BFS pod...   \n",
              "1  ¿En qué tipo de problemas una búsqueda BFS pod...   \n",
              "2  ¿En qué tipo de problemas una búsqueda BFS pod...   \n",
              "3  ¿En qué tipo de problemas una búsqueda BFS pod...   \n",
              "4  ¿Cuál es la principal diferencia entre búsqued...   \n",
              "\n",
              "                                              answer  real_eval       dataset  \n",
              "0  El bfs es mucho mas util en ejecuciones cortas...          2  C3-Sample100  \n",
              "1  en una situación de resolución de un problema ...          2  C3-Sample100  \n",
              "2  en problemas donde pidan obtener el camino de ...          3  C3-Sample100  \n",
              "3  en problemas de grafos no ponderados ya que no...          3  C3-Sample100  \n",
              "4  La búsqueda por anchura tiene un procedimiento...          3  C3-Sample100  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-04b60d82-6714-4810-9c01-6a571892e627\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>real_eval</th>\n",
              "      <th>dataset</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BFS es preferible en problemas donde se busca ...</td>\n",
              "      <td>¿En qué tipo de problemas una búsqueda BFS pod...</td>\n",
              "      <td>El bfs es mucho mas util en ejecuciones cortas...</td>\n",
              "      <td>2</td>\n",
              "      <td>C3-Sample100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BFS es preferible en problemas donde se busca ...</td>\n",
              "      <td>¿En qué tipo de problemas una búsqueda BFS pod...</td>\n",
              "      <td>en una situación de resolución de un problema ...</td>\n",
              "      <td>2</td>\n",
              "      <td>C3-Sample100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BFS es preferible en problemas donde se busca ...</td>\n",
              "      <td>¿En qué tipo de problemas una búsqueda BFS pod...</td>\n",
              "      <td>en problemas donde pidan obtener el camino de ...</td>\n",
              "      <td>3</td>\n",
              "      <td>C3-Sample100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BFS es preferible en problemas donde se busca ...</td>\n",
              "      <td>¿En qué tipo de problemas una búsqueda BFS pod...</td>\n",
              "      <td>en problemas de grafos no ponderados ya que no...</td>\n",
              "      <td>3</td>\n",
              "      <td>C3-Sample100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>La principal diferencia entre BFS y DFS radica...</td>\n",
              "      <td>¿Cuál es la principal diferencia entre búsqued...</td>\n",
              "      <td>La búsqueda por anchura tiene un procedimiento...</td>\n",
              "      <td>3</td>\n",
              "      <td>C3-Sample100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-04b60d82-6714-4810-9c01-6a571892e627')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-04b60d82-6714-4810-9c01-6a571892e627 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-04b60d82-6714-4810-9c01-6a571892e627');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-832da575-7fbe-4fe5-b290-79d60edfb240\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-832da575-7fbe-4fe5-b290-79d60edfb240')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-832da575-7fbe-4fe5-b290-79d60edfb240 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df = load_dataset(\\\"datasets_v2\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"context\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"La principal diferencia entre BFS y DFS radica en la estrategia de exploraci\\u00f3n de los nodos. BFS explora los nodos nivel por nivel, es decir, visita primero los nodos m\\u00e1s cercanos al nodo inicial. DFS, por otro lado, explora tan profundamente como sea posible a lo largo de cada rama antes de retroceder. No es necesario proporcionar m\\u00e1s detalles.\",\n          \"BFS es preferible en problemas donde se busca la soluci\\u00f3n m\\u00e1s corta o m\\u00ednima en t\\u00e9rminos de n\\u00famero de aristas, como encontrar el camino m\\u00e1s corto en un grafo no ponderado. Esto se debe a que BFS explora todos los vecinos de un nodo antes de profundiza.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\\u00bfCu\\u00e1l es la principal diferencia entre b\\u00fasqueda en anchura (BFS) y b\\u00fasqueda en profundidad (DFS)?\",\n          \"\\u00bfEn qu\\u00e9 tipo de problemas una b\\u00fasqueda BFS podr\\u00eda ser mejor a una DFS? \\u00bfPor qu\\u00e9?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"en una situaci\\u00f3n de resoluci\\u00f3n de un problema que requiera un camino corto para llegar al objetivo, porque el BFS al ser b\\u00fasqueda en anchura, no necesitamos hacer muchas iteraciones hasta pasar al siguiente nodo como en la b\\u00fasqueda por profundidad ya que se va recorriendo desde afuera hacia adentro.\",\n          \"La b\\u00fasqueda por anchura tiene un procedimiento m\\u00e1s horizontal que vertical, ya que el m\\u00e9todo para recorrer es ver los nodos/datos vecinos en la estructura, siendo mejor para casos donde el dato a buscar puede estar dentro de los primeros niveles, en cambio, la b\\u00fasqueda en profundidad cambia totalmente el m\\u00e9todo de b\\u00fasqueda siendo este m\\u00e1s vertical que horizontal, partiendo de la ra\\u00edz y yendo a los hijos, esto es mejor para nodos/datos que pueden estar en los \\u00faltimos niveles.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"real_eval\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2,\n        \"max\": 3,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          3,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dataset\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"C3-Sample100\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "real_eval\n",
            "3    127\n",
            "2     75\n",
            "0     52\n",
            "1     36\n",
            "Name: count, dtype: int64\n",
            "\n",
            "dataset\n",
            "C2-Nan                  92\n",
            "C3-Sample100            91\n",
            "C2-Sample100            90\n",
            "C1-OscarBadAnswers20    17\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_data = {\n",
        "    \"context\": \"context.txt\",\n",
        "    \"question\": \"question.txt\",\n",
        "    \"answer\": \"answer.txt\",\n",
        "    \"instructions\": {\n",
        "        \"score\": \"score_single.txt\"\n",
        "    }\n",
        "}\n",
        "\n",
        "prompt_folder = \"GPTEvaluator/Experiments/Miniprompts_v2\"\n",
        "\n",
        "prompts = generate_prompts(prompt_data, prompt_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TArcbGPT2LA9",
        "outputId": "f361ee55-8eb2-4f77-c856-8d277ba476f9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Knowledge:** {Context}\n",
            "\n",
            "**Question:** {Question}\n",
            "\n",
            "**Student's Answer:** {Answer}\n",
            "\n",
            "Instructions:\n",
            "(score) Assign a score between 0 and 10 to the student's answer.\n",
            "\n",
            "I expect a dict in python as answer: {{\"score\": score}}\n",
            "\n",
            "Python dict:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = experiment(df, prompts, repetitions=1, eval_function=\"map\", eval_params=None, train_set_size=40, test_set_size=60, seed=42, model=\"gpt-4o-mini\", temperature=0.1, normalize_mse=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "CtzNfwy02RVE",
        "outputId": "85bbc426-a502-4c3c-8e71-59a3de129b0f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrenando Prompt 1 con Train Set 1\n",
            "1-4-2-5-0-6-7-3-9-12-27-11-21-13-8-10-15-18-28-14-19-24-17-16-20-22-34-38-31-37-25-26-36-32-33-39-30-35-29-23-\n",
            "Evaluando Prompt 1 con Test Set 1\n",
            "0-21-2-15-7-18-8-10-9-4-14-42-26-12-45-3-6-17-16-40-41-20-28-13-37-30-29-47-49-11-31-44-23-27-19-24-36-33-5-43-35-34-25-38-46-32-1-22-48-39-51-55-57-52-50-56-59-53-58-54-\n",
            "\n",
            "Tabla Promedio MSE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-35-aa1fdb7aca1a>:108: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  mse_dict = result_set.groupby('dataset').apply(lambda x: mean_squared_error(x['real_eval']/3, x['gpt_eval']/3)).to_dict()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                                                                                          Prompt  \\\n",
              "0  {\"context\": \"context.txt\", \"question\": \"question.txt\", \"answer\": \"answer.txt\", \"instructions\": {\"score\": \"score_single.txt\"}}   \n",
              "\n",
              "        All  C1-OscarBadAnswers20    C2-Nan  C2-Sample100  C3-Sample100  \n",
              "0  0.055652              0.063213  0.079496      0.038563      0.038039  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6f0aeacb-74b7-468a-8d97-cf0f312e930a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prompt</th>\n",
              "      <th>All</th>\n",
              "      <th>C1-OscarBadAnswers20</th>\n",
              "      <th>C2-Nan</th>\n",
              "      <th>C2-Sample100</th>\n",
              "      <th>C3-Sample100</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{\"context\": \"context.txt\", \"question\": \"question.txt\", \"answer\": \"answer.txt\", \"instructions\": {\"score\": \"score_single.txt\"}}</td>\n",
              "      <td>0.055652</td>\n",
              "      <td>0.063213</td>\n",
              "      <td>0.079496</td>\n",
              "      <td>0.038563</td>\n",
              "      <td>0.038039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f0aeacb-74b7-468a-8d97-cf0f312e930a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6f0aeacb-74b7-468a-8d97-cf0f312e930a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6f0aeacb-74b7-468a-8d97-cf0f312e930a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"x = experiment(df, prompts, repetitions=1, eval_function=\\\"map\\\", eval_params=None, train_set_size=40, test_set_size=60, seed=42, model=\\\"gpt-4o-mini\\\", temperature=0\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"{\\\"context\\\": \\\"context.txt\\\", \\\"question\\\": \\\"question.txt\\\", \\\"answer\\\": \\\"answer.txt\\\", \\\"instructions\\\": {\\\"score\\\": \\\"score_single.txt\\\"}}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"All\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.055651988486237654,\n        \"max\": 0.055651988486237654,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.055651988486237654\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"C1-OscarBadAnswers20\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.06321272756068451,\n        \"max\": 0.06321272756068451,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.06321272756068451\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"C2-Nan\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.0794962146833768,\n        \"max\": 0.0794962146833768,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0794962146833768\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"C2-Sample100\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.03856345578399615,\n        \"max\": 0.03856345578399615,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.03856345578399615\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"C3-Sample100\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.03803877292327917,\n        \"max\": 0.03803877292327917,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.03803877292327917\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tabla Desviación estándar\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                                                                                          Prompt  \\\n",
              "0  {\"context\": \"context.txt\", \"question\": \"question.txt\", \"answer\": \"answer.txt\", \"instructions\": {\"score\": \"score_single.txt\"}}   \n",
              "\n",
              "   All  C1-OscarBadAnswers20  C2-Nan  C2-Sample100  C3-Sample100  \n",
              "0  0.0                   0.0     0.0           0.0           0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-801178cd-644e-4147-88c0-fc86190f2b8a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prompt</th>\n",
              "      <th>All</th>\n",
              "      <th>C1-OscarBadAnswers20</th>\n",
              "      <th>C2-Nan</th>\n",
              "      <th>C2-Sample100</th>\n",
              "      <th>C3-Sample100</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{\"context\": \"context.txt\", \"question\": \"question.txt\", \"answer\": \"answer.txt\", \"instructions\": {\"score\": \"score_single.txt\"}}</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-801178cd-644e-4147-88c0-fc86190f2b8a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-801178cd-644e-4147-88c0-fc86190f2b8a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-801178cd-644e-4147-88c0-fc86190f2b8a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"x = experiment(df, prompts, repetitions=1, eval_function=\\\"map\\\", eval_params=None, train_set_size=40, test_set_size=60, seed=42, model=\\\"gpt-4o-mini\\\", temperature=0\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"{\\\"context\\\": \\\"context.txt\\\", \\\"question\\\": \\\"question.txt\\\", \\\"answer\\\": \\\"answer.txt\\\", \\\"instructions\\\": {\\\"score\\\": \\\"score_single.txt\\\"}}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"All\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"C1-OscarBadAnswers20\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"C2-Nan\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"C2-Sample100\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"C3-Sample100\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r Results.zip Results/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElKesxXQDZq2",
        "outputId": "3c18ebe3-80d3-4318-f5d2-0e3b75fe799a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: Results/ (stored 0%)\n",
            "  adding: Results/20240906-1645.json (deflated 62%)\n",
            "  adding: Results/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: Results/20240906-1525.json (deflated 65%)\n",
            "  adding: Results/20240906-1538.json (deflated 65%)\n",
            "  adding: Results/20240906-1529.json (deflated 65%)\n",
            "  adding: Results/20240906-1519.json (deflated 65%)\n",
            "  adding: Results/20240906-1534.json (deflated 65%)\n",
            "  adding: Results/20240906-1641.json (deflated 62%)\n",
            "  adding: Results/20240906-1522.json (deflated 65%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extras"
      ],
      "metadata": {
        "id": "obIJUahMBuuR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparar MSE por temperatura"
      ],
      "metadata": {
        "id": "5jvZTPFRDYj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Directorio donde se encuentran los archivos JSON\n",
        "json_folder = 'Results'\n",
        "\n",
        "# Lista para guardar los valores de MSE y las temperaturas\n",
        "mse_values = []\n",
        "temperatures = []\n",
        "\n",
        "# Recorrer todos los archivos en la carpeta\n",
        "for filename in os.listdir(json_folder):\n",
        "    if filename.endswith('.json'):\n",
        "        # Leer cada archivo JSON\n",
        "        with open(os.path.join(json_folder, filename), 'r') as file:\n",
        "            data = json.load(file)\n",
        "\n",
        "            # Extraer valores de MSE[\"All\"]\n",
        "            mse_all_values = [stat[\"MSE\"][\"All\"] for stat in data[\"results\"][0][\"stats\"]]\n",
        "\n",
        "            # Guardar los valores de MSE y las temperaturas\n",
        "            mse_values.append(mse_all_values)\n",
        "            temperatures.append(data[\"temperature\"])\n",
        "\n",
        "# Ordenar los valores de MSE y las temperaturas según la temperatura\n",
        "temperatures, mse_values = zip(*sorted(zip(temperatures, mse_values)))\n",
        "\n",
        "# Crear un boxplot con los datos ordenados por temperatura\n",
        "plt.boxplot(mse_values, labels=[temp for temp in temperatures])\n",
        "plt.title('MSE obtenido por temperatura')\n",
        "plt.ylabel('MSE')\n",
        "plt.xlabel('Temperatura')\n",
        "plt.xticks(rotation=45, ha='right')  # Girar las etiquetas para mejor visibilidad\n",
        "plt.tight_layout()  # Ajustar el layout para que no se corten las etiquetas\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "ajdJS1G6CREG",
        "outputId": "c303389f-6ce4-4430-ecff-94a40e5c1e44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}