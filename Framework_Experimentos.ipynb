{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8wQ5glA48ROnmFfGzRc4H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OscarRojasG/Experimentos-GPTValidator/blob/main/Framework_Experimentos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Framework para experimentos GPTValidator"
      ],
      "metadata": {
        "id": "wAu6OvJu7hBs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El objetivo de este framework consiste en proporcionar un conjunto de funciones previamente implementadas para facilitar la evaluación y comparación de prompts para el proyecto EvaluAI."
      ],
      "metadata": {
        "id": "3ixHfITmnzVF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instrucciones de uso"
      ],
      "metadata": {
        "id": "NtGhcZhln18k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En primer lugar, es necesario ejecutar **TODAS** las celdas de código de la sección Implementación."
      ],
      "metadata": {
        "id": "ExLyT4Rm3Bhx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Cargar dataset"
      ],
      "metadata": {
        "id": "pV4tFiFvGSY4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Subir archivo .xlsx con todos los datasets combinados. Debe contener al menos 5 columnas con los siguientes datos:\n",
        "    * **Contexto** (context): Conocimiento previo que necesita el modelo para evaluar la respuesta del estudiante.\n",
        "    * **Pregunta** (question)\n",
        "    * **Respuesta** (answer): Respuesta del estudiante\n",
        "    * **Evaluación manual** (real_eval): Puntaje de referencia dado por uno o más evaluadores humanos.\n",
        "    * **Dataset de origen** (dataset): Dataset del cual provienen los datos para una fila en particular.\n",
        "\n",
        "2. Especificar el nombre de las columnas en un diccionario con la siguiente estructura (ejemplo):\n",
        "\n",
        "    ```\n",
        "    column_data = {\n",
        "            \"context\": \"Contexto\",\n",
        "            \"question\": \"Pregunta\",\n",
        "            \"answer\": \"Respuesta\",\n",
        "            \"real_eval\": \"EvalManual\",\n",
        "            \"dataset\": \"Dataset\"\n",
        "    }\n",
        "    ```\n",
        "\n",
        "3. Cargar dataset con la función `load_dataset(path, sheet_name, column_data)`\n",
        "\n",
        "    - **path** - Ruta del archivo xlsx a utilizar.\n",
        "    - **sheet_name** - Nombre de la hoja donde se encuentran los datos.\n",
        "    - **column_data** - Diccionario explicado en el punto anterior."
      ],
      "metadata": {
        "id": "AKWV5dgcCGKv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Definir miniprompts a evaluar"
      ],
      "metadata": {
        "id": "Q0nCnpHNaR9O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Subir carpeta con la colección de miniprompts. Los miniprompts deben estar definidos en archivos txt y agrupados en carpetas por categoría (ejemplos, analysis, feedback, etc.). **Se pueden crear nuevas carpetas sin restricciones**.\n",
        "\n",
        "2. Seleccionar los miniprompts a utilizar para la generación de los prompts. Estos deben ser definidos en un diccionario donde la clave corresponde al nombre de la carpeta y el valor es el nombre del archivo txt con el miniprompt correspondiente. Se puede utilizar el comodín * como valor para probar con todos los miniprompts de esa carpeta.\n",
        "\n",
        "    ```\n",
        "    prompt_data = {\n",
        "        \"examples\": \"examples_XX.txt\",\n",
        "        \"context\": \"knowledge_XX.txt\",\n",
        "        \"question\": \"...\",\n",
        "        \"answer\": \"...\",\n",
        "        \"instructions\": {\n",
        "            \"analysis\": \"*\",\n",
        "            \"feedback\": \"...\",\n",
        "            \"score\": \"...\",\n",
        "        }\n",
        "    }\n",
        "    ```\n",
        "\n",
        "3. Cargar prompts con la función ``generate_prompts(prompt_data, prompt_folder)``\n",
        "\n",
        "    - **prompt_data** - Diccionario explicado en el punto anterior.\n",
        "    - **prompt_folder** - Ruta de la carpeta donde se encuentra la colección de miniprompts. (Ej: Experiments/Miniprompts)\n",
        "\n",
        "#### Notas adicionales\n",
        "\n",
        "En caso de tener problemas al subir la carpeta a colab, subirla como zip y ejecutar el comando\n",
        "\n",
        "```\n",
        "!unzip nombre_carpeta.zip\n",
        "```\n",
        "\n",
        "Los criterios deben ser definidos en las primeras líneas del miniprompt score con el símbolo $.\n",
        "\n",
        "```\n",
        "$correctness\n",
        "$completeness\n",
        "$clarity\n",
        "(score) Assign a score between 0 and 10 to different criteria based on the student's answer and the generated feedback. Criteria are: correctness, completeness, clarity.\n",
        "```\n",
        "\n",
        "Las instrucciones de salida de algunos miniprompts como feedback y analysis, se pueden definir usando el símbolo # en la primera línea del archivo.\n",
        "\n",
        "```\n",
        "#very detailed feedback considering previous analysis (in spanish, within 150 words)\n",
        "(feedback)\n",
        "Provide Feedback to the student considering the analysis. **Do not be strict at all**.\n",
        "It is enough that the student answer correctly and more or less completely the question. **Do not ask for additional information**.\n",
        "Start by stating whether the answer is good/excelent or poor/insatisfactory.\n",
        "If the answer is good/excelent, affirm the student's understanding and potentially add a brief note on why their response was particularly effective or comprehensive.\n",
        "If the answer is poor/insatisfactory, clearly identify the inaccuracies or errors. Provide specific suggestions on how to improve, ensuring the feedback is constructive.\n",
        "Within 150 words. In Spanish.\n",
        "```"
      ],
      "metadata": {
        "id": "T2uhIxI0JW1t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Realizar experimento"
      ],
      "metadata": {
        "id": "a2SphdjqaUJE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluar los prompts con la función ``experiment(dataset, prompts, repetitions, eval_function, eval_params=None, train_set_size=60, test_set_size=100, seed=42)``\n",
        "\n",
        "- **dataset** - Objeto de tipo DataFrame cargado en el punto 1.\n",
        "- **prompts** - Colección de prompts cargados en el punto 2.\n",
        "- **repetitions** - Número de repeticiones que se desea realizar la evaluación de cada prompt. Cada evaluación implica un nuevo conjunto de entrenamiento/prueba.\n",
        "- **eval_function** - Método para convertir los puntajes GPT a escala 0-3. Puede ser \"cuts\" o \"map\".\n",
        "- **eval_params** - Lista de parámetros usados para la conversión de puntajes. Son distintos dependiendo del valor de *eval_function*.\n",
        "- **train_set_size** - Tamaño total $n$ del conjunto de entrenamiento. El conjunto de entrenamiento se encuentra compuesto por $n/4$ muestras de cada puntaje (balanceado).\n",
        "- **test_set_size** - Tamaño total del conjunto de prueba (no balanceado).\n",
        "- **seed** - Semilla utilizada para la creación de los conjuntos de prueba y entrenamiento.\n",
        "\n",
        "Para ``eval_function = \"cuts\"`` los parámetros siguen la estructura $[w_1, w_2, ..., w_m, a, b, c]$\n",
        "\n",
        "Para ``eval_function = \"map\"`` los parámetros siguen la estructura $[w_1, w_2, ..., w_m, a, b]$\n",
        "\n",
        "En ambos casos, los primeros $m$ parámetros corresponden a las ponderaciones de cada criterio (en el mismo orden en que fueron definidos dentro del miniprompt score). La suma de las ponderaciones debe ser 1. En caso de no haber criterios, existe una única ponderación igual a 1.\n",
        "\n",
        "Para la evaluación por cortes, los parámetros $a, b, c$ corresponden a los puntajes de corte ordenados de menor a mayor. Por ejemplo, para un prompt con 2 criterios, una lista de parámetros válidos podría ser $[0.7, 0.3, 3, 5, 7]$\n",
        "\n",
        "Para la evaluación por mapeo, los parámetros $a, b$ representan los puntajes en escala 0-10 que corresponden a los puntajes 1 y 2 en escala 0-3. Por ejemplo:\n",
        "\n",
        "$\\text{map}(0) = 0$\n",
        "\n",
        "$\\text{map}(a) = 1$\n",
        "\n",
        "$\\text{map}(b) = 2$\n",
        "\n",
        "$\\text{map}(10) = 3$"
      ],
      "metadata": {
        "id": "QjpkYTTfa_ka"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementación"
      ],
      "metadata": {
        "id": "IKjPLvH1RBpQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28 &> /dev/null\n",
        "!pip install openai-multi-client &> /dev/null\n",
        "!git clone https://github.com/rilianx/GPTEvaluator &> /dev/null"
      ],
      "metadata": {
        "id": "Blf2NA6gZUN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cargar dataset"
      ],
      "metadata": {
        "id": "qWo35VtxRK23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "# Muestra información relevante del dataset\n",
        "def show_dataset_info(dataset):\n",
        "    display(dataset.head())\n",
        "    print()\n",
        "    print(dataset.value_counts(\"real_eval\"), end=\"\\n\\n\")\n",
        "    print(dataset.value_counts(\"dataset\"))\n",
        "    pass\n",
        "\n",
        "# Carga un dataset a partir de un archivo xlsx y valida sus columnas\n",
        "def load_dataset(path, sheet_name, column_data):\n",
        "    df = pd.read_excel(path, sheet_name=sheet_name)\n",
        "\n",
        "    mandatory_cols = [\"context\", \"question\", \"answer\", \"real_eval\", \"dataset\"]\n",
        "    for key in mandatory_cols:\n",
        "        if key not in column_data.keys():\n",
        "            raise Exception(f\"Error: Debe especificar la columna para la variable {key}\")\n",
        "\n",
        "        value = column_data[key]\n",
        "        if value not in df.columns:\n",
        "            raise Exception(f\"Error: La columna {value} no existe\")\n",
        "\n",
        "        df = df.rename(columns={value: key})\n",
        "\n",
        "    df = df[mandatory_cols]\n",
        "    show_dataset_info(df)\n",
        "    return df"
      ],
      "metadata": {
        "id": "-vAnT6rTr6cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generación prompts"
      ],
      "metadata": {
        "id": "mqHdu2soRNEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "import copy\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "\n",
        "class Prompt():\n",
        "    def __init__(self, structure, instructions, base_folder):\n",
        "        self.structure = structure\n",
        "        self.instructions = instructions\n",
        "        self.base_folder = base_folder\n",
        "        self.raw_text_structure = None\n",
        "        self.text_structure = None\n",
        "        self.criteria = None\n",
        "        self.output_instructions = None\n",
        "        self.prompt = None\n",
        "\n",
        "        self.read_files()\n",
        "        self.extract_metadata()\n",
        "        self.build_prompt()\n",
        "\n",
        "    # Retorna la estructura base del prompt (diccionario)\n",
        "    def base_structure(self):\n",
        "        structure = copy.deepcopy(self.structure)\n",
        "        structure['instructions'] = {}\n",
        "        for i in self.instructions:\n",
        "            structure['instructions'][i] = structure[i]\n",
        "            structure.pop(i, None)\n",
        "        return structure\n",
        "\n",
        "    # Crea un diccionario con el contenido de cada archivo en la estructura\n",
        "    def read_files(self):\n",
        "        self.raw_text_structure = copy.deepcopy(self.structure)\n",
        "\n",
        "        for key, value in self.raw_text_structure.items():\n",
        "            if key == \"instructions\": continue\n",
        "\n",
        "            path = f\"{self.base_folder}/{key}/{value}\"\n",
        "            try:\n",
        "                self.raw_text_structure[key] = open(path, 'r', encoding='utf-8').read()\n",
        "                self.raw_text_structure[key] += \"\\n\\n\"\n",
        "            except:\n",
        "                raise Exception(f\"Error: El archivo {path} no existe\")\n",
        "\n",
        "    # Extrae metadatos de los archivos como los criterios e instrucciones de salida\n",
        "    def extract_metadata(self):\n",
        "        self.text_structure = copy.deepcopy(self.raw_text_structure)\n",
        "\n",
        "        if 'score' in self.text_structure:\n",
        "            lines = self.text_structure['score'].split('\\n')\n",
        "            self.criteria = [line[1:] for line in lines if line.startswith('$')]\n",
        "            text = [line for line in lines if not line.startswith('$')]\n",
        "            self.text_structure['score'] = '\\n'.join(text)\n",
        "\n",
        "        self.output_instructions = {}\n",
        "        output_mp = [\"analysis\", \"feedback\"]\n",
        "        for key in output_mp:\n",
        "            if key not in self.text_structure: continue\n",
        "            value = self.text_structure[key]\n",
        "\n",
        "            if value.startswith('#'):\n",
        "                m = re.search(r'#(.*?)\\n', value).group(1)\n",
        "                self.output_instructions[key] = m\n",
        "                self.text_structure[key] = '\\n'.join(value.split('\\n')[1:])\n",
        "\n",
        "    # Construye el prompt en formato string\n",
        "    def build_prompt(self):\n",
        "        self.prompt = \"\"\n",
        "        for key, value in self.text_structure.items():\n",
        "            self.prompt += value\n",
        "\n",
        "        output = \"I expect a dict in python as answer: {{\"\n",
        "        for key, value in self.output_instructions.items():\n",
        "            output += f'\"{key}\": \\'{value}\\', '\n",
        "\n",
        "        if len(self.criteria) > 0:\n",
        "            for c in self.criteria:\n",
        "                output += f'\"{c}\": {c}_score, '\n",
        "            output = output[:-2]\n",
        "        else:\n",
        "            output += '\"score\": score'\n",
        "\n",
        "        output += \"}}\\n\\nPython dict:\"\n",
        "        self.prompt += output\n",
        "\n",
        "\n",
        "# Procesa y elimina los diccionarios anidados de prompt_data\n",
        "def normalize_prompt_dict(prompt_data):\n",
        "    instructions = []\n",
        "    if \"instructions\" in prompt_data:\n",
        "        for (key, value) in prompt_data[\"instructions\"].items():\n",
        "            prompt_data[key] = value\n",
        "            instructions.append(key)\n",
        "\n",
        "    prompt_data[\"instructions\"] = \"Instructions:\\n\"\n",
        "    return prompt_data, instructions\n",
        "\n",
        "# Retorna la lista de archivos para reemplazar el comodín *\n",
        "def expand_prompt_data(prompt_data, prompt_folder):\n",
        "    wildcard_field = None\n",
        "    for key, value in prompt_data.items():\n",
        "        if value == \"*\":\n",
        "            wildcard_field = key\n",
        "            break\n",
        "\n",
        "    if not wildcard_field: return None, None\n",
        "\n",
        "    wildcard_files = []\n",
        "    path = f\"{prompt_folder}/{wildcard_field}\"\n",
        "    for file in sorted(os.listdir(path)):\n",
        "        if os.path.isfile(os.path.join(path, file)):\n",
        "            wildcard_files.append(file)\n",
        "\n",
        "    return wildcard_field, wildcard_files\n",
        "\n",
        "# Genera una lista con los prompts a evaluar\n",
        "def generate_prompts(prompt_data, prompt_folder):\n",
        "    template, instructions = normalize_prompt_dict(prompt_data)\n",
        "    wildcard_field, wildcard_files = expand_prompt_data(template, prompt_folder)\n",
        "    prompts = []\n",
        "\n",
        "    if wildcard_field == None:\n",
        "        prompt = Prompt(template, instructions, prompt_folder)\n",
        "        prompts.append(prompt)\n",
        "        print(prompt.prompt)\n",
        "        return prompts\n",
        "\n",
        "    for file in wildcard_files:\n",
        "        structure = copy.deepcopy(template)\n",
        "        structure[wildcard_field] = file\n",
        "        prompt = Prompt(structure, instructions, prompt_folder)\n",
        "        prompts.append(prompt)\n",
        "\n",
        "    # Visualizar\n",
        "    template = copy.deepcopy(prompts[0])\n",
        "    template.raw_text_structure[wildcard_field] = f\"{{{wildcard_field}}}\\n\\n\"\n",
        "    template.extract_metadata()\n",
        "    template.build_prompt()\n",
        "    print(template.prompt)\n",
        "\n",
        "    print(f\"\\n\\nArchivos a utilizar ({len(wildcard_files)}):\\n\")\n",
        "    print(\"\\n\".join(wildcard_files))\n",
        "\n",
        "    return prompts"
      ],
      "metadata": {
        "id": "uuM-IEVRPDBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimización parámetros"
      ],
      "metadata": {
        "id": "F-PYuT2HRSHu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.optimize import differential_evolution\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "### Optimización de cortes y ponderaciones ###\n",
        "class CutsEvaluator():\n",
        "    @staticmethod\n",
        "    def f(x, theta):\n",
        "        score = np.dot(x, theta[:-3])\n",
        "        y_pred = np.where(score > theta[-1], 3, np.where(score > theta[-2], 2, np.where(score > theta[-3], 1, 0)))\n",
        "        return y_pred\n",
        "\n",
        "class CutsOptimizer():\n",
        "    def __init__(self, criteria_scores, real_scores):\n",
        "        bounds =  [(0, 1) for _ in range(len(criteria_scores[0]))] + [(1, 4), (4, 7), (7, 10)]\n",
        "        result = differential_evolution(self.error, bounds, args=(criteria_scores, real_scores), seed=1, strategy='rand1exp', mutation=(0,1), recombination=1)\n",
        "        self.params = result.x.tolist()\n",
        "\n",
        "    def error(self, theta, x, y):\n",
        "        y_pred = CutsEvaluator.f(x, theta)\n",
        "        mse = np.mean((y - y_pred) ** 2)\n",
        "        penalty = 1e6 * np.abs(np.sum(theta[:-3]) - 1)\n",
        "        return mse + penalty\n",
        "\n",
        "\n",
        "####### Optimización mapeo de puntajes ########\n",
        "class MapEvaluator():\n",
        "    @staticmethod\n",
        "    def inverse_map(y_pred, theta):\n",
        "        a, b = theta[-2], theta[-1]\n",
        "        def single_inverse_map(y):\n",
        "            if y <= a:\n",
        "                return y / a\n",
        "            elif a < y <= b:\n",
        "                return 1 + (y - a) / (b - a)\n",
        "            else:\n",
        "                return 2 + (y - b) / (10 - b)\n",
        "\n",
        "        return np.array([single_inverse_map(y) for y in y_pred])\n",
        "\n",
        "    @staticmethod\n",
        "    def f(x, theta):\n",
        "        y_pred = np.dot(x, theta[:-2])\n",
        "        return MapEvaluator.inverse_map(y_pred, theta)\n",
        "\n",
        "class MapOptimizer():\n",
        "    def __init__(self, criteria_scores, real_scores):\n",
        "        bounds =  [(0, 1) for _ in range(len(criteria_scores[0]))] + [(1, 9), (1, 9)]\n",
        "        result = differential_evolution(self.error, bounds, args=(criteria_scores, real_scores), seed=1, strategy='rand1exp', mutation=(0,1), recombination=1)\n",
        "        self.params = result.x.tolist()\n",
        "\n",
        "    def error(self, theta, x, y):\n",
        "        y_pred = MapEvaluator.f(x, theta)\n",
        "        mse = np.sum((y - y_pred) ** 2)\n",
        "        penalty = 1e6 * np.abs(np.sum(theta[:-2]) - 1)\n",
        "        a, b = theta[-2], theta[-1]\n",
        "        if a > b: penalty += (a - b) * 1e5\n",
        "        return mse + penalty\n",
        "\n",
        "# Convierte una lista de diccionarios en una lista de tuplas\n",
        "def get_x(gpt_dicts, criteria):\n",
        "    if len(criteria) > 0:\n",
        "        return [\n",
        "            [gpt_dict[key] for key in criteria]\n",
        "            for gpt_dict in gpt_dicts\n",
        "        ]\n",
        "\n",
        "    return [[gpt_dict['score']] for gpt_dict in gpt_dicts]\n",
        "\n",
        "# Obtiene los parámetros óptimos para disminuir el error\n",
        "def optimize_params(gpt_dicts, real_scores, criteria, eval_function):\n",
        "    criteria_scores = get_x(gpt_dicts, criteria)\n",
        "    if eval_function == \"map\":\n",
        "        optimizer = MapOptimizer(criteria_scores, real_scores)\n",
        "    if eval_function == \"cuts\":\n",
        "        optimizer = CutsOptimizer(criteria_scores, real_scores)\n",
        "\n",
        "    return optimizer.params\n",
        "\n",
        "# Convierte los puntajes GPT a puntajes normalizados (0-3)\n",
        "def convert_gpt_scores(gpt_dicts, real_scores, criteria, eval_function, eval_params):\n",
        "    criteria_scores = get_x(gpt_dicts, criteria)\n",
        "    if eval_function == \"map\":\n",
        "        return MapEvaluator.f(criteria_scores, eval_params)\n",
        "    if eval_function == \"cuts\":\n",
        "        return CutsEvaluator.f(criteria_scores, eval_params)"
      ],
      "metadata": {
        "id": "9C0xfFjsE__M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt_dicts = [\n",
        "    {\n",
        "        'score': 9\n",
        "    },\n",
        "    {\n",
        "        'score': 8\n",
        "    },\n",
        "    {\n",
        "        'score': 4\n",
        "    }\n",
        "]\n",
        "\n",
        "real_scores = [3, 2, 1]\n",
        "criteria = []\n",
        "\n",
        "eval_params = optimize_params(gpt_dicts, real_scores, criteria, \"map\")\n",
        "print(eval_params)\n",
        "convert_gpt_scores(gpt_dicts, real_scores, criteria, \"map\", eval_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2v7vABfitpf",
        "outputId": "f3662d09-2fbb-44fd-c92d-a94dafa6de03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.0, 4.000037881048441, 7.4999888512711514]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.60000178, 2.20000357, 0.99999053])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt_dicts = [\n",
        "    {\n",
        "        'relevance': 8,\n",
        "        'clarity': 9,\n",
        "        'precision': 7\n",
        "    },\n",
        "    {\n",
        "        'relevance': 8,\n",
        "        'clarity': 5,\n",
        "        'precision': 3\n",
        "    },\n",
        "    {\n",
        "        'relevance': 4,\n",
        "        'clarity': 1,\n",
        "        'precision': 2\n",
        "    }\n",
        "]\n",
        "\n",
        "real_scores = [3, 2, 1]\n",
        "criteria = ['relevance', 'clarity', 'precision']\n",
        "\n",
        "eval_params = optimize_params(gpt_dicts, real_scores, criteria, \"map\")\n",
        "print(eval_params)\n",
        "convert_gpt_scores(gpt_dicts, real_scores, criteria, \"map\", eval_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qU9hjjTBQ6RI",
        "outputId": "f9815772-ad9e-4d31-8a91-447b9fb29626"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.007063405579985471, 0.9736191598576271, 0.01931743420011689, 1.0250005164759606, 4.822870728613848]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.79801581, 2.03084424, 1.00408311])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experimentos"
      ],
      "metadata": {
        "id": "H3mOMBM_S_QH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from GPTEvaluator.GPTEvaluator import chat_gpt_multiple\n",
        "from openai_multi_client import OpenAIMultiClient\n",
        "import openai\n",
        "from google.colab import userdata\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import os\n",
        "from datetime import datetime, timedelta\n",
        "import json\n",
        "import numpy\n",
        "\n",
        "openai.api_key = userdata.get('api_key')\n",
        "\n",
        "class SetPair():\n",
        "    def __init__(self, train_set, test_set):\n",
        "        self.train_set = train_set\n",
        "        self.test_set = test_set\n",
        "\n",
        "# Divide el dataset en conjuntos de entrenamiento/prueba\n",
        "def generate_sets(dataset, repetitions, train_set_size, test_set_size, seed=42):\n",
        "    sets = []\n",
        "    random.seed(seed)\n",
        "\n",
        "    group_size = train_set_size // 4\n",
        "    for i in range(repetitions):\n",
        "        proportions = df['real_eval'].value_counts(normalize=True)\n",
        "        samples_per_class = (proportions * test_set_size).round().astype(int)\n",
        "        test_set = df.groupby('real_eval', group_keys=False).apply(lambda x: x.sample(samples_per_class[x.name], random_state=random.randint(0,100000)))\n",
        "        test_set = test_set.reset_index(drop=True)\n",
        "\n",
        "        train_set = dataset[~dataset.index.isin(test_set.index)]\n",
        "        train_set = train_set.groupby('real_eval', group_keys=False).apply(lambda x: x.sample(group_size, random_state=random.randint(0,100000)))\n",
        "        train_set = train_set.reset_index(drop=True)\n",
        "        sets.append(SetPair(train_set, test_set))\n",
        "\n",
        "    return sets\n",
        "\n",
        "# Genera las respuestas con ChatGPT\n",
        "def eval_gpt(df, prompt, model, temperature):\n",
        "    api = OpenAIMultiClient(endpoint=\"chats\", data_template={\"model\": model, \"temperature\": temperature, \"n\": 1, \"timeout\":10}, concurrency=50, wait_interval=1, max_retries=3, retry_max=10, retry_multiplier=1)\n",
        "\n",
        "    texts = []\n",
        "    for i, row in df.iterrows():\n",
        "        text = prompt.format(Question=row['question'], Answer=row['answer'], Context=row['context'])\n",
        "        texts.append(text)\n",
        "\n",
        "    answers_gpt = chat_gpt_multiple(api, texts)\n",
        "    return answers_gpt\n",
        "\n",
        "# Extrae diccionario de salida de las respuestas GPT\n",
        "def extract_dicts(answers_gpt):\n",
        "    pattern = r'\\{[^{}]+\\}'\n",
        "\n",
        "    gpt_dicts = []\n",
        "    for answer_gpt in answers_gpt:\n",
        "        try:\n",
        "            answer = re.findall(pattern, answer_gpt[0])[0]\n",
        "            gpt_dicts.append(eval(answer))\n",
        "        except Exception as e:\n",
        "            print(f\"Error al extraer diccionario. Respuesta GPT: \\n{answer_gpt[0]}\\n\\n\")\n",
        "            gpt_dicts.append(None)\n",
        "\n",
        "    return gpt_dicts\n",
        "\n",
        "# Elimina filas del dataset donde hubo errores en la salida GPT\n",
        "def clean_set(dataset, gpt_dicts, criteria):\n",
        "    for i in reversed(range(len(gpt_dicts))):\n",
        "        if gpt_dicts[i] is None:\n",
        "            gpt_dicts.pop(i)\n",
        "            dataset.drop(index=i, inplace=True)\n",
        "        elif all(key in gpt_dicts[i] for key in criteria) == False:\n",
        "            print(gpt_dicts[i])\n",
        "            gpt_dicts.pop(i)\n",
        "            dataset.drop(index=i, inplace=True)\n",
        "\n",
        "# Obtiene los puntajes reales de un dataset\n",
        "def get_real_scores(dataset):\n",
        "    return dataset['real_eval'].tolist()\n",
        "\n",
        "# Prepara el set de entrenamiento y obtiene los parámetros óptimos para disminuir el error\n",
        "def train(train_set, prompt, criteria, eval_function, model, temperature):\n",
        "    train_set = train_set.copy()\n",
        "    answers_gpt = eval_gpt(train_set, prompt, model, temperature)\n",
        "    gpt_dicts = extract_dicts(answers_gpt)\n",
        "    clean_set(train_set, gpt_dicts, criteria)\n",
        "    real_scores = get_real_scores(train_set)\n",
        "    return optimize_params(gpt_dicts, real_scores, criteria, eval_function)\n",
        "\n",
        "# Prepara el set de prueba y calcula las métricas del modelo preentrenado usando el conjunto de prueba\n",
        "def test(test_set, prompt, criteria, eval_function, eval_params, model, temperature):\n",
        "    test_set = test_set.copy()\n",
        "    answers_gpt = eval_gpt(test_set, prompt, model, temperature)\n",
        "    gpt_dicts = extract_dicts(answers_gpt)\n",
        "    clean_set(test_set, gpt_dicts, criteria)\n",
        "    real_scores = get_real_scores(test_set)\n",
        "    pred_scores = convert_gpt_scores(gpt_dicts, real_scores, criteria, eval_function, eval_params)\n",
        "\n",
        "    result_set = test_set.copy(deep=True)\n",
        "    result_set['gpt_eval'] = pred_scores\n",
        "\n",
        "    df_dicts = pd.DataFrame(gpt_dicts)\n",
        "    result_set = pd.concat([result_set, df_dicts], axis=1)\n",
        "\n",
        "    return calculate_mse(result_set), result_set\n",
        "\n",
        "# Retorna un dataset con el MSE por grupo\n",
        "def calculate_mse(result_set):\n",
        "    mse_dict = result_set.groupby('dataset').apply(lambda x: mean_squared_error(x['real_eval'], x['gpt_eval'])).to_dict()\n",
        "    overall_mse = mean_squared_error(result_set['real_eval'], result_set['gpt_eval'])\n",
        "    mse_dict['All'] = overall_mse\n",
        "    return mse_dict\n",
        "\n",
        "# Evalúa una lista de prompts obtienendo el MSE promedio en M repeticiones\n",
        "def experiment(dataset, prompts, repetitions, eval_function, eval_params=None, train_set_size=40, test_set_size=60, seed=42, model=\"gpt-4o-mini\", temperature=0.1):\n",
        "    sets = generate_sets(dataset, repetitions, train_set_size, test_set_size, seed)\n",
        "    stats = []\n",
        "    full_df = pd.DataFrame()\n",
        "\n",
        "    for i, prompt_data in enumerate(prompts):\n",
        "        prompt = prompt_data.prompt\n",
        "        criteria = prompt_data.criteria\n",
        "        stats.append([])\n",
        "\n",
        "        for j in range(repetitions):\n",
        "            train_set = sets[j].train_set\n",
        "            test_set = sets[j].test_set\n",
        "\n",
        "            iter_params = eval_params\n",
        "            if not eval_params:\n",
        "                print(f\"Entrenando Prompt {i+1} con Train Set {j+1}\")\n",
        "                iter_params = train(train_set, prompt, criteria, eval_function, model, temperature)\n",
        "                print()\n",
        "\n",
        "            print(f\"Evaluando Prompt {i+1} con Test Set {j+1}\")\n",
        "            metrics, result_set = test(test_set, prompt, criteria, eval_function, iter_params, model, temperature)\n",
        "            stats[i].append({\n",
        "                \"MSE\": metrics,\n",
        "                \"params\": iter_params\n",
        "            })\n",
        "            print()\n",
        "\n",
        "            result_set['prompt'] = prompt\n",
        "            result_set['repetition'] = j+1\n",
        "            full_df = pd.concat([full_df, result_set], ignore_index=True)\n",
        "\n",
        "    full_df.to_excel('final_set.xlsx', index=False)\n",
        "    filename = save_stats(prompts, stats, eval_function, train_set_size, test_set_size, model, temperature)\n",
        "    read_results(filename)\n",
        "\n",
        "    return stats\n",
        "\n",
        "# Guarda resultados en un archivo JSON\n",
        "def save_stats(prompts, stats, eval_function, train_set_size, test_set_size, model, temperature):\n",
        "    data = {\n",
        "        \"model\": model,\n",
        "        \"temperature\": temperature,\n",
        "        \"train_set_size\": train_set_size,\n",
        "        \"test_set_size\": test_set_size,\n",
        "        \"repetitions\": len(stats[0]),\n",
        "        \"results\": []\n",
        "    }\n",
        "\n",
        "    for i in range(len(stats)):\n",
        "        results = {\n",
        "            \"prompt\": prompts[i].base_structure(),\n",
        "            \"stats\": stats[i]\n",
        "        }\n",
        "        data[\"results\"].append(results)\n",
        "\n",
        "    dir = \"Results\"\n",
        "    if not os.path.exists(dir):\n",
        "        os.makedirs(dir)\n",
        "\n",
        "    date = datetime.now() - timedelta(hours=4)\n",
        "    formatted_date = date.strftime('%Y%m%d-%H%M')\n",
        "    path = f'{dir}/{formatted_date}.json'\n",
        "    with open(path, 'w', encoding='utf-8') as file:\n",
        "        json.dump(data, file, ensure_ascii=False)\n",
        "\n",
        "    return path\n",
        "\n",
        "# Lee y muestra resultados de un archivo JSON\n",
        "def read_results(path):\n",
        "    with open(path, 'r', encoding='utf-8') as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    rows = []\n",
        "    for result in data[\"results\"]:\n",
        "        for i, stat in enumerate(result[\"stats\"]):\n",
        "            row = stat[\"MSE\"]\n",
        "            row[\"Prompt\"] = json.dumps(result[\"prompt\"])\n",
        "            row[\"Repetition\"] = i+1\n",
        "            rows.append(row)\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "    col = df.pop('Prompt')\n",
        "    df.insert(0, 'Prompt', col)\n",
        "    col = df.pop('All')\n",
        "    df.insert(1, 'All', col)\n",
        "\n",
        "    pd.set_option('display.max_columns', None)\n",
        "    pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "    # STD normalizado\n",
        "    def std(x): return np.std(x)\n",
        "    df_norm = df[['Repetition', 'Prompt', 'All']].copy()\n",
        "\n",
        "    mean_per_rep = df_norm[['Repetition', 'All']].groupby('Repetition', as_index=False).mean().reset_index(drop=True)\n",
        "    mean_per_rep.rename(columns={'All': 'Mean'}, inplace=True)\n",
        "    std_per_rep = df_norm[['Repetition', 'All']].groupby('Repetition', as_index=False).agg(std).reset_index(drop=True)\n",
        "    std_per_rep.rename(columns={'All': 'Std'}, inplace=True)\n",
        "\n",
        "    df_norm = df_norm.merge(mean_per_rep, on='Repetition', how='inner')\n",
        "    df_norm = df_norm.merge(std_per_rep, on='Repetition', how='inner')\n",
        "\n",
        "    df_norm['Norm'] = (df_norm['All'] - df_norm['Mean'])/df_norm['Std']\n",
        "    df_norm = df_norm[['Prompt', 'Norm']].groupby('Prompt', as_index=False).agg(Mean=('Norm', 'mean'), Std=('Norm', std)).reset_index(drop=True)\n",
        "    df_norm = df_norm.sort_values('Mean')\n",
        "\n",
        "    print(\"\\nTabla MSE normalizado\")\n",
        "    display(df_norm)\n",
        "\n",
        "    # STD sin normalizar\n",
        "    df_mean = df.drop(columns=[\"Repetition\"]).groupby('Prompt', as_index=False).mean().reset_index(drop=True)\n",
        "    df_std = df.drop(columns=[\"Repetition\"]).groupby('Prompt', as_index=False).agg(std).reset_index(drop=True)\n",
        "\n",
        "    df_mean = df_mean.loc[df_norm.index]\n",
        "    df_std = df_std.loc[df_norm.index]\n",
        "\n",
        "    print(\"\\nTabla Promedio MSE\")\n",
        "    display(df_mean)\n",
        "    print(\"\\nTabla Desviación estándar\")\n",
        "    display(df_std)\n",
        "\n",
        "    pd.reset_option('^display.', silent=True)"
      ],
      "metadata": {
        "id": "iXoEKV3qzn0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Espacio para experimentos"
      ],
      "metadata": {
        "id": "chb-5XuP2MRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "column_data = {\n",
        "    \"context\": \"Contexto simple\",\n",
        "    \"question\": \"Pregunta\",\n",
        "    \"answer\": \"Respuesta\",\n",
        "    \"real_eval\": \"Promedio Redondeado\",\n",
        "    \"dataset\": \"DataSet\"\n",
        "}\n",
        "\n",
        "df = load_dataset(\"datasets_v2.xlsx\", \"AllDatasets (1dif)\", column_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "id": "9THpDAIu2ZRj",
        "outputId": "c5774202-7324-48be-9774-8c28b1b1ee11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                             context  \\\n",
              "0  BFS es preferible en problemas que requieren e...   \n",
              "1  BFS es preferible en problemas que requieren e...   \n",
              "2  BFS es preferible en problemas que requieren e...   \n",
              "3  BFS es preferible en problemas que requieren e...   \n",
              "4  BFS explora nodos nivel por nivel, visitando p...   \n",
              "\n",
              "                                            question  \\\n",
              "0  ¿En qué tipo de problemas una búsqueda BFS pod...   \n",
              "1  ¿En qué tipo de problemas una búsqueda BFS pod...   \n",
              "2  ¿En qué tipo de problemas una búsqueda BFS pod...   \n",
              "3  ¿En qué tipo de problemas una búsqueda BFS pod...   \n",
              "4  ¿Cuál es la principal diferencia entre búsqued...   \n",
              "\n",
              "                                              answer  real_eval       dataset  \n",
              "0  El bfs es mucho mas util en ejecuciones cortas...          2  C3-Sample100  \n",
              "1  en una situación de resolución de un problema ...          2  C3-Sample100  \n",
              "2  en problemas donde pidan obtener el camino de ...          3  C3-Sample100  \n",
              "3  en problemas de grafos no ponderados ya que no...          3  C3-Sample100  \n",
              "4  La búsqueda por anchura tiene un procedimiento...          3  C3-Sample100  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-183aeb39-bb63-4656-baa1-7685d0748126\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>real_eval</th>\n",
              "      <th>dataset</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BFS es preferible en problemas que requieren e...</td>\n",
              "      <td>¿En qué tipo de problemas una búsqueda BFS pod...</td>\n",
              "      <td>El bfs es mucho mas util en ejecuciones cortas...</td>\n",
              "      <td>2</td>\n",
              "      <td>C3-Sample100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BFS es preferible en problemas que requieren e...</td>\n",
              "      <td>¿En qué tipo de problemas una búsqueda BFS pod...</td>\n",
              "      <td>en una situación de resolución de un problema ...</td>\n",
              "      <td>2</td>\n",
              "      <td>C3-Sample100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BFS es preferible en problemas que requieren e...</td>\n",
              "      <td>¿En qué tipo de problemas una búsqueda BFS pod...</td>\n",
              "      <td>en problemas donde pidan obtener el camino de ...</td>\n",
              "      <td>3</td>\n",
              "      <td>C3-Sample100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BFS es preferible en problemas que requieren e...</td>\n",
              "      <td>¿En qué tipo de problemas una búsqueda BFS pod...</td>\n",
              "      <td>en problemas de grafos no ponderados ya que no...</td>\n",
              "      <td>3</td>\n",
              "      <td>C3-Sample100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>BFS explora nodos nivel por nivel, visitando p...</td>\n",
              "      <td>¿Cuál es la principal diferencia entre búsqued...</td>\n",
              "      <td>La búsqueda por anchura tiene un procedimiento...</td>\n",
              "      <td>3</td>\n",
              "      <td>C3-Sample100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-183aeb39-bb63-4656-baa1-7685d0748126')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-183aeb39-bb63-4656-baa1-7685d0748126 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-183aeb39-bb63-4656-baa1-7685d0748126');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-89318cc0-051a-47f2-876a-0110fc53e515\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-89318cc0-051a-47f2-876a-0110fc53e515')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-89318cc0-051a-47f2-876a-0110fc53e515 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df = load_dataset(\\\"datasets_v2\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"context\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"BFS explora nodos nivel por nivel, visitando primero los m\\u00e1s cercanos al nodo inicial. DFS explora profundamente a lo largo de cada rama antes de retroceder.\",\n          \"BFS es preferible en problemas que requieren encontrar la soluci\\u00f3n m\\u00e1s corta, como el camino m\\u00e1s corto en un grafo no ponderado, ya que explora nodos nivel por nivel.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\\u00bfCu\\u00e1l es la principal diferencia entre b\\u00fasqueda en anchura (BFS) y b\\u00fasqueda en profundidad (DFS)?\",\n          \"\\u00bfEn qu\\u00e9 tipo de problemas una b\\u00fasqueda BFS podr\\u00eda ser mejor a una DFS? \\u00bfPor qu\\u00e9?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"en una situaci\\u00f3n de resoluci\\u00f3n de un problema que requiera un camino corto para llegar al objetivo, porque el BFS al ser b\\u00fasqueda en anchura, no necesitamos hacer muchas iteraciones hasta pasar al siguiente nodo como en la b\\u00fasqueda por profundidad ya que se va recorriendo desde afuera hacia adentro.\",\n          \"La b\\u00fasqueda por anchura tiene un procedimiento m\\u00e1s horizontal que vertical, ya que el m\\u00e9todo para recorrer es ver los nodos/datos vecinos en la estructura, siendo mejor para casos donde el dato a buscar puede estar dentro de los primeros niveles, en cambio, la b\\u00fasqueda en profundidad cambia totalmente el m\\u00e9todo de b\\u00fasqueda siendo este m\\u00e1s vertical que horizontal, partiendo de la ra\\u00edz y yendo a los hijos, esto es mejor para nodos/datos que pueden estar en los \\u00faltimos niveles.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"real_eval\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2,\n        \"max\": 3,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          3,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dataset\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"C3-Sample100\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "real_eval\n",
            "3    127\n",
            "2     75\n",
            "0     52\n",
            "1     36\n",
            "Name: count, dtype: int64\n",
            "\n",
            "dataset\n",
            "C2-Nan                  92\n",
            "C3-Sample100            91\n",
            "C2-Sample100            90\n",
            "C1-OscarBadAnswers20    17\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_data = {\n",
        "    \"question\": \"question.txt\",\n",
        "    \"answer\": \"answer.txt\",\n",
        "    \"instructions\": {\n",
        "        \"score\": \"score_single.txt\"\n",
        "    }\n",
        "}\n",
        "\n",
        "prompt_folder = \"GPTEvaluator/Experiments/Miniprompts_v2\"\n",
        "\n",
        "prompts = generate_prompts(prompt_data, prompt_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TArcbGPT2LA9",
        "outputId": "bd09f727-f3c1-4235-bd9b-c8660df6f438"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Question:** {Question}\n",
            "\n",
            "**Student's Answer:** {Answer}\n",
            "\n",
            "Instructions:\n",
            "(score) Assign a score between 0 and 10 to the student's answer.\n",
            "\n",
            "I expect a dict in python as answer: {{\"score\": score}}\n",
            "\n",
            "Python dict:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = experiment(df, prompts, repetitions=10, eval_function=\"map\", eval_params=[1, 3.33333, 6.66666], train_set_size=40, test_set_size=60, seed=42, model=\"gpt-4o-mini\", temperature=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "id": "CtzNfwy02RVE",
        "outputId": "5dd82595-30a7-4abe-c9e6-967731435e13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluando Prompt 1 con Test Set 1\n",
            "6-26-11-1-40-27-0-47-21-13-22-2-28-29-41-49-38-30-17-32-20-39-14-44-42-8-48-7-10-46-4-37-24-36-19-34-3-5-33-43-31-23-12-35-45-16-18-25-15-51-53-52-50-58-56-59-54-57-55-9-\n",
            "Evaluando Prompt 1 con Test Set 2\n",
            "0-11-42-32-37-22-35-10-16-18-8-28-24-44-14-26-25-43-46-15-1-6-31-27-19-48-47-33-40-36-49-2-41-34-12-13-20-7-39-4-21-3-30-38-29-5-45-23-9-50-17-51-54-52-53-59-55-57-56-58-\n",
            "Evaluando Prompt 1 con Test Set 3\n",
            "4-7-5-10-1-21-6-17-20-11-9-2-8-25-12-42-0-3-23-24-31-37-47-36-14-16-28-15-19-13-43-35-46-38-49-30-29-18-48-22-40-33-27-39-34-32-44-41-45-50-52-54-58-51-55-57-53-59-56-26-\n",
            "Evaluando Prompt 1 con Test Set 4\n",
            "0-47-16-35-5-30-26-1-6-12-21-36-34-32-41-37-31-38-33-49-24-39-13-28-44-40-8-43-23-22-20-14-48-15-46-29-7-25-11-18-9-17-45-2-27-3-4-42-10-19-50-53-54-57-51-56-58-59-55-52-\n",
            "Evaluando Prompt 1 con Test Set 5\n",
            "16-38-10-20-9-26-7-5-4-18-22-17-0-1-45-30-31-41-28-34-21-35-42-23-44-2-27-11-19-39-15-12-13-29-6-36-47-46-25-14-49-48-33-3-8-40-43-37-32-24-56-50-55-51-54-57-58-59-52-53-\n",
            "Evaluando Prompt 1 con Test Set 6\n",
            "2-5-4-3-1-38-0-16-49-7-31-22-20-6-18-10-25-8-28-46-35-42-30-47-41-44-33-9-26-48-24-29-12-14-15-23-17-45-19-32-27-43-34-40-39-36-11-13-21-51-53-54-50-52-58-59-55-57-37-56-\n",
            "Evaluando Prompt 1 con Test Set 7\n",
            "7-27-11-3-5-32-23-24-36-2-18-14-40-0-25-10-46-13-43-44-21-4-37-8-16-19-17-31-29-26-34-35-30-42-28-22-15-38-45-47-48-49-20-39-9-41-1-12-6-51-55-50-52-54-57-53-56-58-59-33-\n",
            "Evaluando Prompt 1 con Test Set 8\n",
            "4-11-16-19-14-2-48-29-22-5-10-8-9-18-28-13-12-30-26-45-31-43-1-20-17-25-7-21-39-40-44-24-36-23-15-0-3-6-46-47-35-38-34-32-27-33-41-49-37-42-53-55-50-54-59-57-56-58-51-52-\n",
            "Evaluando Prompt 1 con Test Set 9\n",
            "0-6-29-4-36-3-15-17-38-14-26-27-22-49-24-28-10-11-21-31-44-12-25-13-19-9-34-37-47-48-35-5-18-39-32-30-42-7-33-46-2-8-23-45-40-1-20-43-41-16-56-55-51-57-53-50-54-52-59-58-\n",
            "Evaluando Prompt 1 con Test Set 10\n",
            "8-34-0-1-18-4-14-9-27-3-15-6-37-24-43-40-33-48-32-7-38-49-10-21-2-5-30-11-13-20-19-26-41-47-23-44-36-28-45-22-35-31-12-17-16-39-25-29-46-42-52-59-51-54-53-57-56-50-55-58-\n",
            "\n",
            "Tabla MSE normalizado\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                                                                Prompt  \\\n",
              "0  {\"question\": \"question.txt\", \"answer\": \"answer.txt\", \"instructions\": {\"score\": \"score_single.txt\"}}   \n",
              "\n",
              "   Mean  Std  \n",
              "0   NaN  NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-06edb760-0288-4048-8ce8-67551ab8981a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prompt</th>\n",
              "      <th>Mean</th>\n",
              "      <th>Std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{\"question\": \"question.txt\", \"answer\": \"answer.txt\", \"instructions\": {\"score\": \"score_single.txt\"}}</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-06edb760-0288-4048-8ce8-67551ab8981a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-06edb760-0288-4048-8ce8-67551ab8981a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-06edb760-0288-4048-8ce8-67551ab8981a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"x = experiment(df, prompts, repetitions=10, eval_function=\\\"map\\\", eval_params=[1, 3\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"{\\\"question\\\": \\\"question.txt\\\", \\\"answer\\\": \\\"answer.txt\\\", \\\"instructions\\\": {\\\"score\\\": \\\"score_single.txt\\\"}}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tabla Promedio MSE\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                                                                Prompt  \\\n",
              "0  {\"question\": \"question.txt\", \"answer\": \"answer.txt\", \"instructions\": {\"score\": \"score_single.txt\"}}   \n",
              "\n",
              "        All  C1-OscarBadAnswers20    C2-Nan  C2-Sample100  C3-Sample100  \n",
              "0  0.744584              1.659382  0.907606      0.561431      0.554591  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e4f74b2b-2d5a-4afb-83ea-c191fafc56fd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prompt</th>\n",
              "      <th>All</th>\n",
              "      <th>C1-OscarBadAnswers20</th>\n",
              "      <th>C2-Nan</th>\n",
              "      <th>C2-Sample100</th>\n",
              "      <th>C3-Sample100</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{\"question\": \"question.txt\", \"answer\": \"answer.txt\", \"instructions\": {\"score\": \"score_single.txt\"}}</td>\n",
              "      <td>0.744584</td>\n",
              "      <td>1.659382</td>\n",
              "      <td>0.907606</td>\n",
              "      <td>0.561431</td>\n",
              "      <td>0.554591</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e4f74b2b-2d5a-4afb-83ea-c191fafc56fd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e4f74b2b-2d5a-4afb-83ea-c191fafc56fd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e4f74b2b-2d5a-4afb-83ea-c191fafc56fd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"x = experiment(df, prompts, repetitions=10, eval_function=\\\"map\\\", eval_params=[1, 3\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"{\\\"question\\\": \\\"question.txt\\\", \\\"answer\\\": \\\"answer.txt\\\", \\\"instructions\\\": {\\\"score\\\": \\\"score_single.txt\\\"}}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"All\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.7445835566369701,\n        \"max\": 0.7445835566369701,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.7445835566369701\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"C1-OscarBadAnswers20\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.6593818383464065,\n        \"max\": 1.6593818383464065,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.6593818383464065\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"C2-Nan\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.907605977164543,\n        \"max\": 0.907605977164543,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.907605977164543\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"C2-Sample100\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.561431106990329,\n        \"max\": 0.561431106990329,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.561431106990329\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"C3-Sample100\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.5545914783419822,\n        \"max\": 0.5545914783419822,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.5545914783419822\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tabla Desviación estándar\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                                                                Prompt  \\\n",
              "0  {\"question\": \"question.txt\", \"answer\": \"answer.txt\", \"instructions\": {\"score\": \"score_single.txt\"}}   \n",
              "\n",
              "        All  C1-OscarBadAnswers20    C2-Nan  C2-Sample100  C3-Sample100  \n",
              "0  0.063526               0.51081  0.161689       0.19289      0.133011  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-82368b61-39df-4aa7-932b-dfc95609a8e8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prompt</th>\n",
              "      <th>All</th>\n",
              "      <th>C1-OscarBadAnswers20</th>\n",
              "      <th>C2-Nan</th>\n",
              "      <th>C2-Sample100</th>\n",
              "      <th>C3-Sample100</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{\"question\": \"question.txt\", \"answer\": \"answer.txt\", \"instructions\": {\"score\": \"score_single.txt\"}}</td>\n",
              "      <td>0.063526</td>\n",
              "      <td>0.51081</td>\n",
              "      <td>0.161689</td>\n",
              "      <td>0.19289</td>\n",
              "      <td>0.133011</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82368b61-39df-4aa7-932b-dfc95609a8e8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-82368b61-39df-4aa7-932b-dfc95609a8e8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-82368b61-39df-4aa7-932b-dfc95609a8e8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"x = experiment(df, prompts, repetitions=10, eval_function=\\\"map\\\", eval_params=[1, 3\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"{\\\"question\\\": \\\"question.txt\\\", \\\"answer\\\": \\\"answer.txt\\\", \\\"instructions\\\": {\\\"score\\\": \\\"score_single.txt\\\"}}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"All\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.063526081417516,\n        \"max\": 0.063526081417516,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.063526081417516\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"C1-OscarBadAnswers20\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.5108100260196241,\n        \"max\": 0.5108100260196241,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.5108100260196241\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"C2-Nan\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.16168893278937632,\n        \"max\": 0.16168893278937632,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.16168893278937632\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"C2-Sample100\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.1928901915124964,\n        \"max\": 0.1928901915124964,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.1928901915124964\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"C3-Sample100\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.13301067046261855,\n        \"max\": 0.13301067046261855,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.13301067046261855\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r Results.zip Results/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElKesxXQDZq2",
        "outputId": "6247e643-0531-49aa-cc1e-298cbd9d6e99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: Results/ (stored 0%)\n",
            "updating: Results/scores.json (deflated 66%)\n",
            "updating: Results/context_full.json (deflated 58%)\n",
            "updating: Results/base.json (deflated 62%)\n",
            "updating: Results/.ipynb_checkpoints/ (stored 0%)\n",
            "updating: Results/context_simple.json (deflated 58%)\n",
            "updating: Results/analysis.json (deflated 63%)\n",
            "updating: Results/examples_basic.json (deflated 69%)\n",
            "updating: Results/examples_full.json (deflated 65%)\n",
            "updating: Results/feedback.json (deflated 64%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf Results"
      ],
      "metadata": {
        "id": "Lamji1gPGCNe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}